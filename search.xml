<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数据库优化方案]]></title>
    <url>%2F2019%2F02%2F22%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[SQL优化方案参考博客 优化的哲学优化可能带来的影响 优化不总是对一个单纯的环境进行，还很可能是一个复杂的已投产的系统； 优化手段本来就有很大的风险，只不过你没能力意识到和预见到； 任何的技术可以解决一个问题，但必然存在带来一个问题的风险； 对于优化来说解决问题而带来的问题，控制在可接受的范围内才是有成果； 保持现状或出现更差的情况都是失败！ 优化的需求 稳定性和业务可持续性，通常比性能更重要； 优化不可避免涉及到变更，变更就有风险； 优化使性能变好，维持和变差是等概率事件； 切记优化，应该是各部门协同，共同参与的工作，任何单一部门都不能对数据库进行优化！ 所以优化工作，是由业务需要驱使的！ 优化参与在进行数据库优化时，应由数据库管理员、业务部门代表、应用程序架构师、应用程序设计人员、应用程序开发人员、硬件及系统管理员、存储管理员等，业务相关人员共同参与。 优化思路优化对象在数据库优化上有两个主要方面：即安全与性能。 安全-&gt;数据可持续性 性能-&gt;数据的高性能访问 优化的范围 存储、主机和操作系统方面： 主机架构稳定性； I/O规划及配置； Swap交换分区； OS内核参数和网络问题。 应用程序方面： 应用程序稳定性； SQL语句性能； 串行访问资源； 能欠佳会话管理； 这个应用适不适合用MySQL。 数据库优化方面： 内存； 数据库结构（物理&amp;逻辑）； 实例配置。 不管是设计系统、定位问题还是优化，都可以按照这个顺序执行。 优化维度数据库优化维度有四个： 硬件、系统配置、数据库表结构、SQL及索引。 优化选择： 优化成本：硬件&gt;系统配置&gt;数据库表结构&gt;SQL及索引。 优化效果：硬件&lt;系统配置&lt;数据库表结构&lt;SQL及索引。 优化工具数据库层面检查问题常用工具： 12345678910111213141516171819202122231）MySQL2）msyqladmin：MySQL客户端，可进行管理操作3）mysqlshow：功能强大的查看shell命令4）show [SESSION | GLOBAL] variables：查看数据库参数信息5）SHOW [SESSION | GLOBAL] STATUS：查看数据库的状态信息6）information_schema：获取元数据的方法7）SHOW ENGINE INNODB STATUS：Innodb引擎的所有状态8）SHOW PROCESSLIST：查看当前所有连接session状态9）explain：获取查询语句的执行计划10）show index：查看表的索引信息11）slow-log：记录慢查询语句12）mysqldumpslow：分析slowlog文件的 不常用但好用的工具：123456789101112131）Zabbix：监控主机、系统、数据库（部署zabbix监控平台）2）pt-query-digest：分析慢日志3）MySQL slap：分析慢日志4）sysbench：压力测试工具5）MySQL profiling：统计数据库整体状态工具 6）Performance Schema：MySQL性能状态统计的数据7）workbench：管理、备份、监控、分析、优化工具（比较费资源） 关于Zabbix参考 数据库层面问题解决思路一般应急调优的思路：针对突然的业务办理卡顿，无法进行正常的业务处理，需要立马解决的场景。12345678910111）show processlist；2）explain select id ,name from stu where name='clsn'; # ALL id name age sex；select id,name from stu where id=2-1 函数 结果集&gt;30；show index from table；3）通过执行计划判断，索引问题（有没有、合不合理）或者语句本身问题；4）show status like '%lock%'; # 查询锁状态kill SESSION_ID; # 杀掉有问题的session。 常规调优思路：针对业务周期性的卡顿，例如在每天10-11点业务特别慢，但是还能够使用，过了这段时间就好了。12345671）查看slowlog，分析slowlog，分析出查询慢的语句；2）按照一定优先级，一个一个排查所有慢语句；3）分析top SQL，进行explain调试，查看语句执行时间；4）调整索引或语句本身。 系统层面Cpu方面1vmstat、sar top、htop、nmon、mpstat； 内存1free、ps-aux； IO设备（磁盘、网络）1iostat、ss、netstat、iptraf、iftop、lsof； vmstat命令说明12345678910111）Procs：r显示有多少进程正在等待CPU时间。b显示处于不可中断的休眠的进程数量。在等待I/O。2）Memory：swpd显示被交换到磁盘的数据块的数量。未被使用的数据块，用户缓冲数据块，用于操作系统的数据块的数量。3）Swap：操作系统每秒从磁盘上交换到内存和从内存交换到磁盘的数据块的数量。s1和s0最好是0。4）Io：每秒从设备中读入b1的写入到设备b0的数据块的数量。反映了磁盘I/O。5）System：显示了每秒发生中断的数量（in）和上下文交换（cs）的数量。6）Cpu：显示用于运行用户代码，系统代码，空闲，等待I/O的Cpu时间。 iostat命令说明1234567891011121314151617实例命令：iostat -dk 1 5 iostat -d -k -x 5 （查看设备使用率（%util）和响应时间（await））1）tps：该设备每秒的传输次数。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。2）iops ：硬件出厂的时候，厂家定义的一个每秒最大的IO次数3）"一次传输"请求的大小是未知的。4）kB_read/s：每秒从设备（drive expressed）读取的数据量；5）KB_wrtn/s：每秒向设备（drive expressed）写入的数据量；6）kB_read：读取的总数据量；7）kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。 系统层面问题解决办法你认为到底负载高好，还是低好呢？在实际的生产中，一般认为Cpu只要不超过90%都没什么问题。 当然不排除下面这些特殊情况： Cpu负载高，IO负载低1234567891）内存不够；2）磁盘性能差；3）SQL问题---&gt;去数据库层，进一步排查SQL 问题；4）IO出问题了（磁盘到临界了、raid设计不好、raid降级、锁、在单位时间内tps过高）；5）tps过高：大量的小数据IO、大量的全表扫描。 IO负载高，Cpu负载低123451）大量小的IO写操作：autocommit，产生大量小IO；IO/PS，磁盘的一个定值，硬件出厂的时候，厂家定义的一个每秒最大的IO次数。2）大量大的IO 写操作：SQL问题的几率比较大 IO和cpu负载都很高1硬件不够了或SQL存在问题。 基础优化优化思路定位问题点吮吸：硬件–&gt;系统–&gt;应用–&gt;数据库–&gt;架构（高可用、读写分离、分库分表）。 处理方向：明确优化目标、性能和安全的折中、防患未然。 硬件优化主机方面1234567根据数据库类型，主机CPU选择、内存容量选择、磁盘选择：1）平衡内存和磁盘资源；2）随机的I/O和顺序的I/O；3）主机 RAID卡的BBU（Battery Backup Unit）关闭。 CPU的选择1234567CPU的两个关键因素：核数、主频根据不同的业务类型进行选择：1）CPU密集型：计算比较多，OLTP - 主频很高的cpu、核数还要多2）IO密集型：查询比较，OLAP - 核数要多，主频不一定高的 内存的选择123OLAP类型数据库，需要更多内存，和数据获取量级有关。OLTP类型数据一般内存是Cpu核心数量的2倍到4倍，没有最佳实践。 存储方面12345678910111213141516171）根据存储数据种类的不同，选择不同的存储设备；2）配置合理的RAID级别（raid5、raid10、热备盘）；3）对与操作系统来讲，不需要太特殊的选择，最好做好冗余（raid1）（ssd、sas、sata）。4）raid卡： 主机raid卡选择： 实现操作系统磁盘的冗余（raid1）； 平衡内存和磁盘资源； 随机的I/O和顺序的I/O； 主机raid卡的BBU（Battery Backup Unit）要关闭。 网络设备方面1使用流量支持更高的网络设备（交换机、路由器、网线、网卡、HBA卡） 注意：以上这些规划应该在初始设计系统时就应该考虑好。 服务器硬件优化12345671）物理状态灯2）自带管理设备：远程控制卡（FENCE设备：ipmi ilo idarc）、开关机、硬件监控。3）第三方的监控软件、设备（snmp、agent）对物理设施进行监控。4）存储设备：自带的监控平台。EMC2（hp收购了）、 日立（hds）、IBM低端OEM hds、高端存储是自己技术，华为存储。 系统优化Cpu1基本不需要调整，在硬件选择方面下功夫即可。 内存1基本不需要调整，在硬件选择方面下功夫即可。 SWAP123MySQL尽量避免使用swap。阿里云的服务器中默认swap为0。 IO1raid、no lvm、ext4或xfs、ssd、IO调度策略。 Swap调整(不使用swap分区)1/proc/sys/vm/swappiness的内容改成0（临时），/etc/sysctl. conf上添加vm.swappiness=0（永久） 这个参数决定了Linux是倾向于使用swap，还是倾向于释放文件系统cache。在内存紧张的情况下，数值越低越倾向于释放文件系统cache。 当然，这个参数只能减少使用swap的概率，并不能避免Linux使用swap。 修改MySQL的配置参数innodb_flush_ method，开启O_DIRECT模式： 这种情况下，InnoDB的buffer pool会直接绕过文件系统cache来访问磁盘，但是redo log依旧会使用文件系统cache。 值得注意的是，Redo log是覆写模式的，即使使用了文件系统的cache，也不会占用太多。 IO调度策略1#echo deadline&gt;/sys/block/sda/queue/scheduler 临时修改为deadline 永久修改12345vi /boot/grub/grub.conf更改到如下内容:kernel /boot/vmlinuz-2.6.18-8.el5 ro root=LABEL=/ elevator=deadline rhgb quiet 系统参数调整Linux系统内核参数优化123456789vim/etc/sysctl.confnet.ipv4.ip_local_port_range = 1024 65535：# 用户端口范围net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_fin_timeout = 30 fs.file-max=65535：# 系统最大文件句柄，控制的是能打开文件最大数量 用户限制参数（MySQL可以不设置以下配置）123456789vim/etc/security/limits.conf * soft nproc 65535* hard nproc 65535* soft nofile 65535* hard nofile 65535 应用优化业务应用和数据库应用独立； 防火墙：iptables、selinux等其他无用服务（关闭）：1234567891011121314151617181920212223242526272829chkconfig --level 23456 acpid offchkconfig --level 23456 anacron offchkconfig --level 23456 autofs offchkconfig --level 23456 avahi-daemon offchkconfig --level 23456 bluetooth offchkconfig --level 23456 cups offchkconfig --level 23456 firstboot offchkconfig --level 23456 haldaemon offchkconfig --level 23456 hplip offchkconfig --level 23456 ip6tables offchkconfig --level 23456 iptables offchkconfig --level 23456 isdn offchkconfig --level 23456 pcscd offchkconfig --level 23456 sendmail offchkconfig --level 23456 yum-updatesd off 安装图形界面的服务器不要启动图形界面runlevel 3。 另外，思考将来我们的业务是否真的需要MySQL，还是使用其他种类的数据库。用数据库的最高境界就是不用数据库。 数据库优化SQL优化方向：执行计划、索引、SQL改写。 架构优化方向：高可用架构、高性能架构、分库分表。 数据库参数优化调整 实例整体（高级优化，扩展）：1234567891011thread_concurrency：# 并发线程数量个数sort_buffer_size：# 排序缓存read_buffer_size：# 顺序读取缓存read_rnd_buffer_size：# 随机读取缓存key_buffer_size：# 索引缓存thread_cache_size：# (1G—&gt;8, 2G—&gt;16, 3G—&gt;32, &gt;3G—&gt;64) 连接层（基础优化）设置合理的连接客户和连接方式：12345678910111213max_connections # 最大连接数，看交易笔数设置 max_connect_errors # 最大错误连接数，能大则大connect_timeout # 连接超时max_user_connections # 最大用户连接数skip-name-resolve # 跳过域名解析wait_timeout # 等待超时back_log # 可以在堆栈中的连接数量 SQL层（基础优化）query_cache_size： 查询缓存 &gt;&gt;&gt; OLAP类型数据库,需要重点加大此内存缓存，但是一般不会超过GB。 对于经常被修改的数据，缓存会立马失效。 我们可以实用内存数据库（redis、memecache），替代他的功能。 存储引擎层（innodb基础优化参数）123456789101112131415161718192021222324252627default-storage-engineinnodb_buffer_pool_size # 没有固定大小，50%测试值，看看情况再微调。但是尽量设置不要超过物理内存70%innodb_file_per_table=(1,0)innodb_flush_log_at_trx_commit=(0,1,2) # 1是最安全的，0是性能最高，2折中binlog_syncInnodb_flush_method=(O_DIRECT, fdatasync)innodb_log_buffer_size # 100M以下innodb_log_file_size # 100M 以下innodb_log_files_in_group # 5个成员以下,一般2-3个够用（iblogfile0-N）innodb_max_dirty_pages_pct # 达到百分之75的时候刷写 内存脏页到磁盘。log_binmax_binlog_cache_size # 可以不设置max_binlog_size # 可以不设置innodb_additional_mem_pool_size #小于2G内存的机器，推荐值是20M。32G内存以上100M SQL语句优化原文博客 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描1select id from t where num is null; 可以在 num 上设置默认值 0,确保表中 num 列没有 null 值，然后这样查询：1select id from t where num=0; 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描1select id from t where num=10 or num=20; 可以这样查询12select id from t where num=10;select id from t where num=20; in 和 not in 也要慎用，否则会导致全表扫描，如：1select id from t where num in(1,2,3); 对于连续的数值，能用 between 就不要用 in 了：1select id from t where num between 1 and 3; 下面的查询也将导致全表扫描：1select id from t where name like '%c%'; 若要提高效率，可以考虑全文检索。 如果在 where 子句中使用参数，也会导致全表扫描。因为 SQL 只有在运行时才会解析局部变量，但优 化程序不能将访问计划的选择推迟到运行时;它必须在编译时进行选择。然 而，如果在编译时建立访问计 划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：1select id from t where num=@num ; 可以改为强制查询使用索引：1select id from t with(index(索引名)) where num=@num ; 应尽量避免在 where 子句中对字段进行表达式操作， 这将导致引擎放弃使用索引而进行全表扫描。1select id from t where num/2=100; 可以这样查询：1select id from t where num=100*2; 应尽量避免在 where 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：1select id from t where substring(name,1,3)='abc';#name 以 abc 开头的 id 应改为：1select id from t where name like 'abc%'; 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用 索引。 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件 时才能保证系统使用该索引， 否则该索引将不会 被使用， 并且应尽可能的让字段顺序与索引顺序相一致。 不要写一些没有意义的查询，如需要生成一个空表结构：1select col1,col2 into #t from t where 1=0; 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：1create table #t(…); 很多时候用 exists 代替 in 是一个好的选择：1select num from a where num in(select num from b); 用下面的语句替换：1select num from a where exists(select 1 from b where num=a.num); 并不是所有索引对查询都有效，SQL 是根据表中数据来进行查询优化的，当索引列有大量数据重复时， SQL 查询可能不会去利用索引，如一表中有字段 sex,male、female 几乎各一半，那么即使在 sex 上建 了索引也对查询效率起不了作用。 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过 6 个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 应尽可能的避免更新 clustered 索引数据列， 因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并 会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言 只需要比较一次就够了。 尽可能的使用 varchar/nvarchar 代替 char/nchar , 因为首先变长字段存储空间小， 可以节省存储空间， 其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 任何地方都不要使用 select * from t ,用具体的字段列表代替“*”,不要返回用不到的任何字段。 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限(只有主键索引)。 避免频繁创建和删除临时表，以减少系统表资源的消耗。 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用。 表中的某个数据集时。但是，对于一次性事件， 最好使用导出表。 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table,避免造成大量 log ,以提高速度;如果数据量不大，为了缓和系统表的资源，应先 create table,然后 insert。 如果使用到了临时表， 在存储过程的最后务必将所有的临时表显式删除， 先 truncate table ,然后 drop table ,这样可以避免系统表的较长时间锁定。 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过 1 万行，那么就应该考虑改写。 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON,在结束时设置 SET NOCOUNT OFF .无需在执行存储过程和触发器的每个语句后向客户端发送DONE_IN_PROC消息。 尽量避免大事务操作，提高系统并发能力。 sql 优化方法使用索引来更快地遍历表。 缺省情况下建立的索引是非群集索引，但有时它并不是最佳的。在非群集索引下，数据在物理上随机存放在数据页上。合理的索引设计要建立在对各种查询的分析和预测上。一般来说： 有大量重复值、且经常有范围查询( &gt; ,&lt; ,&gt; =,&lt; =)和 order by、group by 发生的列，可考虑建立集群索引; 经常同时存取多列，且每列都含有重复值可考虑建立组合索引; 组合索引要尽量使关键查询形成索引覆盖，其前导列一定是使用最频繁的列。索引虽有助于提高性能但 不是索引越多越好，恰好相反过多的索引会导致系统低效。用户在表中每加进一个索引，维护索引集合就 要做相应的更新工作。 定期分析表和检查表1分析表的语法：ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tb1_name[, tbl_name]... 以上语句用于分析和存储表的关键字分布，分析的结果将可以使得系统得到准确的统计信息，使得SQL能够生成正确的执行计划。如果用户感觉实际执行计划并不是预期的执行计划，执行一次分析表可能会解决问题。在分析期间，使用一个读取锁定对表进行锁定。这对于MyISAM，DBD和InnoDB表有作用。123例如分析一个数据表：analyze table table_name检查表的语法：CHECK TABLE tb1_name[,tbl_name]...[option]...option = &#123;QUICK | FAST | MEDIUM | EXTENDED | CHANGED&#125; 检查表的作用是检查一个或多个表是否有错误，CHECK TABLE 对MyISAM 和 InnoDB表有作用，对于MyISAM表，关键字统计数据被更新 CHECK TABLE 也可以检查视图是否有错误，比如在视图定义中被引用的表不存在。 定期优化表。1优化表的语法：OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tb1_name [,tbl_name]... 如果删除了表的一大部分，或者如果已经对含有可变长度行的表(含有 VARCHAR、BLOB或TEXT列的表)进行更多更改，则应使用OPTIMIZE TABLE命令来进行表优化。这个命令可以将表中的空间碎片进行合并，并且可以消除由于删除或者更新造成的空间浪费，但OPTIMIZE TABLE 命令只对MyISAM、 BDB 和InnoDB表起作用。 1例如： optimize table table_name 注意： analyze、check、optimize执行期间将对表进行锁定，因此一定注意要在MySQL数据库不繁忙的时候执行相关的操作。 其他 在海量查询时尽量少用格式转换。 ORDER BY 和 GROPU BY:使用 ORDER BY 和 GROUP BY 短语，任何一种索引都有助于 SELECT 的性能提高。 任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边。 IN、OR 子句常会使用工作表，使索引失效。如果不产生大量重复值，可以考虑把子句拆开。拆开的子 句中应该包含索引。 只要能满足你的需求，应尽可能使用更小的数据类型：例如使用 MEDIUMINT 代替 INT 尽量把所有的列设置为 NOT NULL,如果你要保存 NULL,手动去设置它，而不是把它设为默认值。 尽量少用 VARCHAR、TEXT、BLOB 类型 如果你的数据只有你所知的少量的几个。最好使用 ENUM 类型 正如 graymice 所讲的那样，建立索引。 合理用运分表与分区表提高数据存放和提取速度。 亿级数据下的分库分表方案原文 项目背景项目背景是企业级的统一消息处理平台，客户数据在5千万加，每分钟处理消息流水1千万，每天消息流水1亿左右。 虽说Mysql单表可以存储10亿级的数据，但这个时候性能非常差，项目中大量的实验证明，Mysql单表容量在500万左右，性能处于最佳状态，此时，Mysql的BTREE索引树高在3～5之间。既然一张表无法搞定，那么就想办法将数据放到多个地方来解决问题吧，于是，数据库分库分表的方案便产生了，目前比较普遍的方案有三个： 分区，分库分表，NoSql/NewSql 。 在实际的项目中，往往是这三种方案的结合来解决问题，目前绝大部分系统的核心数据都是以RDBMS存储为主，NoSql/NewSql存储为辅。 分区首先来了解一下分区方案。 分区表是由多个相关的底层表实现，这些底层表也是由句柄对象表示，所以我们也可以直接访问各个分区，存储引擎管理分区的各个底层表和管理普通表一样（所有的底层表都必须使用相同的存储引擎），分区表的索引只是在各个底层表上各自加上一个相同的索引，从存储引擎的角度来看，底层表和一个普通表没有任何不同，存储引擎也无须知道这是一个普通表还是一个分区表的一部分。这个方案也不错，它对用户屏蔽了sharding的细节，即使查询条件没有sharding column，它也能正常工作（只是这时候性能一般）。不过它的缺点很明显：很多的资源都受到单机的限制，例如连接数，网络吞吐等。如何进行分区，在实际应用中是一个非常关键的要素之一。在我们的项目中，以客户信息为例，客户数据量5000万加，项目背景要求保存客户的银行卡绑定关系，客户的证件绑定关系，以及客户绑定的业务信息。此业务背景下，该如何设计数据库呢。项目一期的时候，我们建立了一张客户业务绑定关系表，里面冗余了每一位客户绑定的业务信息。基本结构大致如下：查询时，对银行卡做索引，业务编号做索引，证件号做索引。随着需求大增多，这张表的索引会达到10个以上。而且客户解约再签约，里面会保存两条数据，只是绑定的状态不同。假设我们有5千万的客户，5个业务类型，每位客户平均2张卡，那么这张表的数据量将会达到惊人的5亿，事实上我们系统用户量还没有过百万时就已经不行了。mysql数据库中的数据是以文件的形势存在磁盘上的，默认放在/mysql/data下面（可以通过my.cnf中的datadir来查看）， 一张表主要对应着三个文件，一个是frm存放表结构的，一个是myd存放表数据的，一个是myi存表索引的。这三个文件都非常的庞大，尤其是.myd文件，快5个G了。 下面进行第一次分区优化 ，Mysql支持的分区方式有四种：在我们的项目中，range分区和list分区没有使用场景，如果基于绑定编号做range或者list分区，绑定编号没有实际的业务含义，无法通过它进行查询，因此，我们就剩下 HASH 分区和 KEY 分区了， HASH 分区仅支持int类型列的分区，且是其中的一列。看看我们的库表结构，发现没有哪一列是int类型的，如何做分区呢？可以增加一列，绑定时间列，将此列设置为int类型，然后按照绑定时间进行分区，将每一天绑定的用户分到同一个区里面去。这次优化之后，我们的插入快了许多，但是查询依然很慢，为什么，因为在做查询的时候，我们也只是根据银行卡或者证件号进行查询，并没有根据时间查询，相当于每次查询，mysql都会将所有的分区表查询一遍。 然后进行第二次方案优化，既然hash分区和key分区要求其中的一列必须是int类型的，那么创造出一个int类型的列出来分区是否可以。分析发现，银行卡的那串数字有秘密。银行卡一般是16位到19位不等的数字串，我们取其中的某一位拿出来作为表分区是否可行呢，通过分析发现，在这串数字中，其中确实有一位是0到9随机生成的，不同的卡串长度，这一位不同，绝不是最后一位，最后位数字一般都是校验位，不具有随机性。我们新设计的方案，基于银行卡号+随机位进行KEY分区，每次查询的时候，通过计算截取出这位随机位数字，再加上卡号，联合查询，达到了分区查询的目的，需要说明的是，分区后，建立的索引，也必须是分区列，否则的话，Mysql还是会在所有的分区表中查询数据。那么通过银行卡号查询绑定关系的问题解决了，那么证件号呢，如何通过证件号来查询绑定关系。前面已经讲过，做索引一定是要在分区健上进行，否则会引起全表扫描。我们再创建了一张新表，保存客户的证件号绑定关系，每位客户的证件号都是唯一的，新的证件号绑定关系表里，证件号作为了主键，那么如何来计算这个分区健呢，客户的证件信息比较庞杂，有身份证号，港澳台通行证，机动车驾驶证等等，如何在无序的证件号里找到分区健。为了解决这个问题，我们将证件号绑定关系表一分为二，其中的一张表专用于保存身份证类型的证件号，另一张表则保存其他证件类型的证件号，在身份证类型的证件绑定关系表中，我们将身份证号中的月数拆分出来作为了分区健，将同一个月出生的客户证件号保存在同一个区，这样分成了12个区，其他证件类型的证件号，数据量不超过10万，就没有必要进行分区了。这样每次查询时，首先通过证件类型确定要去查询哪张表，再计算分区健进行查询。 作了分区设计之后，保存2000万用户数据的时候，银行卡表的数据保存文件就分成了10个小文件，证件表的数据保存文件分成了12个小文件，解决了这两个查询的问题，还剩下一个问题就是，业务编号呢，怎么办，一个客户有多个签约业务，如何进行保存，这时候，采用分区的方案就不太合适了，它需要用到分表的方案。 分库分表如何进行分库分表，目前互联网上有许多的版本，比较知名的一些方案： 阿里的TDDL，DRDS和cobar 京东金融的sharding-jdbc 民间组织的MyCAT 360的Atlas 美团的zebra 其他比如网易，58，京东等公司都有自研的中间件。 百花齐放的景象。但是这么多的分库分表中间件方案，归总起来，就两类： client模式和proxy模式 。 client模式 proxy模式 无论是client模式，还是proxy模式，几个核心的步骤是一样的：SQL解析，重写，路由，执行，结果归并。个人比较倾向于采用client模式，它架构简单，性能损耗也比较小，运维成本低。如果在项目中引入mycat或者cobar，他们的单机模式无法保证可靠性，一旦宕机则服务就变得不可用，你又不得不引入HAProxy来实现它的高可用集群部署方案， 为了解决HAProxy的高可用问题，又需要采用Keepalived来实现。 我们在项目中放弃了这个方案，采用了shardingjdbc的方式。回到刚才的业务问题，如何对业务类型进行分库分表。分库分表第一步也是最重要的一步，即sharding column的选取，sharding column选择的好坏将直接决定整个分库分表方案最终是否成功。而sharding column的选取跟业务强相关。在我们的项目场景中，sharding column无疑最好的选择是业务编号。通过业务编号，将客户不同的绑定签约业务保存到不同的表里面去，查询时，根据业务编号路由到相应的表中进行查询，达到进一步优化sql的目的。 前面我们讲到了基于客户签约绑定业务场景的数据库优化，下面我们再聊一聊，对于海量数据的保存方案。 垂直拆分垂直分表也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。 垂直分库垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。如下图：优点 数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于 Web 和应用服务器来讲，是比较难实现“横向扩展”的。数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破 IO、连接数及单机硬件资源的瓶颈，是大型分布式系统中优化数据库架构的重要手段。 缺点 跨库 join 的问题 跨库事务（分布式事务）的问题 解决方式 全局表 所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似我们理解的“数据字典”。为了避免跨库 join 查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。 字段冗余 这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免 join 查询。 数据同步 定时 A 库中的 tab_a 表和 B 库中 tbl_b 有关联，可以定时将指定的表做同步。当然，同步本来会对数据库带来一定的影响，需要性能影响和数据时效性中取得一个平衡。这样来避免复杂的跨库查询。例如ETL工具。 系统层组装 在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装。说起来很容易，但实践起来可真没有这么简单，尤其是数据库设计上存在问题但又无法轻易调整的时候。 对于每分钟要处理近1000万的流水，每天流水近1亿的量，如何高效的写入和查询，是一项比较大的挑战。还是老办法，分库分表分区，读写分离，只不过这一次，我们先分表，再分库，最后分区。我们将消息流水按照不同的业务类型进行分表，相同业务的消息流水进入同一张表，分表完成之后，再进行分库。我们将流水相关的数据单独保存到一个库里面去，这些数据，写入要求高，查询和更新到要求低，将它们和那些更新频繁的数据区分开。分库之后，再进行分区。这是基于业务垂直度进行的分库操作，垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库，以达到系统资源的饱和利用率。这样的分库方案结合应用的微服务治理，每个微服务系统使用独立的一个数据库。将不同模块的数据分库存储，模块间不能进行相互关联查询，如果有，要么通过数据冗余解决，要么通过应用代码进行二次加工进行解决。若不能杜绝跨库关联查询，则将小表到数据冗余到大数据量大库里去。假如，流水大表中查询需要关联获得渠道信息，渠道信息在基础管理库里面，那么，要么在查询时，代码里二次查询基础管理库中的渠道信息表，要么将渠道信息表冗余到流水大表中。 将每天过亿的流水数据分离出去之后，流水库中单表的数据量还是太庞大，我们将单张流水表继续分区，按照一定的业务规则，（一般是查询索引列）将单表进行分区，一个表编程N个表，当然这些变化对应用层是无法感知的。分区表的设置，一般是以查询索引列进行分区，例如，对于流水表A，查询需要根据手机号和批次号进行查询，所以我们在创建分区的时候，就选择以手机号和批次号进行分区，这样设置后，查询都会走索引，每次查询Mysql都会根据查询条件计算出来，数据会落在那个分区里面，直接到对应的分区表中检索即可，避免了全表扫描。 对于每天流水过亿的数据，当然是要做历史表进行数据迁移的工作了。客户要求流水数据需要保存半年的时间，有的关键流水需要保存一年。删数据是不可能的了，也跑不了路，虽然当时非常有想删数据跑路的冲动。其实即时是删数据也是不太可能的了，delete的拙劣表演先淘汰了，truncate也快不了多少，我们采用了一种比较巧妙方法，具体步骤如下： 创建一个原表一模一样的临时表1 create table test_a_serial_1 like test_a_serial; 将原表命名为临时表2 alter table test_a_serial rename test_a_serial_{date}; 将临时表1改为原表 alter table able test_a_serial_1 rename able test_a_serial; 此时，当日流水表就是一张新的空表了，继续保存当日的流水，而临时表2则保存的是昨天的数据和部分今天的数据，临时表2到名字中的date时间是通过计算获得的昨日的日期；每天会产生一张带有昨日日期的临时表2，每个表内的数据大约是有1000万。 将当日表中的历史数据迁移到昨日流水表中去 这样的操作都是用的定时任务进行处理，定时任务触发一般会选择凌晨12点以后，这个操作即时是几秒内完成，也有可能会有几条数据落入到当日表中去。因此我们最后还需要将当日表内的历史流水数据插入到昨日表内； insert into test_a_serial_{date}(cloumn1,cloumn2….) select(cloumn1,cloumn2….) from test_a_serial where LEFT(create_time,8) &gt; CONCAT(date); commit; 如此，便完成了流水数据的迁移； 根据业务需要，有些业务数据需要保存半年，超过半年的进行删除,在进行删除的时候，就可以根据表名中的_{date}筛选出大于半年的流水直接删表； 半年的时间，对于一个业务流水表大约就会有180多张表，每张表又有20个分区表，那么如何进实时计算统计行查询呢？由于我们的项目对于流水的查询实时性要求不是特别高，因此我们在做查询时，进行了根据查询时间区间段进行路由查询的做法。大致做法时，根据客户选择的时间区间段，带上查询条件，分别去时间区间段内的每一张表内查询，将查询结果保存到一张临时表内，然后，再去查询临时表获得最终的查询结果。 半年的时间，对于一个业务流水表大约就会有180多张表，每张表又有20个分区表，那么如何进行查询呢？由于我们的项目对于流水的查询实时性要求不是特别高，因此我们在做查询时，进行了根据查询时间区间段进行路由查询的做法。大致做法时，根据客户选择的时间区间段，带上查询条件，分别去时间区间段内的每一张表内查询，将查询结果保存到一张临时表内，然后，再去查询临时表获得最终的查询结果。 以上便是我们面对大数据量的场景下，数据库层面做的相应的优化，一张每天一亿的表，经过拆分后，每个表分区内的数据在500万左右。 水平拆分水平分表针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。某种意义上来讲，有些系统中使用的“冷热数据分离”（将一些使用较少的历史数据迁移到其他的数据库中。而在业务功能上，通常默认只提供热点数据的查询），也是类似的实践。在高并发和海量数据的场景下，分库分表能够有效缓解单机和单库的性能瓶颈和压力，突破 IO、连接数、硬件资源的瓶颈。当然，投入的硬件成本也会更高。同时，这也会带来一些复杂的技术问题和挑战（例如：跨分片的复杂查询，跨分片事务等）。 水平分库分表将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。 水平分库分表切分规则 RANGE 从0到10000一个表，10001到20000一个表； HASH取模 一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。 地理区域 比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。 时间 按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。 唯一ID方案这个方案也很多，主流的有那么几种: 利用数据库自增ID 优点：最简单。 缺点：单点风险、单机性能瓶颈。 利用数据库集群并设置相应的步长（Flickr方案） 优点：高可用、ID较简洁。 缺点：需要单独的数据库集群。 Twitter Snowflake 优点：高性能高可用、易拓展。 缺点：需要独立的集群以及ZK。 一大波GUID、Random算法 优点：简单。 缺点：生成ID较长，有重复几率。 带有业务属性的方案： &gt; 时间戳+用户标识码+随机数 优点：方便、成本低。基本无重复的可能。自带分库规则，这里的用户标识码即为用户ID的后四位，在查询的场景下，只需要订单号就可以匹配到相应的库表而无需用户ID，只取四位是希望订单号尽可能的短一些，并且评估下来四位已经足够。可排序，因为时间戳在最前面。 缺点：比如长度稍长，性能要比int/bigint的稍差等。 数据迁移数据库拆分一般是业务发展到一定规模后的优化和重构，为了支持业务快速上线，很难一开始就分库分表，垂直拆分还好办，改改数据源就搞定了，一旦开始水平拆分，数据清洗就是个大问题，为此，我们经历了以下几个阶段。 第一阶段 数据库双写（事务成功以老模型为准），查询走老模型。 每日job数据对账（通过DW），并将差异补平。 通过job导历史数据。 第二阶段历史数据导入完毕并且数据对账无误。依然是数据库双写，但是事务成功与否以新模型为准，在线查询切新模型。每日job数据对账，将差异补平。 第三阶段 老模型不再同步写入，仅当订单有终态时才会异步补上。 此阶段只有离线数据依然依赖老的模型，并且下游的依赖非常多，待DW改造完就可以完全废除老模型了。 报表统计待我后续更新。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式应用监控]]></title>
    <url>%2F2019%2F02%2F18%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%BA%94%E7%94%A8%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[分布式应用监控分布式系统已经诞生了很长时间，现代互联网公司规模都变得异常庞大，系统也变得越来越复杂，给监控工作带来了极大的难度：海量日志数据如何处理，服务如何追踪，如何高效定位故障缩短故障时常，常见的监控手段可以分为集中式日志系统（Logging），集中式度量系统（Metrics）和分布式追踪系统（Tracing）。 集中式日志系统集中式日志系统，选取了最具代表性的ELK ElasticsearchElasticsearch是个开源的分布式搜索引擎，提供搜索、分析、存储数据三大功能。它的特点有：分布式、自动发现、索引自动分片、索引副本机制、RESTful 风格接口、多数据源以及自动搜索负载等。 LogstashLogstash 是一个开源的动态数据收集处理管道，它可以同时从多个源中提取数据，对其进行转换，并且拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。 KibanaKibana是一个开源的分析与可视化平台，设计出来用于和Elasticsearch一起使用的。你可以用kibana搜索、查看存放在Elasticsearch中的数据。Kibana与Elasticsearch的交互方式是各种不同的图表、表格、地图等，直观的展示数据，从而达到高级的数据分析与可视化的目的。 BeatsBeats 是 ELK Stack 技术栈中负责单一用途数据采集并推送给 Logstash 或 Elasticsearch 的轻量级产品。包括： Filebeats：应用于日志收集场景的实现。 Metricbeat：轻量级的系统级性能指标监控工具。 Packetbeat：轻量级的网络数据包分析工具。 Winlogbeat：轻量级的 Windows 事件日志收集工具。 Heartbeat：心跳检测工具，主要监控服务的可用性。 安装修改虚拟机的内存限制1vi /etc/sysctl.conf 加入1vm.max_map_count=262144 sysctl -p查看设置 docker安装ELK12docker pull sebp/elkdocker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -e ES_MIN_MEM=128m -e ES_MAX_MEM=1024m -it --name elk sebp/elk 输入网址http://&lt;your-host&gt;:5601可以看到下面的界面，则说明安装成功 配置使用1docker exec -it &lt;container-name&gt; /bin/bash 进入容器，执行命令1/opt/logstash/bin/logstash -e 'input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; ["localhost"] &#125; &#125;' 如果有错误信息1service logstash stop 当命令成功被执行后，看到：Successfully started Logstash API endpoint {:port=&gt;9600}信息后，输入：this is a dummy entry然后回车，模拟一条日志进行测试。 打开浏览器http://&lt;your-host&gt;:9200/_search?pretty，如图所示 打开浏览器，输入：http://&lt;your-host&gt;:5601 点击创建 看到如下界面，到此安装结束。 与java应用结合的日志分析系统可以通过Beats的Filebeats来实现，通过log4j将运行日志输出在文件中，通过Filebeats插件利用Logstash过滤并导入到Elasticsearch中，最后通过Kibana展示。 集中式度量系统PrometheusPrometheus是一个基于时间序列的数值数据的监控解决方案，这是一个开源项目，由前Google员工在SoundCloud启动，他们希望监控一个高度动态的容器环境，因为对传统的监控工具不甚满意，所以开发出Prometheus，并在上面进行工作。Prometheus解决了Devs如何监控高动态容器环境的问题。 例如我们想要获取所有的服务器上node_exporter暴露出来的数据，就必须有个程序去定时访问这些接口，如果想要增加或者修改这些接口，那么就需要有个配置文件来记录这些服务器的地址，如果想要访问历史的某个时间点的数据，那么就必须按照时间顺序存储获取到的指标和值。而如果想要将值绘制成图，也需要有代码去查询、计算和渲染。最后你可能还希望当服务器的某个指标超过一定的阈值时，向指定的接口发出告警信息。一切的一切其实都可以使用Prometheus来解决。 Prometheus检测mysql相关指标前提：本地安装了mysql 安装node-exporter12docker pull node-exporterdocker run -d -p 9100:9100 --cap-add SYS_TIME --net="host" --pid="host" -v "/:/host:ro,rslave"quay.io/prometheus/node-exporter --cap-add=SYS_TIME --path.rootfs /host 安装mysqld-exporter通过mysql命令界面创建相应角色并赋予权限12CREATE USER 'mysql_monitor'@'localhost' IDENTIFIED BY 'XXXXXXXX' WITH MAX_USER_CONNECTIONS 3;GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'mysql_monitor'@'localhost'; docker安装12docker pull mysqld-exporterdocker run -d -p 9104:9104 -e DATA_SOURCE_NAME="mysql_monitor:root@(127.0.0.1:3306)/" prom/mysqld-exporter 安装Prometheus创建文件prometheus.yml12345678910111213141516171819202122global: scrape_interval: 60s evaluation_interval: 60sscrape_configs: - job_name: prometheus static_configs: - targets: ['106.15.226.184:9090'] labels: instance: prometheus - job_name: linux static_configs: - targets: ['106.15.226.184:9100'] labels: instance: db1 - job_name: mysql static_configs: - targets: ['106.15.226.184:9104'] labels: instance: db1 docker启动12docker pull prometheussudo docker run -d -p 9090:9090 -v /root/conf/prometheus.yml:/usr/local/src/file/prometheus.yml quay.io/prometheus/prometheus --config.file=/usr/local/src/file/prometheus.yml 安装Grafana12docker pull grafana/grafanadocker run -d --name=grafana -p 3000:3000 grafana/grafana 打开http:x.x.x.x:9090如图所示，说明数据源管道agent启动成功 打开http://x.x.x.x:3000，配置Prometheus数据源 配置好数据源后，下载mysql监控模板，解压后，找到mysql开头的模板，导入，最后如图所示： CatCAT（Central Application Tracking）是一个实时和接近全量的监控系统，它侧重于对Java应用的监控，基本接入了美团上海侧所有核心应用。目前在中间件（MVC、RPC、数据库、缓存等）框架中得到广泛应用，为美团各业务线提供系统的性能指标、健康状况、监控告警等。 监控整体要求就是快速发现故障、快速定位故障以及辅助进行程序性能优化。为了做到这些，我们对监控系统的一些非功能做了如下的要求： 实时处理：信息的价值会随时间锐减，尤其是事故处理过程中。全量数据：最开始的设计目标就是全量采集，全量的好处有很多。高可用：所有应用都倒下了，需要监控还站着，并告诉工程师发生了什么，做到故障还原和问题定位。故障容忍：CAT本身故障不应该影响业务正常运转，CAT挂了，应用不该受影响，只是监控能力暂时减弱。高吞吐：要想还原真相，需要全方位地监控和度量，必须要有超强的处理吞吐能力。可扩展：支持分布式、跨IDC部署，横向扩展的监控系统。不保证可靠：允许消息丢失，这是一个很重要的trade-off，目前CAT服务端可以做到4个9的可靠性，可靠系统和不可靠性系统的设计差别非常大。CAT从开发至今，一直秉承着简单的架构就是最好的架构原则，主要分为三个模块：CAT-client、CAT-consumer、CAT-home。 Cat-client 提供给业务以及中间层埋点的底层SDK。Cat-consumer 用于实时分析从客户端提供的数据。Cat-home 作为用户给用户提供展示的控制端。在实际开发和部署中，Cat-consumer和Cat-home是部署在一个JVM内部，每个CAT服务端都可以作为consumer也可以作为home，这样既能减少整个层级结构，也可以增加系统稳定性。上图是CAT目前多机房的整体结构图，图中可见： 路由中心是根据应用所在机房信息来决定客户端上报的CAT服务端地址，目前美团有广州、北京、上海三地机房。每个机房内部都有独立的原始信息存储集群HDFS。CAT-home可以部署在一个机房也可以部署在多个机房，在最后做展示的时候，home会从consumer中进行跨机房的调用，将所有的数据合并展示给用户。实际过程中，consumer、home以及路由中心都是部署在一起的，每个服务端节点都可以充当任何一个角色。 安装使用Cat本文演示单机集群安装部署123git clone https://github.com/dianping/cat.gitcd dockerdocker-compose up 第一次运行以后，数据库中没有表结构，需要通过下面的命令创建表：1docker exec &lt;container_id&gt; bash -c "mysql -uroot -Dcat &lt; /init.sql" 依赖配置说明 datasources.xml CAT数据库配置，默认配置是mysql镜像，可以按需替换 docker-compose.yml 通过docker-compose启动的编排文件，文件中包含cat和mysql。可以屏蔽掉mysql的部分，并且修改cat的环境变量，改为真实的mysql连接信息。 client.xml CAT 初始化默认的路由列表，配置此文件可以将客户端数据上报指向到不同环境。 datasources.sh 辅助脚本，脚本作用时修改datasources.xml，使用环境变量中制定的mysql连接信息。（通过sed命令替换） Java 应用的集成参考博客需要指定 cat 专用的远程仓库123456789101112131415161718192021222324&lt;!-- %MAVEN_HOME%\conf\settings.xml --&gt;&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;url&gt;http://repo1.maven.org/maven2&lt;/url&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;unidal.nexus&lt;/id&gt; &lt;url&gt;http://unidal.org/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 加入依赖(pom.xml)1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.dianping.cat&lt;/groupId&gt; &lt;artifactId&gt;cat-client&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加过滤器 CatFilter123456789101112@Configurationpublic class CatFilterConfigure &#123; @Bean public FilterRegistrationBean catFilter() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new CatFilter()); registration.addUrlPatterns("/*"); registration.setName("cat-filter"); registration.setOrder(1); return registration; &#125;&#125; 添加注解12345678910@CatCacheTransactionpublic void test() &#123;&#125;@ResponseBody@RequestMapping("/hello")@CatHttpRequestTransaction(type = "URL", name = "/hello")public String hello() &#123; return "hello!";&#125; 更多集成 管理平台的使用控制台http://192.168.126.101:8080/cat帐号/密码: catadmin/catadmin 项目配置http://192.168.126.101:8080/cat/s/config?op=projects 相关文档部署文档: http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=deploy用户文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=user告警文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=alert集成文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=integration开发文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=develop设计文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=design常见问题：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=problem 实时查看http://192.168.126.101:8080/cat/r/t 分布式追踪系统ZipkinZipkin是一种分布式跟踪系统。它有助于收集解决微服务架构中的延迟问题所需的时序数据。它管理这些数据的收集和查找。Zipkin的设计基于Google Dapper论文。应用程序用于向Zipkin报告时序数据。Zipkin UI还提供了一个依赖关系图，显示了每个应用程序通过的跟踪请求数。如果要解决延迟问题或错误，可以根据应用程序，跟踪长度，注释或时间戳对所有跟踪进行筛选或排序。选择跟踪后，您可以看到每个跨度所需的总跟踪时间百分比，从而可以识别问题应用程序。 共有四个组件构成了 Zipkin： collector storage search web UI Zipkin Collector 一旦追踪数据抵达 Zipkin Collector 守护进程，Zipkin Collector 为了查询，会对其进行校验、存储和索引。 Storage Zipkin 最初是构建在将数据存储在 Cassandra 中，因为 Cassandra 易跨站，支持灵活的 schema，并且在 Twitter 内部被大规模使用。然而，我们将这个组件做成了可插拔式的。在 Cassandra 之外，我们原生支持 ElasticSearch 和 MySQL。可作为第三方扩展提供给其它后端。 Zipkin 查询服务 一旦数据被存储索引，我们就需要一种方式提取它。查询守护进程提供了一个简单的 JSON API 查询和获取追踪数据。API 的主要消费者就是 Web UI。 Web UI 我们创建了一个用户图形界面为追踪数据提供了一个漂亮的视图。Web UI 提供了基于服务、时间和标记（annotation）查看追中数据的方法。注意：UI 没有内置的身份认证功能。 安装部署参考前提条件：已经安装好ElasticSearch 安装zookeeper和kafka123docker pull wurstmeister/zookeeper docker pull wurstmeister/kafka 启动镜像12345docker run -d --name zookeeper --publish 2181:2181 --volume /etc/localtime:/etc/localtime zookeeper:latestdocker run -d --name kafka --publish 9092:9092 --link zookeeper --env KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 --env KAFKA_ADVERTISED_HOST_NAME=kafka所在宿主机的IP --env KAFKA_ADVERTISED_PORT=9092 --volume /etc/localtime:/etc/localtime wurstmeister/kafka:latestdocker run -d --name zipkin-server -p 9411:9411 -e "KAFKA_BOOTSTRAP_SERVERS=your-kafka-address" -e "STORAGE_TYPE=elasticsearch" -e "ES_HOSTS=your-es-host" -e "ES_INDEX=zipkin" -e "ES_INDEX_SHARDS=1" -e "ES_INDEX_REPLICAS=1" zipkin:latest 使用用maven新建springboot项目引入依赖，包括Spring Cloud Sleuth和Kafka传输的支持依赖Spring Stream Kafak以及web依赖。1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置12345678910spring: application: name: service-producer # 配置应用名称 kafka: bootstrap-servers: localhost:9092 # 缓冲kafka地址 sleuth: sampler: percentage: 1 # 设置采样频率，默认为0.1，设置为全采样，便于观测，实际项目中根据具体情况设置server: port: 8080 类似的方法再新建一个项目然后写一个接口进行2个服务之间的通讯，触发调用链，可以在http://localhost:9411查看如下效果图：需要注意的是，我们使用的存储模块是ES，所以一段时间内的服务调用关系图是无法直接得到的（使用内存存储可以直接得到）。我们需要使用Zipkin官方提供的zipkin-dependencies来生成依赖关系图。12# ex to run the job to process yesterday's traces on OS/X$ STORAGE_TYPE=elasticsearch ES_HOSTS=your-es-host ES_INDEX=zipkin ES_NODES_WAN_ONLY=true java -jar zipkin-dependencies.jar `date -uv-1d +%F` PinpointPinpoint是一个开源的APM监控工具，我们可以通过pinpoint实时跟踪应用之间的调用、程序的响应时间以及服务器资源使用状态，可以在分布式环境中为没个调用生成代码级别的可视图并定位瓶颈点和失败点。Pinpoint的设计也是基于Google Dapper论文 安装部署参考123git clone https://github.com/naver/pinpoint-docker.gitcd Pinpoint-Dockerdocker-compose pull &amp;&amp; docker-compose up -d 如有问题，请修改相对路径为绝对路径12345... volumes: - /home/pinpoint/hbase - /home/pinpoint/zookeeper... 启动镜像,访问http://x.x.x.x:8079/hbase页面 http://x.x.x.x:16010/ SkywalkingSkywalking是一款优秀的国产 APM 工具，包括了分布式追踪、性能指标分析、应用和服务依赖分析等。通过在应用程序中添加 SkyWalking Agent，就可以将接口、服务、数据库、MQ等进行追踪，将追踪结果通过 HTTP 或 gRPC 发送到 SkyWalking Collecter，SkyWalking Collecter 经过分析和聚合，将结果存储到 Elasticsearch 或 H2，SkyWalking 同时提供了一个 SkyWalking UI 的可视化界面，UI 以 GraphQL + HTTP 方式获取存储数据进行展示。 安装部署参考博客 使用拷贝apache-skywalking-apm-incubating目录下的agent目录到应用程序位置，探针包含整个目录，请不要改变目录结构 java程序启动时，增加JVM启动参数，-javaagent:/path/to/agent/skywalking-agent.jar。参数值为skywalking-agent.jar的绝对路径 agent探针配置，简单修改下agent.application_code即可1234567891011121314151617181920212223242526272829303132# 当前的应用编码，最终会显示在webui上。# 建议一个应用的多个实例，使用有相同的application_code。请使用英文agent.application_code=Your_ApplicationName# 每三秒采样的Trace数量# 默认为负数，代表在保证不超过内存Buffer区的前提下，采集所有的Trace# agent.sample_n_per_3_secs=-1# 设置需要忽略的请求地址# 默认配置如下# agent.ignore_suffix=.jpg,.jpeg,.js,.css,.png,.bmp,.gif,.ico,.mp3,.mp4,.html,.svg# 探针调试开关，如果设置为true，探针会将所有操作字节码的类输出到/debugging目录下# skywalking团队可能在调试，需要此文件# agent.is_open_debugging_class = true# 对应Collector的config/application.yml配置文件中 agent_server/jetty/port 配置内容# 例如：# 单节点配置：SERVERS="127.0.0.1:8080" # 集群配置：SERVERS="10.2.45.126:8080,10.2.45.127:7600" collector.servers=127.0.0.1:10800# 日志文件名称前缀logging.file_name=skywalking-agent.log# 日志文件最大大小# 如果超过此大小，则会生成新文件。# 默认为300Mlogging.max_file_size=314572800# 日志级别，默认为DEBUG。logging.level=DEBUG 一切正常的话，稍后就可以在skywalking ui看到了。 JaegerUber开源的Jaeger用于监控和排除基于微服务的分布式系统，包括： 分布式上下文传播 分布式事务监控 根本原因分析 服务依赖性分析 性能/延迟优化 安装部署all-in-one 是Uber官方打包好的镜像，可以直接部署使用，但是只能用于测试环境，不能用于线上，因为它把数据放入了内存。 12docker run -d -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p5775:5775/udp -p6831:6831/udp -p6832:6832/udp \ -p5778:5778 -p16686:16686 -p14268:14268 -p9411:9411 jaegertracing/all-in-one:latest 通过 http://localhost:16686 可以在浏览器查看 Jaeger的后台 正常安装参考 使用参考 分布式链路追踪技术对比来自博文 cat由大众点评开源，基于Java开发的实时应用监控平台，包括实时应用监控，业务监控 。 集成方案是通过 代码埋点的方式来实现监控，比如： 拦截器，注解，过滤器等。 对代码的侵入性很大，集成成本较高。支持技术栈： dubbo spring mvc ,spring aop ,springmvc-url spring boot mybatis log4j , logback playframework http请求 风险较大。 zipkin由Twitter团队开源， Zipkin是一个分布式的跟踪系统。它有助于收集数据需要解决潜在的问题在市微服架构的时机。它管理数据的收集和查找 . 该产品结合spring-cloud-sleuth使用较为简单， 集成很方便。 但是功能较简单。 支持技术栈： spring cloud 以上是结合spring-cloud-sleuth支持的技术栈 pinpoint由韩国团队naver团队开源，针对大规模分布式系统用链路监控，使用java写的工具。灵感来自短小精悍，帮助分析系统的总 体结构和内部组件如何被调用在分布式应用提供了一个很好的解决方案。 使用java探针字节码增加技术，实现对整个应用的监控 。 对应用零侵入 支持技术栈： Tomcat 6+,Jetty 8/9,JBoss 6,Resin 4,Websphere 6+,Vertx 3.3+ Spring, Spring Boot (Embedded Tomcat, Jetty) HTTP Client 3.x/4.x, HttpConnector, GoogleHttpClient, OkHttpClient, NingAsyncHttpClient Thrift, Dubbo mysql, oracle, mssql, cubrid,PostgreSQL, maria arcus, memcached, redis, cassandra MyBatis DBCP, DBCP2, HIKARICP gson, Jackson, Json Lib log4j, Logback skywalking2015年由个人吴晟（华为开发者）开源 ， 2017年加入Apache孵化器。 针对分布式系统的应用性能监控系统，特别针对微服务、cloud native和容器化(Docker, Kubernetes, Mesos)架构， 其核心是个分布式追踪系统。 使用java探针字节码增加技术，实现对整个应用的监控 。对应用零侵入 支持技术栈 Tomcat7+ , resin3+, jetty spring boot ,spring mvc strtuts2 spring RestTemplete ,spring-cloud-feign okhttp , httpClient msyql ,oracle , H2 , sharding-jdbc,PostgreSQL dubbo,dubbox ,motan, gRpc , rocketMq , kafla redis, mongoDB,memcached , elastic-job , Netflix Eureka , Hystric 总结模拟了三种并发用户：500，750，1000。使用jmeter测试，每个线程发送30个请求，设置思考时间为10ms。使用的采样率为1，即100%，这边与生产可能有差别。 pinpoint默认的采样率为20，即50%，通过设置agent的配置文件改为100%。zipkin默认也是1。组合起来，一共有12种。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TestNG测试框架与rest-assured结合]]></title>
    <url>%2F2019%2F01%2F24%2FTestNG%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%E4%B8%8Erest-assured%E7%BB%93%E5%90%88%2F</url>
    <content type="text"><![CDATA[TestNG官网 TestNG简介 TestNG是一个受JUnit和NUnit启发的测试框架，但引入了一些新功能，使其功能更强大，相对于JUnit来说，xml的配置使的testNG对于不同测试之间的依赖程度有更好的把控性。 rest-assured简介在Java中测试和验证REST服务比在Ruby和Groovy等动态语言中更难。REST Assured将使用这些语言的简单性带入了Java域。 TestNG测试框架与rest-assured结合项目地址：https://github.com/dinghuang/testNGExample 上面实现了模拟用户登录以及rest-assured的高级用法，同时可以通过命令行直接生成报告，报告中对http请求增加了过滤，会在报告中展示请求信息，可以通过xml解析直接获取，还实现了多个suit通过mvn命令直接运行。目前在Choerodon中已经增加了TestNG的支持，用户可以直接推到gitlab，gitlab中的runner会在ci中打包并运行测试jar包，把报告解析并提取请求信息生成测试用例。 项目的关键代码就不一一说了，项目中有注释，不懂的+我VX:742041978]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes学习（一）之认识Kubernetes]]></title>
    <url>%2F2019%2F01%2F12%2FKubernetes%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E8%AE%A4%E8%AF%86Kubernetes%2F</url>
    <content type="text"><![CDATA[Kubernetes学习（一）之认识KubernetesKubernetes概念简介Kubernetes是一个跨主机集群的 开源的容器调度平台，它可以自动化应用容器的部署、扩展和操作 , 提供以容器为中心的基础架构。结合docker可以提供持续开发，持续部署的功能，我现在所从事开发的Choerodon就是基于这一套架构开发的企业级数字服务平台，具有敏捷化的应用交付和自动化的运营管理的特点。这里介绍的版本是v1.13 新的方式是通过部署容器方式实现，每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。相对于虚拟机，容器能快速部署，由于容器与底层设施、机器文件系统解耦的，所以它能在不同云、不同版本操作系统间进行迁移。 容器占用资源少、部署快，每个应用可以被打包成一个容器镜像，每个应用与容器间成一对一关系也使容器有更大优势，使用容器可以在build或release 的阶段，为应用创建容器镜像，因为每个应用不需要与其余的应用堆栈组合，也不依赖于生产环境基础结构，这使得从研发到测试、生产能提供一致环境。类似地，容器比虚机轻量、更“透明”，这更便于监控和管理。 组件 Master组件Kubernetes 主要由以下几个核心（Master）组件组成，Master组件提供集群的管理控制中心。Master组件可以在集群中任何节点上运行。但是为了简单起见，通常在一台VM/机器上启动所有Master组件，并且不会在此VM/机器上运行用户容器。请参考构建高可用群集以来构建multi-master-VM。 kube-apiserverkube-apiserver。 etcdetcd是Kubernetes提供默认的存储系统，保存所有集群数据，使用时需要为etcd数据提供备份计划。 kube-scheduler主服务器上的组件，用于监视未创建节点的新创建的pod，并选择一个节点供其运行。 调度决策所考虑的因素包括个人和集体资源需求，硬件/软件/策略约束，亲和力和反亲和性规范，数据位置，工作负载间干扰和最后期限。 kube-controller-managerkube-controller-manager运行管理控制器，它们是集群中处理常规任务的后台线程。逻辑上，每个控制器是一个单独的进程，但为了降低复杂性，它们都被编译成单个二进制文件，并在单个进程中运行。负责维护集群的状态，比如故障检测、自动扩展、滚动更新等。 这些控制器包括： 节点（Node）控制器。 副本（Replication）控制器：负责维护系统中每个副本中的pod。 端点（Endpoints）控制器：填充Endpoints对象（即连接Services＆Pods）。- Service Account和Token控制器：为新的Namespace 创建默认帐户访问API Token。 cloud-controller-manager云控制器管理器负责与底层云提供商的平台交互。云控制器管理器是Kubernetes版本1.6中引入的，目前还是Alpha的功能。 云控制器管理器仅运行云提供商特定的（controller loops）控制器循环。可以通过将--cloud-provider flag设置为external启动kube-controller-manager ，来禁用控制器循环。 cloud-controller-manager 具体功能： 节点（Node）控制器 路由（Route）控制器 Service控制器 卷（Volume）控制器 节点（Node）组件节点组件运行在Node，提供Kubernetes运行时环境，以及维护Pod。 kubeletkubelet是主要的节点代理，它会监视已分配给节点的pod，负责维护容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理，具体功能： 安装Pod所需的volume。 下载Pod的Secrets。 Pod中运行的 docker（或experimentally，rkt）容器。 定期执行容器健康检查。 通过在必要时创建镜像pod，将pod状态报告回系统的其余部分。 将节点的状态返回到系统的其余部分。 kube-proxykube-proxy通过在主机上维护网络规则并执行连接转发来实现Kubernetes服务抽象。负责为 Service 提供 cluster 内部的服务发现和负载均衡。 Container Runtime容器运行时是负责运行容器的软件。 Kubernetes支持多种运行时：Docker，rkt，runc和任何OCI运行时规范实现。 插件插件（addon）是实现集群pod和Services功能的 。PodDeployments，ReplicationController等进行管理。Namespace 插件对象是在kube-system Namespace中创建。有关可用插件的扩展列表，请参阅插件。 DNS虽然不严格要求使用插件，但Kubernetes集群都应该具有DNS集群。群集 DNS是一个DNS服务器，能够为 Kubernetes services提供 DNS记录。由Kubernetes启动的容器自动将这个DNS服务器包含在他们的DNS searches中。 用户界面仪表板是Kubernetes集群的基于Web的通用UI。它允许用户管理和解决群集中运行的应用程序以及群集本身。 容器资源监测容器资源监控提供一个UI浏览监控数据。 Cluster-level LoggingCluster-level logging，负责保存容器日志，搜索/查看日志。 supervisordsupervisord是一个轻量级的监控系统，用于保障kubelet和docker运行。 fluentdfluentd是一个守护进程，可提供cluster-level logging。 The Kubernetes APIAPI约定文档中描述了总体API约定 API参考中描述了API端点，资源类型和示例。 Controlling API Access文档中讨论了对API的远程访问。 Kubernetes API还可用作系统声明性配置架构的基础。 kubectl命令行工具可用于创建，更新，删除和获取API对象。 Kubernetes还根据API资源存储其序列化状态（当前在etcd中）。 Kubernetes本身被分解为多个组件，通过其API进行交互。 API更改 OpenAPI和Swagger定义 API版本控制 API组 启用API组 启用组中的资源 API更改根据我们的经验，任何成功的系统都需要随着新用例的出现或现有用例的变化而增长和变化。因此，我们希望Kubernetes API能够不断变化和发展。但是，我们打算在很长一段时间内不破坏与现有客户端的兼容性。通常，可以预期频繁添加新的API资源和新的资源字段。消除资源或字段将需要遵循API弃用策略。 OpenAPI和Swagger定义使用OpenAPI记录完整的API详细信息。 从Kubernetes 1.10开始，Kubernetes API服务器通过/openapi/ v2端点提供OpenAPI规范。通过设置HTTP标头指定请求的格式： Header Possible Values Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for / or not passing this header) Accept-Encoding gzip (not passing this header is acceptable) 在1.14之前，格式分离的端点（/swagger.json,/swagger-2.0.0.json,/swagger-2.0.0.pb-v1,/swagger-2.0.0.pb-v1.gz）为OpenAPI提供服务不同格式的规范。这些端点已弃用，将在Kubernetes 1.14中删除。 获取OpenAPI规范的示例： Before 1.10 Starting with Kubernetes 1.10 GET /swagger.json GET /openapi/v2 Accept: application/json GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip Kubernetes为API实现了另一种基于Protobuf的序列化格式，主要用于集群内通信，在设计提案中有记录，每个模式的IDL文件都位于定义API对象的Go包中。 在1.14之前，Kubernetes apiserver还公开了一个API，可用于检索/ swaggerapi上的Swagger v1.2 Kubernetes API规范。该端点已弃用，将在Kubernetes 1.14中删除。 API版本控制为了更容易消除字段或重构资源表示，Kubernetes支持多个API版本，每个API版本位于不同的API路径，例如/api/v1或/apis/extensions/v1beta1。 我们选择在API级别而不是在资源或字段级别进行版本化，以确保API提供清晰，一致的系统资源和行为视图，并允许控制对生命末端和/或实验API的访问。 JSON和Protobuf序列化模式遵循相同的模式更改指南 - 以下所有描述都涵盖两种格式。 请注意，API版本控制和软件版本控制仅间接相关。 API和发布版本控制提议描述了API版本控制和软件版本控制之间的关系。 不同的API版本意味着不同级别的稳定性和支持。 API更改文档中更详细地描述了每个级别的标准。他们总结在这里： Alpha level: 版本名称包含alpha（例如v1alpha1）。 可能是马车。启用该功能可能会暴露错误。默认情况下禁用。 可随时删除对功能的支持，恕不另行通知。 API可能会在以后的软件版本中以不兼容的方式更改，恕不另行通知。 由于错误风险增加和缺乏长期支持，建议仅在短期测试集群中使用。 Beta level:: 版本名称包含beta（例如v2beta3）。 代码经过了充分测试。启用该功能被认为是安全的。默认情况下启用。 虽然细节可能会有所变化，但不会删除对整体功能的支持。 在随后的beta版或稳定版中，对象的模式和/或语义可能以不兼容的方式发生变化。发生这种情况时，我们将提供迁移到下一版本的说明。这可能需要删除，编辑和重新创建API对象。编辑过程可能需要一些思考。对于依赖该功能的应用程序，这可能需要停机时间。 建议仅用于非关键业务用途，因为后续版本中可能存在不兼容的更改。如果您有多个可以独立升级的群集，您可以放宽此限制。 请尝试我们的测试版功能并提供反馈！一旦他们退出测试版，我们可能无法进行更多更改。 Stable level: 该版本名称是vX这里X是一个整数。 许多后续版本的已发布软件中将出现稳定版本的功能。 API组为了更容易扩展Kubernetes API，我们实现了API组。API组在REST路径和apiVersion序列化对象的字段中指定。 目前有几个API组正在使用中： 核心组，常常被称为遗留组，是在REST路径/api/v1和用途apiVersion: v1。 命名组处于REST路径/apis/$GROUP_NAME/$VERSION，并使用apiVersion: $GROUP_NAME/$VERSION （例如apiVersion: batch/v1）。在Kubernetes API参考中可以看到支持的API组的完整列表。 使用自定义资源扩展API有两种受支持的路径： CustomResourceDefinition 适用于具有非常基本CRUD需求的用户。 需要完整Kubernetes API语义的用户可以实现自己的apiserver并使用聚合器 使其无缝地为客户端。 启用API组默认情况下启用某些资源和API组。可以通过设置--runtime-config apiserver 来启用或禁用它们。--runtime-config接受逗号分隔值。例如：要禁用批处理/ v1，请设置 --runtime-config=batch/v1=false，以启用批处理/ v2alpha1，设置--runtime-config=batch/v2alpha1。该标志接受逗号分隔的一组key = value对，描述了apiserver的运行时配置。 重要信息：启用或禁用组或资源需要重新启动apiserver和controller-manager以获取--runtime-config更改。 启用组中的资源默认情况下启用DaemonSet，Deployments，HorizontalPodAutoscalers，Ingresses，Jobs和ReplicaSet。可以通过设置--runtime-configapiserver 来启用其他扩展资源。--runtime-config接受逗号分隔值。例如：要禁用部署和入口，请设置 --runtime-config=extensions/v1beta1/deployments=false,extensions/v1beta1/ingresses=false 与Kubernetes对象一起工作了解Kubernetes对象了解Kubernetes对象Kubernetes对象是Kubernetes系统中的持久实体。Kubernetes使用这些实体来表示集群的状态。具体来说，他们可以描述： 容器化应用正在运行(以及在哪些节点上) 这些应用可用的资源 关于这些应用如何运行的策略，如重新策略，升级和容错Kubernetes对象是“record of intent”，一旦创建了对象，Kubernetes系统会确保对象存在。通过创建对象，可以有效地告诉Kubernetes系统你希望集群的工作负载是什么样的。 要使用Kubernetes对象（无论是创建，修改还是删除），都需要使用Kubernetes API。例如，当使用kubectl命令管理工具时，CLI会为提供Kubernetes API调用。你也可以直接在自己的程序中使用Kubernetes API，您还可以使用其中一个客户端库在您自己的程序中直接使用Kubernetes API。 对象（Object）规范和状态每个Kubernetes对象都包含两个嵌套对象字段，用于管理Object的配置：Object Spec和Object Status。Spec描述了对象所需的状态 - 希望Object具有的特性，Status描述了对象的实际状态，并由Kubernetes系统提供和更新。 例如，通过Kubernetes Deployment 来表示在集群上运行的应用的对象。创建Deployment时，可以设置Deployment Spec，来指定要运行应用的三个副本。Kubernetes系统将读取Deployment Spec，并启动你想要的三个应用实例 - 来更新状态以符合之前设置的Spec。如果这些实例中有任何一个失败（状态更改），Kuberentes系统将响应Spec和当前状态之间差异来调整，这种情况下，将会开始替代实例。 有关object spec、status和metadata更多信息，请参考“Kubernetes API Conventions”。 描述Kubernetes对象在Kubernetes中创建对象时，必须提供描述其所需Status的对象Spec，以及关于对象（如name）的一些基本信息。当使用Kubernetes API创建对象（直接或通过kubectl）时，该API请求必须将该信息作为JSON包含在请求body中。通常，可以将信息提供给kubectl .yaml文件，在进行API请求时，kubectl将信息转换为JSON。 以下示例是一个.yaml文件，显示Kubernetes Deployment所需的字段和对象Spec：1234567891011121314151617181920#application/deployment.yamlapiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用上述.yaml文件创建Deployment，是通过在kubectl中使用kubectl create命令来实现。将该.yaml文件作为参数传递。如下例子：12$ kubectl create -f https://k8s.io/examples/application/deployment.yaml --recorddeployment.apps/nginx-deployment created 必填字段对于要创建的Kubernetes对象的yaml文件，需要为以下字段设置值： apiVersion - 创建对象的Kubernetes API 版本 kind - 要创建什么样的对象？ metadata- 具有唯一标示对象的数据，包括 name（字符串）、UID和Namespace（可选项）您还需要提供对象规范字段。对象规范的精确格式对于每个Kubernetes对象都是不同的，并且包含特定于该对象的嵌套字段。 Kubernetes API Reference可以帮助您找到可以使用Kubernetes创建的所有对象的规范格式。例如，可以在此处找到Pod对象的spec格式，可以在此处找到Deployment对象的spec格式。 nameKubernetes REST API中的所有对象都由Name和UID明确标识。 对于非唯一的用户提供的属性，Kubernetes提供标签和注释。 有关名称和UID的精确语法规则，请参阅标识符设计文档。 Names UIDs Names客户端提供的字符串，用于引用资源URL中的对象，例如/api/v1/pods/some-name。 只有给定类型的一个对象一次可以有一个给定的名称。但是，如果删除该对象，则可以创建具有相同名称的新对象。 按照惯例，Kubernetes资源的名称应最多为253个字符，并且由小写字母数字字符组成-，并且.，但某些资源具有更具体的限制。 UIDsKubernetes系统生成的字符串，用于唯一标识对象。 在Kubernetes集群的整个生命周期中创建的每个对象都具有不同的UID。它旨在区分类似实体的历史事件。 NamespacesKubernetes支持由同一物理集群支持的多个虚拟集群。这些虚拟集群称为名称空间。 何时使用多个命名空间 使用命名空间 命名空间和DNS 并非所有对象都在命名空间中 何时使用多个命名空间命名空间旨在用于多个用户分布在多个团队或项目中的环境中。对于具有几个到几十个用户的集群，您根本不需要创建或考虑名称空间。当您需要它们提供的功能时，请开始使用命名空间。 命名空间提供名称范围。资源名称在名称空间中必须是唯一的，而不是跨名称空间。 命名空间是一种在多个用户之间划分群集资源的方法（通过资源配额）。 在Kubernetes的未来版本中，默认情况下，同一名称空间中的对象将具有相同的访问控制策略。 没有必要使用多个名称空间来分隔略有不同的资源，例如同一软件的不同版本：使用标签来区分同一名称空间中的资源。 使用命名空间名称空间的管理指南文档中描述了名称空间的创建和删除。 查看名称空间您可以使用以下命令列出集群中的当前名称空间：12345$ kubectl get namespacesNAME STATUS AGEdefault Active 1dkube-system Active 1dkube-public Active 1d Kubernetes以三个初始名称空间开头： default 没有其他命名空间的对象的默认命名空间 kube-system Kubernetes系统创建的对象的命名空间 kube-public此命名空间是自动创建的，并且所有用户（包括未经过身份验证的用户）都可以读取。此命名空间主要用于群集使用，以防某些资源在整个群集中可见且可公开读取。此命名空间的公共方面只是一个约定，而不是一个要求。 设置请求的命名空间要临时设置请求的命名空间，请使用该--namespace标志。 例如：12$ kubectl --namespace=&lt;insert-namespace-name-here&gt; run nginx --image=nginx$ kubectl --namespace=&lt;insert-namespace-name-here&gt; get pods 设置命名空间首选项您可以在该上下文中为所有后续kubectl命令永久保存命名空间。 123$ kubectl config set-context $(kubectl config current-context) --namespace=&lt;insert-namespace-name-here&gt;# Validate it$ kubectl config view | grep namespace: 命名空间和DNS创建服务时，它会创建相应的DNS条目。此条目是表单&lt;service-name&gt;.&lt;namespace-name&gt;.svc.cluster.local，这意味着如果容器只是使用&lt;service-name&gt;，它将解析为命名空间本地的服务。这对于在多个名称空间（如开发，分段和生产）中使用相同的配置非常有用。如果要跨命名空间访问，则需要使用完全限定的域名（FQDN）。 并非所有对象都在命名空间中大多数Kubernetes资源（例如pod，服务，复制控制器等）都在某些名称空间中。但是，命名空间资源本身并不在命名空间中。并且低级资源（例如节点和persistentVolumes）不在任何名称空间中。 要查看哪些Kubernetes资源在命名空间中，哪些不在：12345# In a namespace$ kubectl api-resources --namespaced=true# Not in a namespace$ kubectl api-resources --namespaced=false Labels and Selectors标签是附加到对象（例如pod）的键/值对。标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接暗示核心系统的语义。标签可用于组织和选择对象的子集。标签可以在创建时附加到对象，随后可以随时添加和修改。每个对象都可以定义一组键/值标签。每个Key对于给定对象必须是唯一的。123456"metadata": &#123; "labels": &#123; "key1" : "value1", "key2" : "value2" &#125;&#125; 标签允许高效的查询和监视，非常适合在UI和CLI中使用。应使用注释记录非识别信息。 动机 语法和字符集 标签选择器 API 动机标签使用户能够以松散耦合的方式将他们自己的组织结构映射到系统对象，而无需客户端存储这些映射。 服务部署和批处理流水线通常是多维实体（例如，多个分区或部署，多个释放轨道，多个层，每层多个微服务）。管理通常需要交叉操作，这打破了严格的层次表示的封装，特别是由基础设施而不是用户确定的严格的层次结构。 示例标签： &quot;release&quot; : &quot;stable&quot;，&quot;release&quot; : &quot;canary&quot; &quot;environment&quot; : &quot;dev&quot;，&quot;environment&quot; : &quot;qa&quot;，&quot;environment&quot; : &quot;production&quot; &quot;tier&quot; : &quot;frontend&quot;，&quot;tier&quot; : &quot;backend&quot;，&quot;tier&quot; : &quot;cache&quot; &quot;partition&quot; : &quot;customerA&quot;， &quot;partition&quot; : &quot;customerB&quot; &quot;track&quot; : &quot;daily&quot;， &quot;track&quot; : &quot;weekly&quot;这些只是常用标签的例子; 你可以自由地制定自己的约定。请记住，标签Key对于给定对象必须是唯一的。 语法和字符集标签是键/值对。有效标签键有两个段：可选前缀和名称，用斜杠（/）分隔。名称段是必需的，必须是63个字符或更少，以字母数字字符（[a-z0-9A-Z]）开头和结尾，带有破折号（-），下划线（_），点（.）和字母数字之间。前缀是可选的。如果指定，前缀必须是DNS子域：由点（.）分隔的一系列DNS标签，总共不超过253个字符，后跟斜杠（/）。 如果省略前缀，则假定标签Key对用户是私有的。自动化系统组件（例如kube-scheduler，kube-controller-manager，kube-apiserver，kubectl，或其他第三方自动化），它添加标签终端用户对象都必须指定一个前缀。 在kubernetes.io/和k8s.io/前缀保留给Kubernetes核心组件。 有效标签值必须为63个字符或更少，并且必须为空或以字母数字字符（[a-z0-9A-Z]）开头和结尾，并带有短划线（-），下划线（_），点（.）和字母数字。 标签选择器与名称和UID不同，标签不提供唯一性。通常，我们希望许多对象携带相同的标签。 通过标签选择器，客户端/用户可以识别一组对象。标签选择器是Kubernetes中的核心分组原语。 目前，API支持两种类型的选择：基于平等，和基于集的。标签选择器可以由逗号分隔的多个要求组成。在多个要求的情况下，必须满足所有要求，因此逗号分隔符充当逻辑AND（&amp;&amp;）运算符。 空或非指定选择器的语义取决于上下文，使用选择器的API类型应记录它们的有效性和含义。 注意：对于某些API类型（例如ReplicaSet），两个实例的标签选择器不得在命名空间内重叠，或者控制器可以将其视为冲突的指令，并且无法确定应存在多少副本。 基于平等的要求基于平等或不平等的要求允许按标签键和值进行过滤。匹配对象必须满足所有指定的标签约束，尽管它们也可能有其他标签。三种操作都承认=，==，!=。前两个代表平等（简单地说是同义词），而后者代表不平等。例如：12environment = productiontier != frontend 前者选择密钥等于environment和值等于的所有资源production。后者选择密钥等于tier和值不同的frontend所有资源，以及没有带tier密钥标签的所有资源。可以过滤使用逗号运算符production排除的资源frontend：environment=production,tier!=frontend 基于等同的标签要求的一种使用场景是Pods指定节点选择标准。例如，下面的示例Pod选择标签为“ accelerator=nvidia-tesla-p100”的节点。12345678910111213apiVersion: v1kind: Podmetadata: name: cuda-testspec: containers: - name: cuda-test image: "k8s.gcr.io/cuda-vector-add:v0.1" resources: limits: nvidia.com/gpu: 1 nodeSelector: accelerator: nvidia-tesla-p100 基于集合的要求基于集合的标签要求允许根据一组值过滤密钥。三种操作的支持：in，notin和exists（仅密钥标识符）。例如：1234environment in (production, qa)tier notin (frontend, backend)partition!partition 第一个示例选择键等于environment和值等于production或的所有资源qa。第二个示例选择密钥等于tier和除了frontend和之外的值的backend所有资源，以及没有带tier密钥标签的所有资源。第三个例子选择所有资源，包括带密钥的标签partition; 没有检查值。第四个示例选择没有带键的标签的所有资源partition; 没有检查值。类似地，逗号分隔符充当AND运算符。因此，使用partition密钥（无论值）和environment不同的 过滤资源qa都可以实现partition,environment notin (qa)。基于集合标签选择器是一种平等的一般形式，因为environment=production它等同于environment in (production); 同样的!=和notin。 基于集合的需求可以与基于相等的需求相结合。例如：partition in (customerA, customerB),environment!=qa。 APILIST和WATCH过滤LIST和WATCH操作可以指定标签选择器来过滤使用查询参数返回的对象集。这两个要求都是允许的（在此处显示为出现在URL查询字符串中）： 基于平等的要求：?labelSelector=environment%3Dproduction,tier%3Dfrontend 基于集合的要求：?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29 两种标签选择器样式都可用于通过REST客户端列出或查看资源。例如，靶向apiserver与kubectl和使用基于平等-一个可写：1$ kubectl get pods -l environment=production,tier=frontend 或使用基于集合的要求：1$ kubectl get pods -l 'environment in (production),tier in (frontend)' 如前所述，基于集合的要求更具表现力。例如，他们可以在值上实现OR运算符：1$ kubectl get pods -l 'environment in (production, qa)' 或限制负匹配通过存在操作者：1$ kubectl get pods -l 'environment,environment notin (frontend)' 在API对象中设置引用 某些Kubernetes对象（例如services和replicationcontrollers）也使用标签选择器来指定其他资源集，例如pod。 服务和ReplicationControllerservice使用标签选择器定义目标的一组pod 。类似地，replicationcontroller应该管理的pod的数量也用标签选择器定义。 两个对象的标签选择器在使用映射定义json或yaml文件中定义，并且仅支持基于等同的需求选择器：123"selector": &#123; "component" : "redis",&#125; 要么12selector: component: redis 这个选择器（分别以json或yaml格式）相当于component=redis或component in (redis)。 支持基于集合的需求的资源较新的资源，如Job，Deployment，Replica Set，和Daemon Set，支持基于集合的要求也是如此。123456selector: matchLabels: component: redis matchExpressions: - &#123;key: tier, operator: In, values: [cache]&#125; - &#123;key: environment, operator: NotIn, values: [dev]&#125; matchLabels是对的地图{key,value}。一个单一的{key,value}在matchLabels地图相当于一个元件matchExpressions，其key字段是“key”，则operator是“In”和values阵列仅包含“value”。matchExpressions是一个pod选择器要求列表。有效的运算符包括In，NotIn，Exists和DoesNotExist。在In和NotIn的情况下，设置的值必须是非空的。所有的要求，从两者matchLabels和matchExpressionsAND一起 - 他们必须满足，以匹配。 选择节点集用于选择标签的一个用例是约束pod可以调度的节点集。有关更多信息，请参阅有关节点选择的文档。 Annotations您可以使用Kubernetes注释将任意非标识元数据附加到对象。工具和库等客户端可以检索此元数据。 将元数据附加到对象 语法和字符集 将元数据附加到对象您可以使用标签或注释将元数据附加到Kubernetes对象。标签可用于选择对象和查找满足特定条件的对象集合。相反，注释不用于识别和选择对象。注释中的元数据可以是小的或大的，结构化的或非结构化的，并且可以包括标签不允许的字符。 注释（如标签）是键/值映射123456"metadata": &#123; "annotations": &#123; "key1" : "value1", "key2" : "value2" &#125;&#125; 以下是可以在注释中记录的一些信息示例： 由声明性配置层管理的字段。将这些字段作为注释附加，可以将它们与客户端或服务器设置的默认值以及自动生成的字段和自动调整大小或自动调整系统设置的字段区分开来。 构建，发布或映像信息，如时间戳，版本ID，git分支，PR编号，镜像哈希和仓库地址。 指向日志记录，监视，分析或审计存储库的指针。 可用于调试目的的客户端库或工具信息：例如，名称，版本和构建信息。 用户或工具/系统出处信息，例如来自其他生态系统组件的相关对象的URL。 轻量推出工具元数据：例如，配置或检查点。 负责人的电话或寻呼机号码，或指定可在何处找到该信息的目录条目，例如团队网站。 从最终用户到实现的指令，用于修改行为或使用非标准功能。 您可以将此类信息存储在外部数据库或目录中，而不是使用注释，但这会使生成用于部署，管理，内省等的共享客户端库和工具变得更加困难。 语法和字符集注释是键/值对。有效的注释键有两个段：可选的前缀和名称，用斜杠（/）分隔。名称段是必需的，必须是63个字符或更少，以字母数字字符（[a-z0-9A-Z]）开头和结尾，带有破折号（-），下划线（_），点（.）和字母数字之间。前缀是可选的。如果指定，前缀必须是DNS子域：由点（.）分隔的一系列DNS标签，总共不超过253个字符，后跟斜杠（/）。 如果省略前缀，则假定注释密钥对用户是私有的。自动化系统组件（例如kube-scheduler，kube-controller-manager，kube-apiserver，kubectl，或其他第三方自动化）的添加注释到最终用户的对象都必须指定一个前缀。 在kubernetes.io/和k8s.io/前缀保留给Kubernetes核心组件。 Field Selectors 支持的字段 支持操作 链式选择器 多种资源类型 字段选择器允许您根据一个或多个资源字段的值选择Kubernetes资源。以下是一些示例字段选择器查询： metadata.name=my-service metadata.namespace!=default status.phase=Pending 此kubectl命令选择status.phase字段值为的所有Pod Running：1$ kubectl get pods --field-selector status.phase=Running 注意：字段选择器本质上是资源过滤器。默认情况下，不应用选择器/过滤器，这意味着将选择指定类型的所有资源。这使以下kubectl查询等效：12$ kubectl get pods$ kubectl get pods --field-selector "" 支持的字段支持的字段选择器因Kubernetes资源类型而异。所有资源类型都支持metadata.name和metadata.namespace字段。使用不受支持的字段选择器会产生错误。例如：12$ kubectl get ingress --field-selector foo.bar=bazError from server (BadRequest): Unable to find "ingresses" that match label selector "", field selector "foo.bar=baz": "foo.bar" is not a known field selector: only "metadata.name", "metadata.namespace" 支持操作您可以使用=，==以及!=与现场选择操作（=和==意思是一样的）。kubectl例如，此命令选择不在default命名空间中的所有Kubernetes服务：1$ kubectl get services --field-selector metadata.namespace!=default 链式选择器与标签和其他选择器一样，字段选择器可以作为逗号分隔列表链接在一起。此kubectl命令选择status.phase不相等Running且spec.restartPolicy字段等于的所有Pod Always：1$ kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always 多种资源类型您可以跨多种资源类型使用字段选择器。此kubectl命令选择不在default命名空间中的所有Statefulsets和Services ：1$ kubectl get statefulsets,services --field-selector metadata.namespace!=default Recommended Labels您可以使用比kubectl和仪表板更多的工具来可视化和管理Kubernetes对象。一组通用的标签允许工具以互操作的方式工作，以所有工具都能理解的通用方式描述对象。 除支持工具外，推荐标签还以可查询的方式描述应用程序。 标签 应用程序和应用程序实例 例子元数据围绕应用程序的概念进行组织。Kubernetes不是一个服务平台（PaaS），也没有或强制执行正式的应用程序概念。相反，应用程序是非正式的，并使用元数据进 应用程序包含的内容的定义是松散的。 注意：这些是推荐标签。它们使管理应用程序变得更容易，但对于任何核心工具都不是必需的。 共享标签和注释共享一个共同的前缀：app.kubernetes.io。没有前缀的标签对用户是私有的。共享前缀可确保共享标签不会干扰自定义用户标签。 标签为了充分利用这些标签，应将它们应用于每个资源对象。 键 描述 例 类型 app.kubernetes.io/name 应用程序的名称 string mysql app.kubernetes.io/instance 标识应用程序实例的唯一名称 string wordpress-abcxzy app.kubernetes.io/version 应用程序的当前版本（例如，语义版本，修订版哈希等） string 5.7.21 app.kubernetes.io/component 架构中的组件 string database app.kubernetes.io/part-of 此级别的更高级别应用程序的名称 string wordpress app.kubernetes.io/managed-by 该工具用于管理应用程序的操作 string helm 要说明这些标签的运行情况，请考虑以下StatefulSet对象：12345678910apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "5.7.21" app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/managed-by: helm 应用程序和应用程序实例应用程序可以一次或多次安装到Kubernetes集群中，在某些情况下，可以安装在同一名称空间中。例如，wordpress可以不止一次安装，其中不同的网站是wordpress的不同安装。 应用程序的名称和实例名称分别记录。例如，在WordPress具有app.kubernetes.io/name的wordpress，同时它有一个实例名，被表示为app.kubernetes.io/instance具有值 wordpress-abcxzy。这使得应用程序的应用程序和实例可以识别。应用程序的每个实例都必须具有唯一的名称。 例子为了说明使用这些标签的不同方式，以下示例具有不同的复杂性。 一种简单的无状态服务考虑使用Deployment和Service对象部署的简单无状态服务的情况。以下两个代码段表示如何以最简单的形式使用标签。 本Deployment是用来监督运行应用程序本身的豆荚。1234567apiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/name: myservice app.kubernetes.io/instance: myservice-abcxzy... 将Service用于公开应用程序。1234567apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/name: myservice app.kubernetes.io/instance: myservice-abcxzy... 使用数据库的Web应用程序考虑一个稍微复杂的应用程序：使用Helm安装的使用数据库（MySQL）的Web应用程序（WordPress）。以下代码段说明了用于部署此应用程序的对象的开始。 以下Deployment内容用于WordPress：1234567891011apiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/name: wordpress app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "4.9.4" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: server app.kubernetes.io/part-of: wordpress... 将Service用于公开WordPress的：1234567891011apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/name: wordpress app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "4.9.4" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: server app.kubernetes.io/part-of: wordpress... MySQL作为一个StatefulSet包含它的元数据和它所属的更大的应用程序公开：1234567891011apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/managed-by: helm app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/version: "5.7.21"... 将Service用于公开MySQL作为WordPress的部分：1234567891011apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/managed-by: helm app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/version: "5.7.21"... 使用MySQL StatefulSet，Service您会注意到有关MySQL和Wordpress的信息，包括更广泛的应用程序。 对象管理使用kubectlKubernetes对象管理该kubectl命令行工具支持多种不同的方法来创建和管理Kubernetes对象。本文档概述了不同的方法。 管理技巧 命令式命令 势在必行的对象配置 声明性对象配置 管理技巧 警告：应仅使用一种技术管理Kubernetes对象。对同一对象的混合和匹配技术会导致未定义的行为。 Management technique 操作 推荐环境 Supported writers Learning curve Imperative commands Live objects Development projects 1+ Lowest Imperative object configuration Individual files Production projects 1 Moderate Declarative object configuration Directories of files Production projects 1+ Highest 命令式命令使用命令性命令时，用户直接在群集中的活动对象上操作。用户将kubectl命令的操作作为参数或标志提供。 这是在集群中启动或运行一次性任务的最简单方法。由于此技术直接在活动对象上运行，因此它不提供先前配置的历史记录。 例子通过创建Deployment对象来运行nginx容器的实例：1kubectl run nginx --image nginx 使用不同的语法执行相同的操作：1kubectl create deployment nginx --image nginx 权衡与对象配置相比的优点： 命令简单易学，易记。 命令只需要一个步骤即可对集群进行更改。 与对象配置相比的缺点： 命令不与更改审核过程集成。 命令不提供与更改关联的审计跟踪。 除了活动之外，命令不提供记录源。 命令不提供用于创建新对象的模板。 势在必行的对象配置在命令式对象配置中，kubectl命令指定操作（创建，替换等），可选标志和至少一个文件名。指定的文件必须包含YAML或JSON格式的对象的完整定义。 有关 对象定义的更多详细信息，请参阅API参考。 警告：replace命令式命令将现有规范替换为新提供的规范，删除对配置文件中缺少的对象的所有更改。此方法不应与其配置文件独立更新的资源类型一起使用。LoadBalancer例如，类型的服务使其externalIPs字段独立于群集的配置而更新。 例子创建配置文件中定义的对象：1kubectl create -f nginx.yaml 删除两个配置文件中定义的对象：1kubectl delete -f nginx.yaml -f redis.yaml 通过覆盖实时配置来更新配置文件中定义的对象：1kubectl replace -f nginx.yaml 权衡与命令式命令相比的优点： 对象配置可以存储在诸如Git的源控制系统中。 对象配置可以与进程集成，例如在推送和审计跟踪之前查看更改。 对象配置提供了用于创建新对象的模板。 与命令式命令相比的缺点： 对象配置需要对对象模式有基本的了解。 对象配置需要编写YAML文件的附加步骤。 与声明对象配置相比的优点： 命令式对象配置行为更简单，更易于理解。 从Kubernetes 1.5版开始，命令式对象配置更加成熟。 与声明对象配置相比的缺点： 命令对象配置最适合文件，而不是目录。 活动对象的更新必须反映在配置文件中，否则在下次更换时会丢失。 声明性对象配置使用声明性对象配置时，用户对本地存储的对象配置文件进行操作，但是用户不定义要对文件执行的操作。每个对象自动检测创建，更新和删除操作kubectl。这使得能够处理目录，其中可能需要不同对象的不同操作。 注意：声明性对象配置保留其他编写者所做的更改，即使更改未合并回对象配置文件也是如此。这可以通过使用patchAPI操作来仅写入观察到的差异，而不是使用replace API操作来替换整个对象配置。 例子处理目录中的所有对象配置文件configs，并创建或修补活动对象。您可以先diff查看要进行的更改，然后应用： 12kubectl diff -f configs/kubectl apply -f configs/ 递归处理目录：12kubectl diff -R -f configs/kubectl apply -R -f configs/ 权衡与命令式对象配置相比的优点： 即使它们未合并回配置文件，也会保留直接对活动对象所做的更改。 声明性对象配置更好地支持对目录进行操作并自动检测每个对象的操作类型（创建，修补，删除）。 与命令式对象配置相比的缺点： 声明性对象配置更难以调试，并在意外时理解结果。 使用diff的部分更新会创建复杂的合并和修补操作。 使用命令式命令管理Kubernetes对象可以使用命令kubectl行工具中内置的命令性命令直接创建，更新和删除Kubernetes对象。本文档说明了如何组织这些命令以及如何使用它们来管理实时对象。 权衡 如何创建对象 如何更新对象 如何删除对象 如何查看对象 使用set命令在创建之前修改对象 使用–edit修改之前创建的对象 权衡该kubectl工具支持三种对象管理： 命令式命令 势在必行的对象配置 声明性对象配置 有关每种对象管理 的优缺点的讨论，请参阅Kubernetes对象管理。 如何创建对象该kubectl工具支持动词驱动的命令，用于创建一些最常见的对象类型。这些命令被命名为不熟悉Kubernetes对象类型的用户可识别。 run：创建一个新的Deployment对象以在一个或多个Pod中运行Container。 expose：创建一个新的服务对象，以跨Pod调整流量负载。 autoscale：创建新的Autoscaler对象以自动水平扩展控制器，例如部署。 该kubectl工具还支持由对象类型驱动的创建命令。这些命令支持更多对象类型，并且更明确地表达了它们的意图，但要求用户知道他们打算创建的对象的类型。 create &lt;objecttype&gt; [&lt;subtype&gt;] &lt;instancename&gt; 某些对象类型具有您可以在create命令中指定的子类型。例如，Service对象有几个子类型，包括ClusterIP，LoadBalancer和NodePort。这是一个使用子类型NodePort创建服务的示例：1kubectl create service nodeport &lt;myservicename&gt; 在前面的示例中，该create service nodeport命令称为命令的子create service命令。 您可以使用该-h标志来查找子命令支持的参数和标志：1kubectl create service nodeport -h 如何更新对象该kubectl命令支持一些常见更新操作的动词驱动命令。命名这些命令是为了使不熟悉Kubernetes对象的用户能够在不知道必须设置的特定字段的情况下执行更新： scale：通过更新控制器的副本计数，水平缩放控制器以添加或删除Pod。 annotate：在对象中添加或删除注释。 label：在对象中添加或删除标签。 该kubectl命令还支持由对象的一个方面驱动的更新命令。设置此方面可以为不同的对象类型设置不同的字段： set ：设置对象的一个方面。 注意：在Kubernetes 1.5版中，并非每个动词驱动的命令都有一个关联的方面驱动命令。 该kubectl工具支持这些直接更新实时对象的其他方法，但是它们需要更好地理解Kubernetes对象模式。 edit：通过在编辑器中打开其配置，直接编辑活动对象的原始配置。 patch：使用补丁字符串直接修改活动对象的特定字段。有关修补程序字符串的更多详细信息，请参阅API约定中的修补程序部分 。 如何删除对象您可以使用该delete命令从群集中删除对象： delete &lt;type&gt;/&lt;name&gt; 注意：您可以使用kubectl delete命令式命令和命令式对象配置。不同之处在于传递给命令的参数。要 kubectl delete用作命令性命令，请将要删除的对象作为参数传递。这是一个传递名为nginx的Deployment对象的示例： 1kubectl delete deployment/nginx 如何查看对象有几个命令用于打印有关对象的信息： get：打印有关匹配对象的基本信息。使用get -h查看选项列表。 describe：打印有关匹配对象的聚合详细信息。 logs：为在Pod中运行的容器打印stdout和stderr。 使用set命令在创建之前修改对象有些对象字段没有可在create命令中使用的标志。在一些案件中，可以使用的组合 set并create指定对象创建前场的值。这是通过将create命令的输出传递给 set命令，然后返回到create命令来完成的。这是一个例子： 1kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run | kubectl set selector --local -f - 'environment=qa' -o yaml | kubectl create -f - 该kubectl create service -o yaml --dry-run命令为服务创建配置，但将其作为YAML打印到stdout，而不是将其发送到Kubernetes API服务器。 该kubectl set selector --local -f - -o yaml命令从stdin读取配置，并将更新的配置作为YAML写入stdout。 该kubectl create -f -命令使用stdin提供的配置创建对象。 使用–edit修改之前创建的对象您可以kubectl create --edit在创建对象之前对其进行任意更改。这是一个例子：12kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run &gt; /tmp/srv.yamlkubectl create --edit -f /tmp/srv.yaml 该kubectl create service命令为服务创建配置并将其保存到/tmp/srv.yaml。该kubectl create --edit命令在创建对象之前打开配置文件以进行编辑。 使用配置文件管理Kubernetes对象可以使用kubectl 命令行工具以及使用YAML或JSON编写的对象配置文件来创建，更新和删除Kubernetes对象。本文档介绍了如何使用配置文件定义和管理对象。 权衡 如何创建对象 如何更新对象 如何删除对象 如何查看对象 限制 在不保存配置的情况下从URL创建和编辑对象 从命令式命令迁移到命令式对象配置 定义控制器选择器和PodTemplate标签 权衡该kubectl工具支持三种对象管理： 命令式命令 势在必行的对象配置 声明性对象配置 有关每种对象管理 的优缺点的讨论，请参阅Kubernetes对象管理。 如何创建对象您可以使用kubectl create -f从配置文件创建对象。 有关详细信息，请参阅kubernetes API参考。 kubectl create -f &lt;filename|url&gt; 如何更新对象 警告：使用该replace命令更新对象会删除配置文件中未指定的规范的所有部分。这不应该与规范部分由集群管理的对象一起使用，例如类型服务LoadBalancer，其中externalIPs字段独立于配置文件进行管理。必须将独立管理的字段复制到配置文件中以防止replace丢弃它们。 您可以使用kubectl replace -f根据配置文件更新活动对象。 kubectl replace -f &lt;filename|url&gt; 如何删除对象您可以使用kubectl delete -f删除配置文件中描述的对象。 kubectl delete -f &lt;filename|url&gt; 如何查看对象您可以使用它kubectl get -f来查看有关配置文件中描述的对象的信息。 kubectl get -f &lt;filename|url&gt; -o yaml 该-o yaml标志指定打印完整对象配置。使用kubectl get -h查看选项列表。 限制create，replace和delete命令工作得很好，当每个对象的配置完全确定并记录在它的配置文件。但是，当更新活动对象并且更新未合并到其配置文件中时，更新将在下次replace 执行时丢失。如果控制器（例如HorizontalPodAutoscaler）直接对活动对象进行更新，则会发生这种情况。这是一个例子： 您可以从配置文件创建对象。 另一个源通过更改某个字段来更新对象。 您从配置文件中替换该对象。步骤2中其他来源所做的更改将丢失。 如果需要支持同一对象的多个编写器，则可以使用它kubectl apply来管理对象。 在不保存配置的情况下从URL创建和编辑对象假设您具有对象配置文件的URL。您可以 kubectl create --edit在创建对象之前用于更改配置。这对于指向可由读者修改的配置文件的教程和任务特别有用。 1kubectl create -f &lt;url&gt; --edit 从命令式命令迁移到命令式对象配置 从命令式命令迁移到命令式对象配置涉及几个手动步骤。将活动对象导出到本地对象配置文件： 1kubectl get &lt;kind&gt;/&lt;name&gt; -o yaml --export &gt; &lt;kind&gt;_&lt;name&gt;.yaml 从对象配置文件中手动删除状态字段。 对于后续对象管理，请replace专门使用。 1kubectl replace -f &lt;kind&gt;_&lt;name&gt;.yaml 定义控制器选择器和PodTemplate标签 警告：强烈建议不要更新控制器上的选择器。 推荐的方法是定义一个仅由控制器选择器使用的单个不可变PodTemplate标签，没有其他语义含义。 示例标签：1234567selector: matchLabels: controller-selector: "extensions/v1beta1/deployment/nginx"template: metadata: labels: controller-selector: "extensions/v1beta1/deployment/nginx" 使用配置文件声明管理Kubernetes对象可以通过在目录中存储多个对象配置文件并使用kubectl apply根据需要递归创建和更新这些对象来创建，更新和删除Kubernetes对象。此方法保留对活动对象的写入，而不将更改合并回对象配置文件。kubectl diff还可以预览apply将要进行的更改。 权衡 在你开始之前 如何创建对象 如何更新对象 如何删除对象 如何查看对象 如何应用计算差异并合并更改 默认字段值 如何更改配置文件和直接命令式编写器之间字段的所有权 改变管理方法 定义控制器选择器和PodTemplate标签 权衡该kubectl工具支持三种对象管理： 命令式命令 势在必行的对象配置 声明性对象配置 有关每种对象管理 的优缺点的讨论，请参阅Kubernetes对象管理。 在你开始之前声明性对象配置需要牢固地理解Kubernetes对象定义和配置。如果您还没有阅读并填写以下文件： 使用命令式命令管理Kubernetes对象 使用配置文件管理Kubernetes对象 以下是本文档中使用的术语的定义： 对象配置文件/配置文件：定义Kubernetes对象配置的文件。本主题说明如何将配置文件传递给kubectl apply。配置文件通常存储在源代码管理中，例如Git。 实时对象配置/实时配置：Kubernetes集群观察到的对象的实时配置值。这些保存在Kubernetes集群存储中，通常是etcd。 声明性配置writer / declarative writer：对活动对象进行更新的人员或软件组件。本主题中提到的实时编写器会更改对象配置文件并运行kubectl apply以编写更改。 如何创建对象使用kubectl apply创建的所有对象，除了那些已经存在，通过配置文件在指定的目录中定义：1kubectl apply -f &lt;directory&gt;/ 这将kubectl.kubernetes.io/last-applied-configuration: &#39;{...}&#39;在每个对象上设置注释。注释包含用于创建对象的对象配置文件的内容。 注意：添加-R标志以递归处理目录。 以下是对象配置文件的示例：1234567891011121314151617181920#application/simple_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 运行kubectl diff以打印将要创建的对象：1kubectl diff -f https://k8s.io/examples/application/simple_deployment.yaml 注意：diff使用服务器端干运行，需要启用kube-apiserver。 使用kubectl apply以下方法创建对象1kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示kubectl.kubernetes.io/last-applied-configuration注释已写入实时配置，并且与配置文件匹配：123456789101112131415161718192021222324252627282930313233343536kind: Deploymentmetadata: annotations: # ... # This is the json representation of simple_deployment.yaml # It was written by kubectl apply when the object was created kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 如何更新对象您还可以使用kubectl apply更新目录中定义的所有对象，即使这些对象已存在。此方法可实现以下目标： 设置实时配置中配置文件中显示的字段。 清除实时配置中从配置文件中删除的字段。 12kubectl diff -f &lt;directory&gt;/kubectl apply -f &lt;directory&gt;/ 注意：添加-R标志以递归处理目录。 这是一个示例配置文件：1234567891011121314151617181920#application/simple_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用kubectl apply以下方法创建对象1kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml 注意：出于说明的目的，上述命令引用单个配置文件而不是目录。 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示kubectl.kubernetes.io/last-applied-configuration注释已写入实时配置，并且与配置文件匹配：123456789101112131415161718192021222324252627282930313233343536kind: Deploymentmetadata: annotations: # ... # This is the json representation of simple_deployment.yaml # It was written by kubectl apply when the object was created kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 使用，直接更新replicas实时配置中的字段kubectl scale。这不使用kubectl apply：1kubectl scale deployment/nginx-deployment --replicas=2 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示该replicas字段已设置为2，并且last-applied-configuration注释不包含replicas字段：1234567891011121314151617181920212223242526272829303132333435apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # note that the annotation does not contain replicas # because it was not updated through apply kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: replicas: 2 # written by scale # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... 更新simple_deployment.yaml配置文件以将映像更改 nginx:1.7.9为nginx:1.11.9，并删除该minReadySeconds字段：12345678910111213141516171819#application/update_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 # update the image ports: - containerPort: 80 应用对配置文件所做的更改：12kubectl diff -f https://k8s.io/examples/application/update_deployment.yamlkubectl apply -f https://k8s.io/examples/application/update_deployment.yaml 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示实时配置的以下更改： 该replicas字段保留2的值kubectl scale。这是可能的，因为它从配置文件中省略。该image场已被更新，以nginx:1.11.9从nginx:1.7.9。该last-applied-configuration批注已经更新了新的形象。该minReadySeconds领域已被清除。该last-applied-configuration注释不再包含minReadySeconds字段。 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # The annotation contains the updated image to nginx 1.11.9, # but does not contain the updated replicas to 2 kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.11.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: replicas: 2 # Set by `kubectl scale`. Ignored by `kubectl apply`. # minReadySeconds cleared by `kubectl apply` # ... selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.11.9 # Set by `kubectl apply` # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 警告：混合kubectl apply与势在必行对象配置命令 create和replace不支持。这是因为create 并replace没有保留kubectl.kubernetes.io/last-applied-configuration 的是kubectl apply用来计算更新。 如何删除对象删除管理对象有两种方法kubectl apply。 推荐的： kubectl delete -f &lt;filename&gt;建议的方法是使用命令式命令手动删除对象，因为它更明确地删除了什么，并且不太可能导致用户无意中删除了某些内容1kubectl delete -f &lt;filename&gt; 替代方案： kubectl apply -f &lt;directory/&gt; --prune -l your=label只有在你知道自己在做什么的情况下才能使用它。 警告： kubectl apply --prune处于alpha状态，后续版本中可能会引入向后不兼容的更改。 警告：使用此命令时必须小心，以免意外删除对象。 作为替代方法kubectl delete，您可以使用它kubectl apply来识别从目录中删除配置文件后要删除的对象。--prune 对API服务器应用查询以匹配一组标签的所有对象，并尝试将返回的活动对象配置与对象配置文件进行匹配。如果对象与查询匹配，并且目录中没有配置文件，并且它具有last-applied-configuration注释，则会将其删除。1kubectl apply -f &lt;directory/&gt; --prune -l &lt;labels&gt; 警告：只应对包含对象配置文件的根目录运行prune。如果对象被指定的标签选择器查询返回-l 并且未出现在子目录中，则对子目录运行会导致无意中删除对象。 如何查看对象您可以使用kubectl getwith -o yaml来查看活动对象的配置： 1kubectl get -f &lt;filename|url&gt; -o yaml 如何应用计算差异并合并更改 注意：补丁是一种更新操作，其范围限定为对象的特定字段而不是整个对象。这样可以仅更新对象上的特定字段集，而无需先读取对象。 当kubectl apply一个对象更新实时配置，它通过发送补丁请求API服务器这样做。该补丁定义了作用于活动对象配置的特定字段的更新。该kubectl apply命令使用配置文件，实时配置和实时配置中last-applied-configuration存储的注释来计算此修补程序请求 。 合并补丁计算该kubectl apply命令将配置文件的内容写入 kubectl.kubernetes.io/last-applied-configuration注释。这用于标识已从配置文件中删除的字段，需要从实时配置中清除。以下是用于计算应删除或设置哪些字段的步骤： 计算要删除的字段。这些是last-applied-configuration配置文件中存在和丢失的字段。 计算要添加或设置的字段。这些是配置文件中存在的字段，其值与实时配置不匹配。 这是一个例子。假设这是Deployment对象的配置文件：12345678910111213141516171819#application/update_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 # update the image ports: - containerPort: 80 另外，假设这是同一Deployment对象的实时配置：1234567891011121314151617181920212223242526272829303132333435apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # note that the annotation does not contain replicas # because it was not updated through apply kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: replicas: 2 # written by scale # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... 以下是将通过以下方式执行的合并计算kubectl apply： 通过读取值last-applied-configuration并将它们与配置文件中的值进行比较来计算要删除的字段 。清除字段在本地对象配置文件中显式设置为null，无论它们是否出现在last-applied-configuration。在此示例中，minReadySeconds出现在 last-applied-configuration注释中，但未出现在配置文件中。 Action：minReadySeconds`从实时配置中清除。 通过从配置文件中读取值并将它们与实时配置中的值进行比较来计算要设置的字段。在此示例中，image配置文件中的值与实时配置中的值不匹配。Action：设置image实时配置中的值。 设置last-applied-configuration注释以匹配配置文件的值。 将来自1,2,3的结果合并到API服务器的单个补丁请求中。 以下是合并的实时配置：1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # The annotation contains the updated image to nginx 1.11.9, # but does not contain the updated replicas to 2 kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.11.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: selector: matchLabels: # ... app: nginx replicas: 2 # Set by `kubectl scale`. Ignored by `kubectl apply`. # minReadySeconds cleared by `kubectl apply` # ... template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.11.9 # Set by `kubectl apply` # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 如何合并不同类型的字段配置文件中的特定字段如何与实时配置合并取决于字段的类型。有几种类型的字段： primitive：字符串，整数或布尔类型的字段。例如，image和replicas是原始字段。行动：替换。 map，也称为object：类型为map的字段或包含子字段的复杂类型。例如labels， annotations，spec并且metadata是所有map。Action：合并元素或子字段。 list：包含可以是基本类型或映射的项列表的字段。例如containers，ports和args是列表。行动：变化。 当kubectl apply更新map或列表字段，它通常不更换整个领域，而是更新各个子元素。例如，在合并spec部署时，spec不会替换整个部署。相反，比较和合并spec诸如的子字段replicas。 将更改合并到基本字段将更改合并到基本字段 注意： -用于“不适用”，因为未使用该值。 对象配置文件中的字段 实时对象配置中的字段 最后应用配置中的字段 行动 是 是 - 设置为配置文件值。 是 没有 - 将实时设置为本地配置。 没有 - - 从实时配置中清除。 没有 - 没有 没做什么。保持实时价值。 合并对地图字段的更改通过比较地图的每个子字段或元素来合并表示地图的字段： 注意： -用于“不适用”，因为未使用该值。 键入对象配置文件 键入实时对象配置 最后应用配置中的字段 行动 是 是 - 比较子字段值。 是 没有 - 将实时设置为本地配置。 没有 - 是 从实时配置中删除。 没有 - 没有 没做什么。保持实时价值。 合并类型列表字段的更改将更改合并到列表使用以下三种策略之一： 替换列表。 合并复杂元素列表中的各个元素。 合并原始元素列表。 战略的选择是基于每个领域。 替换列表将列表视为与原始字段相同。替换或删除整个列表。这保留了订购。 例如：使用kubectl apply更新args一个pod里的一个Container的field。这会将args实时配置中的值设置为配置文件中的值。args之前已添加到实时配置的任何元素都将丢失。args配置文件中定义的元素的顺序将保留在实时配置中。1234567891011# last-applied-configuration value args: ["a", "b"]# configuration file value args: ["a", "c"]# live configuration args: ["a", "b", "d"]# result after merge args: ["a", "c"] 说明：合并使用配置文件值作为新列表值。 合并复杂元素列表中的各个元素：将列表视为映射，并将每个元素的特定字段视为键。添加，删除或更新单个元素。这不会保留排序。 此合并策略在每个字段上使用一个名为a的特殊标记patchMergeKey。patchMergeKey是在Kubernetes源代码中的每个字段中定义： types.go 当合并映射的列表，指定的字段作为patchMergeKey对于给定的元素被用于像该元素的映射键。 例如：使用kubectl apply更新containers一PodSpec的field。这将列表合并为好像是每个元素都被键入的映射name。123456789101112131415161718192021222324252627282930313233343536373839404142# last-applied-configuration value containers: - name: nginx image: nginx:1.10 - name: nginx-helper-a # key: nginx-helper-a; will be deleted in result image: helper:1.3 - name: nginx-helper-b # key: nginx-helper-b; will be retained image: helper:1.3# configuration file value containers: - name: nginx image: nginx:1.10 - name: nginx-helper-b image: helper:1.3 - name: nginx-helper-c # key: nginx-helper-c; will be added in result image: helper:1.3# live configuration containers: - name: nginx image: nginx:1.10 - name: nginx-helper-a image: helper:1.3 - name: nginx-helper-b image: helper:1.3 args: ["run"] # Field will be retained - name: nginx-helper-d # key: nginx-helper-d; will be retained image: helper:1.3# result after merge containers: - name: nginx image: nginx:1.10 # Element nginx-helper-a was deleted - name: nginx-helper-b image: helper:1.3 args: ["run"] # Field was retained - name: nginx-helper-c # Element was added image: helper:1.3 - name: nginx-helper-d # Element was ignored image: helper:1.3 说明： 名为“nginx-helper-a”的容器已删除，因为配置文件中没有出现名为“nginx-helper-a”的容器。 名为“nginx-helper-b”的容器保留args 了实时配置中的更改。kubectl apply能够识别实时配置中的“nginx-helper-b”与配置文件中的“nginx-helper-b”相同，即使它们的字段具有不同的值（args配置文件中没有）。这是因为patchMergeKey字段值（名称）在两者中都是相同的。 添加了名为“nginx-helper-c”的容器，因为实时配置中没有出现具有该名称的容器，但配置文件中出现了具有该名称的容器。 保留名为“nginx-helper-d”的容器，因为在最后应用的配置中没有出现具有该名称的元素。 合并原始元素列表从Kubernetes 1.5开始，不支持合并原始元素列表。 注意：为给定字段选择的上述策略中的哪一个由types.go中的patchStrategy标记控制。如果没有为类型列表的字段指定patchStrategy，则替换列表。 默认字段值如果在创建对象时未指定某些字段，则API服务器会将某些字段设置为实时配置中的默认值。 这是部署的配置文件。该文件未指定strategy：1234567891011121314151617181920#application/simple_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用kubectl apply以下方法创建对象1kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示API服务器在实时配置中将多个字段设置为默认值。配置文件中未指定这些字段。12345678910111213141516171819202122232425262728293031323334apiVersion: apps/v1kind: Deployment# ...spec: selector: matchLabels: app: nginx minReadySeconds: 5 replicas: 1 # defaulted by apiserver strategy: rollingUpdate: # defaulted by apiserver - derived from strategy.type maxSurge: 1 maxUnavailable: 1 type: RollingUpdate # defaulted apiserver template: metadata: creationTimestamp: null labels: app: nginx spec: containers: - image: nginx:1.7.9 imagePullPolicy: IfNotPresent # defaulted by apiserver name: nginx ports: - containerPort: 80 protocol: TCP # defaulted by apiserver resources: &#123;&#125; # defaulted by apiserver terminationMessagePath: /dev/termination-log # defaulted by apiserver dnsPolicy: ClusterFirst # defaulted by apiserver restartPolicy: Always # defaulted by apiserver securityContext: &#123;&#125; # defaulted by apiserver terminationGracePeriodSeconds: 30 # defaulted by apiserver# ... 在修补程序请求中，默认字段不会被重新默认，除非它们作为修补程序请求的一部分被明确清除。这可能会导致基于其他字段的值默认的字段出现意外行为。稍后更改其他字段时，除非明确清除，否则不会更新默认值。 因此，建议在配置文件中显式定义服务器默认的某些字段，即使所需的值与服务器默认值匹配也是如此。这样可以更轻松地识别不会被服务器重新默认的冲突值。 例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# last-applied-configurationspec: template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80# configuration filespec: strategy: type: Recreate # updated value template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80# live configurationspec: strategy: type: RollingUpdate # defaulted value rollingUpdate: # defaulted value derived from type maxSurge : 1 maxUnavailable: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80# result after merge - ERROR!spec: strategy: type: Recreate # updated value: incompatible with rollingUpdate rollingUpdate: # defaulted value: incompatible with "type: Recreate" maxSurge : 1 maxUnavailable: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 说明： 用户无需定义即可创建部署strategy.type。 服务器默认strategy.type为RollingUpdate默认 strategy.rollingUpdate值。 用户更改strategy.type为Recreate。该strategy.rollingUpdate值保持在其默认的值，但服务器期望他们被清除。如果strategy.rollingUpdate最初在配置文件中定义了值，则更清楚的是它们需要被删除。 应用失败，因为strategy.rollingUpdate未清除。该strategy.rollingupdate 字段不能与被定义strategy.type的Recreate。 建议：应在对象配置文件中明确定义这些字段： 工作负载上的选择器和PodTemplate标签，例如Deployment，StatefulSet，Job，DaemonSet，ReplicaSet和ReplicationController 部署部署策略 如何清除其他编写者设置的服务器默认字段或字段可以通过将其值设置为null然后应用配置文件来清除未出现在配置文件中的字段。对于服务器默认的字段，这会触发重新默认值。 如何更改配置文件和直接命令式编写器之间字段的所有权这些是您应该用来更改单个对象字段的唯一方法： 使用kubectl apply。 直接写入实时配置而不修改配置文件：例如，使用kubectl scale。 将所有者从直接命令式编写器更改为配置文件将该字段添加到配置文件中。对于现场，停止对未经过的实时配置的直接更新kubectl apply。 将所有者从配置文件更改为直接命令式编写器从Kubernetes 1.5开始，将字段的所有权从配置文件更改为命令式编写器需要手动步骤： 从配置文件中删除该字段。 从kubectl.kubernetes.io/last-applied-configuration活动对象上的注释中删除该字段。 改变管理方法应该一次只使用一种方法管理Kubernetes对象。可以从一种方法切换到另一种方法，但这是一种手动过程。 注意：使用命令式删除和声明式管理是可以的。 从命令式命令管理迁移到声明性对象配置从命令式命令管理迁移到声明性对象配置涉及几个手动步骤： 将活动对象导出到本地配置文件： 1kubectl get &lt;kind&gt;/&lt;name&gt; -o yaml --export &gt; &lt;kind&gt;_&lt;name&gt;.yaml status从配置文件中手动删除该字段。 注意：此步骤是可选的，因为kubectl apply不会更新状态字段 即使它存在于配置文件中。 kubectl.kubernetes.io/last-applied-configuration在对象上设置注释： 1kubectl replace --save-config -f &lt;kind&gt;_&lt;name&gt;.yaml 更改kubectl apply用于专门管理对象的进程。 从命令式对象配置迁移到声明性对象配置 kubectl.kubernetes.io/last-applied-configuration在对象上设置注释： 1kubectl replace --save-config -f &lt;kind&gt;_&lt;name&gt;.yaml 更改kubectl apply用于专门管理对象的进程。 定义控制器选择器和PodTemplate标签 警告：强烈建议不要更新控制器上的选择器。 推荐的方法是定义一个仅由控制器选择器使用的单个不可变PodTemplate标签，没有其他语义含义。 例：1234567selector: matchLabels: controller-selector: "extensions/v1beta1/deployment/nginx"template: metadata: labels: controller-selector: "extensions/v1beta1/deployment/nginx" Kubernetes Architecture节点节点是Kubernetes中的工作机器，以前称为一个 minion。节点可以是VM或物理机，具体取决于集群。每个节点都包含运行pods所需的服务，并由主组件管理。节点上的服务包括container runtime，kubelet和kube-proxy。有关更多详细信息，请参阅 体系结构设计文档中的Kubernetes节点部分。 节点状态 管理 API对象 节点状态节点的状态包含以下信息： 地址 条件 容量 信息 下面详细描述每个部分。 地址这些字段的使用取决于您的云提供商或裸机配置。 HostName：节点内核报告的主机名。可以通过kubelet--hostname-override参数覆盖。 ExternalIP：通常是可从外部路由的节点的IP地址（可从群集外部获得）。 InternalIP：通常仅在群集内可路由的节点的IP地址。 条件该conditions字段描述了所有Running节点的状态。 节点条件 描述 OutOfDisk True 如果节点上的可用空间不足以添加新的pod，否则 False Ready True如果节点是健康的并准备好接受pod，False如果节点不健康且不接受pod，并且Unknown节点控制器在最后一次没有从节点听到node-monitor-grace-period（默认为40秒） MemoryPressure True如果节点存储器上存在压力 - 即节点存储器是否为低; 除此以外False PIDPressure True如果进程存在压力 - 也就是说，如果节点上有太多进程; 除此以外False DiskPressure True如果磁盘大小存在压力 - 即磁盘容量低; 除此以外False NetworkUnavailable True 如果没有正确配置节点的网络，否则 False 节点条件表示为JSON对象。例如，以下响应描述了健康节点。123456"conditions": [ &#123; "type": "Ready", "status": "True" &#125;] 如果就绪状态的状态保持Unknown或False超过pod-eviction-timeout，则会将参数传递给kube-controller-manager，并且节点控制器会调度节点上的所有Pod以进行删除。默认逐出超时持续时间为五分钟。在某些情况下，当节点无法访问时，apiserver无法与节点上的kubelet通信。在重新建立与apiserver的通信之前，不能将删除pod的决定传送到kubelet。同时，计划删除的pod可以继续在分区节点上运行。 在1.5之前的Kubernetes版本中，节点控制器会从apiserver中强制删除这些无法访问的pod。但是，在1.5及更高版本中，节点控制器不会强制删除容器，直到确认它们已停止在群集中运行。您可以看到可能在无法访问的节点上运行的Pod处于Terminating或Unknown状态。如果节点永久离开群集，如果Kubernetes无法从底层基础架构推断出，则群集管理员可能需要手动删除节点对象。从Kubernetes中删除节点对象会导致节点上运行的所有Pod对象从apiserver中删除，并释放它们的名称。 在版本1.12中，TaintNodesByCondition功能被提升为beta版，因此节点生命周期控制器会自动创建表示条件的 taints 。类似地，调度程序在考虑节点时忽略条件;相反，它会查看Node的污点和Pod的容忍度。 现在，用户可以在旧的调度模型和更灵活的新调度模型之间进行选择。根据旧型号，可以安排没有任何容忍度的Pod。但是可以在该节点上安排容忍特定节点的污点的Pod。 警告：启用此功能会在观察到条件和创建污点之间产生一个小延迟。此延迟通常小于一秒，但它可以增加成功安排但被kubelet拒绝的Pod的数量。 容量描述节点上可用的资源：CPU，内存以及可以在节点上调度的最大pod数。 信息有关节点的一般信息，例如内核版本，Kubernetes版本（kubelet和kube-proxy版本），Docker版本（如果使用），操作系统名称。信息由Kubelet从节点收集。 管理与pod和服务不同，Kubernetes本身并不创建节点：它由Google Compute Engine等云提供商在外部创建，或者存在于物理或虚拟机池中。因此，当Kubernetes创建节点时，它会创建一个表示节点的对象。创建后，Kubernetes会检查节点是否有效。例如，如果您尝试从以下内容创建节点：12345678910&#123; "kind": "Node", "apiVersion": "v1", "metadata": &#123; "name": "10.240.79.157", "labels": &#123; "name": "my-first-k8s-node" &#125; &#125;&#125; Kubernetes在内部创建节点对象（表示），并通过基于metadata.name字段的运行状况检查来验证节点。如果节点有效 - 即，如果所有必需的服务都在运行 - 它有资格运行pod。否则，对于任何群集活动，它将被忽略，直到它变为有效。 注意： Kubernetes保留无效节点的对象，并不断检查它是否有效。您必须显式删除Node对象才能停止此过程。 目前，有三个组件与Kubernetes节点接口交互：节点控制器，kubelet和kubectl。 节点控制器节点控制器是Kubernetes主组件，它管理节点的各个方面。 节点控制器在节点的生命周期中具有多个角色。第一种是在注册时为节点分配CIDR块（如果打开了CIDR分配）。 第二个是使节点控制器的内部节点列表与云提供商的可用计算机列表保持同步。在云环境中运行时，只要节点不健康，节点控制器就会询问云提供商该节点的VM是否仍然可用。如果不是，则节点控制器从其节点列表中删除该节点。 第三是监测节点的健康状况。节点控制器负责在节点变得无法访问时将NodeStatus的NodeReady条件更新为ConditionUnknown（即节点控制器由于某种原因停止接收心跳，例如由于节点关闭），然后从节点中驱逐所有pod （如果节点仍然无法访问，则使用正常终止）。（默认超时为40 --node-monitor-period秒，开始报告ConditionUnknown，之后5米开始驱逐pod。）节点控制器每秒检查每个节点的状态。 在1.13之前的Kubernetes版本中，NodeStatus是节点的心跳。从Kubernetes 1.13开始，节点租用功能作为alpha功能引入（功能门NodeLease， KEP-0009）。启用节点租用功能时，每个节点都有一个关联的Lease对象 kube-node-lease由节点定期更新的命名空间，NodeStatus和节点租约都被视为来自节点的心跳。节点租约经常更新，而NodeStatus仅在有一些更改或经过足够时间时从节点报告为主节点（默认值为1分钟，这比不可达节点的默认超时40秒）。由于节点租约比NodeStatus轻得多，因此从可伸缩性和性能角度来看，此功能使节点心跳显着降低。 在Kubernetes 1.4中，我们更新了节点控制器的逻辑，以便在大量节点到达主站时遇到问题时更好地处理案例（例如，因为主站有网络问题）。从1.4开始，节点控制器在决定pod驱逐时查看集群中所有节点的状态。 在大多数情况下，节点控制器将驱逐率限制为每秒 --node-eviction-rate（默认值0.1），这意味着它不会每10秒从多个节点驱逐pod。 当给定可用区中的节点变得不健康时，节点逐出行为会发生变化。节点控制器同时检查区域中节点的百分比是否不健康（NodeReady条件是ConditionUnknown或ConditionFalse）。如果不健康节点的比例至少为 --unhealthy-zone-threshold（默认为0.55），则驱逐率降低：如果群集较小（即小于或等于--large-cluster-size-threshold节点 - 默认为50）则停止驱逐，否则驱逐率降低为 --secondary-node-eviction-rate（默认0.01）每秒。每个可用区域实施这些策略的原因是因为一个可用区域可能从主服务器分区而其他可用区域保持连接。如果您的群集未跨越多个云提供商可用区域，则只有一个可用区域（整个群集）。 在可用区域之间传播节点的一个关键原因是，当整个区域出现故障时，工作负载可以转移到健康区域。因此，如果区域中的所有节点都不健康，则节点控制器以正常速率驱逐--node-eviction-rate。角落情况是所有区域完全不健康（即群集中没有健康的节点）。在这种情况下，节点控制器假定主连接存在一些问题，并在某些连接恢复之前停止所有驱逐。 从Kubernetes 1.6开始，NodeController还负责驱逐在具有NoExecute污点的节点上运行的pod，当pod不能容忍taints时。此外，作为默认禁用的alpha功能，NodeController负责添加与节点无法访问或未就绪等节点问题相对应的污点。 有关污点和alpha功能的详细信息，请参阅此文档NoExecute。 从版本1.8开始，节点控制器可以负责创建表示节点条件的污点。这是1.8版的alpha功能。 节点自注册当kubelet标志--register-node为true（默认值）时，kubelet将尝试向API服务器注册自己。这是大多数发行版使用的首选模式。 对于自行注册，可以使用以下选项启动kubelet： --kubeconfig - 凭证路径，以向apiserver验证自身。 --cloud-provider - 如何与云提供商交谈以阅读有关自身的元数据。 --register-node - 自动注册API服务器。 --register-with-taints- 使用给定的taints列表注册节点（以逗号分隔&lt;key&gt;=&lt;value&gt;:&lt;effect&gt;）。No-op如果register-node是假的。 --node-ip - 节点的IP地址。 --node-labels- 在群集中注册节点时添加的标签（请参阅1.13+中NodeRestriction准入插件强制执行的标签限制）。 --node-status-update-frequency - 指定kubelet将节点状态发布到master的频率。 当节点授权模式和 NodeRestriction录取插件的启用，kubelets仅被授权创建/修改自己的节点资源。 手动节点管理集群管理员可以创建和修改节点对象。 如果管理员希望手动创建节点对象，请设置kubelet标志 --register-node=false。 管理员可以修改节点资源（无论设置如何--register-node）。修改包括在节点上设置标签并将其标记为不可调度。 节点上的标签可以与pod上的节点选择器结合使用以控制调度，例如，将pod限制为仅有资格在节点的子集上运行。 将节点标记为不可调度可防止将新pod调度到该节点，但不会影响节点上的任何现有pod。这在节点重启等之前作为准备步骤很有用。例如，要标记节点不可调度，请运行以下命令：1kubectl cordon $NODENAME 注意：由DaemonSet控制器创建的Pod绕过Kubernetes调度程序，不遵守节点上的不可调度属性。这假设守护进程属于机器，即使它在准备重新启动时正在耗尽应用程序。 节点容量节点的容量（cpus的数量和内存量）是节点对象的一部分。通常，节点在创建节点对象时注册自己并报告其容量。如果您正在进行手动节点管理，则需要在添加节点时设置节点容量。 Kubernetes调度程序确保节点上的所有pod都有足够的资源。它检查节点上容器请求的总和不大于节点容量。它包括由kubelet启动的所有容器，但不包括由容器运行时直接启动的容器，也不包括在容器外部运行的任何进程。 如果要为非Pod进程显式保留资源，请按照本教程 为系统守护程序保留资源。 API对象Node是Kubernetes REST API中的顶级资源。有关API对象的更多详细信息，请参见： Node API对象。 主节点通信本文档对master（实际上是apiserver）和Kubernetes集群之间的通信路径进行了编目。目的是允许用户自定义其安装以强化网络配置，以便群集可以在不受信任的网络（或云提供商上的完全公共IP）上运行。 群集到Master 掌握群集 群集到Master从集群到主服务器的所有通信路径都在apiserver处终止（其他主服务器组件均未设计为公开远程服务）。在典型部署中，apiserver被配置为在安全HTTPS端口（443）上侦听远程连接，其中启用了一种或多种形式的客户端认证。 应启用一种或多种授权形式，尤其是 在允许匿名请求 或服务帐户令牌的情况下。 应为节点配置群集的公共根证书，以便它们可以安全地连接到apiserver以及有效的客户端凭据。例如，在默认GKE部署中，提供给kubelet的客户端凭证采用客户端证书的形式。请参阅 kubelet TLS bootstrapping 以自动配置kubelet客户端证书。 希望连接到apiserver的Pod可以通过利用服务帐户安全地执行此操作，以便Kubernetes在实例化时自动将公共根证书和有效的承载令牌注入到pod中。该kubernetes服务（在所有名称空间中）配置有虚拟IP地址，该地址被重定向（通过kube-proxy）到apiserver上的HTTPS端点。 主组件还通过安全端口与群集服务器通信。 因此，默认情况下，从群集（节点和节点上运行的节点）到主节点的连接的默认操作模式是安全的，可以在不受信任和/或公共网络上运行。 掌握群集从主服务器（apiserver）到集群有两条主要通信路径。第一个是从apiserver到kubelet进程，它在集群中的每个节点上运行。第二种是通过apiserver的代理功能从apiserver到任何节点，pod或服务。 kubelet的保护者从apiserver到kubelet的连接用于： 获取pod的日志。 附加（通过kubectl）到运行的pod。 提供kubelet的端口转发功能。 这些连接终止于kubelet的HTTPS端点。默认情况下，apiserver不会验证kubelet的服务证书，这会使连接受到中间人攻击，并且 不安全地运行在不受信任的和/或公共网络上。 要验证此连接，请使用该--kubelet-certificate-authority标志为apiserver提供根证书包，以用于验证kubelet的服务证书。 如果无法做到这一点，请 在apiserver和kubelet之间使用SSH隧道，以避免连接不受信任或公共网络。 最后， 应启用Kubelet身份验证和/或授权以保护kubelet API。 节点，pod和服务的apiserver从apiserver到节点，pod或服务的连接默认为纯HTTP连接，因此既未经过身份验证也未加密。它们可以通过前缀https:到API URL中的节点，pod或服务名称在安全HTTPS连接上运行，但它们不会验证HTTPS端点提供的证书，也不会提供客户端凭据，因此在连接将被加密时，它不会提供任何诚信保证。这些连接目前在不受信任和/或公共网络上运行是不安全的。 云控制器管理器的基础概念最初创建云控制器管理器（CCM）概念（不要与二进制混淆），以允许特定于云的供应商代码和Kubernetes核心彼此独立地发展。云控制器管理器与其他主组件（如Kubernetes控制器管理器，API服务器和调度程序）一起运行。它也可以作为Kubernetes插件启动，在这种情况下它运行在Kubernetes之上。 云控制器管理器的设计基于一种插件机制，允许新的云提供商通过使用插件轻松地与Kubernetes集成。有计划在Kubernetes上加入新的云提供商，以及将云提供商从旧模型迁移到新的CCM模型。 本文档讨论了云控制器管理器背后的概念，并提供了有关其相关功能的详细信息。 这是没有云控制器管理器的Kubernetes集群的架构： 设计 CCM的组成部分 CCM的功能 插件机制 授权 供应商实施 群集管理 设计在上图中，Kubernetes和云提供商通过几个不同的组件集成： Kubelet Kubernetes控制器经理 Kubernetes API服务器 CCM整合了前三个组件中的所有依赖于云的逻辑，以创建与云的单一集成点。CCM的新架构如下所示： CCM的组成部分CCM打破了Kubernetes控制器管理器（KCM）的一些功能，并将其作为一个单独的进程运行。具体来说，它打破了KCM中依赖于云的控制器。KCM具有以下依赖于云的控制器循环： 节点控制器 音量控制器 路线控制器 服务控制器 在1.9版中，CCM运行前面列表中的以下控制器： 节点控制器 路线控制器 服务控制器 此外，它还运行另一个名为PersistentVolumeLabels控制器的控制器。此控制器负责在GCP和AWS云中创建的PersistentVolumes上设置区域和区域标签。 注意：故意选择音量控制器不属于CCM。由于涉及复杂性并且由于现有的努力抽象出供应商特定的卷逻辑，因此决定不将卷控制器移动到CCM。 使用CCM支持卷的最初计划是使用Flex卷来支持可插拔卷。然而，正在计划一项名为CSI的竞争性工作来取代Flex。 考虑到这些动态，我们决定在CSI准备好之前进行中间止差测量。 CCM的功能CCM从依赖于云提供商的Kubernetes组件继承其功能。本节基于这些组件构建。 1. Kubernetes控制器经理CCM的大部分功能来自KCM。如上一节所述，CCM运行以下控制循环： 节点控制器 路线控制器 服务控制器 PersistentVolumeLabels控制器 节点控制器节点控制器负责通过从云提供商获取有关在集群中运行的节点的信息来初始化节点。节点控制器执行以下功能： 使用特定于云的区域/区域标签初始化节点。 使用特定于云的实例详细信息初始化节点，例如，类型和大小。 获取节点的网络地址和主机名。 如果节点无响应，请检查云以查看该节点是否已从云中删除。如果已从云中删除该节点，请删除Kubernetes Node对象。 路线控制器Route控制器负责适当地配置云中的路由，以便Kubernetes集群中不同节点上的容器可以相互通信。路径控制器仅适用于Google Compute Engine群集。 服务控制器服务控制器负责监听服务创建，更新和删除事件。根据Kubernetes中当前的服务状态，它配置云负载均衡器（如ELB或Google LB）以反映Kubernetes中的服务状态。此外，它还确保云负载平衡器的服务后端是最新的。 PersistentVolumeLabels控制器PersistentVolumeLabels控制器在创建AWS EBS / GCE PD卷时应用标签。这消除了用户手动设置这些卷上的标签的需要。 这些标签对于pod的计划至关重要，因为这些卷仅限于在它们所在的区域/区域内工作。使用这些卷的任何Pod都需要在同一区域/区域中进行调度。 PersistentVolumeLabels控制器专门为CCM创建; 也就是说，在创建CCM之前它不存在。这样做是为了将Kubernetes API服务器（它是一个许可控制器）中的PV标记逻辑移动到CCM。它不在KCM上运行。 2. Kubelet节点控制器包含kubelet的依赖于云的功能。在引入CCM之前，kubelet负责使用特定于云的详细信息（如IP地址，区域/区域标签和实例类型信息）初始化节点。CCM的引入已将此初始化操作从kubelet转移到CCM。 在这个新模型中，kubelet初始化一个没有特定于云的信息的节点。但是，它会为新创建的节点添加污点，使节点不可调度，直到CCM使用特定于云的信息初始化节点。然后它消除了这种污点。 3. Kubernetes API服务器PersistentVolumeLabels控制器将Kubernetes API服务器的依赖于云的功能移动到CCM，如前面部分所述。 插件机制云控制器管理器使用Go接口允许插入任何云的实现。具体来说，它使用此处定义的CloudProvider接口。 上面突出显示的四个共享控制器的实现，以及一些脚手架以及共享的cloudprovider接口，将保留在Kubernetes核心中。特定于云提供商的实现将在核心之外构建，并实现核心中定义的接口。 有关开发插件的更多信息，请参阅开发Cloud Controller Manager。 授权本节分解了CCM执行其操作时各种API对象所需的访问权限。 节点控制器Node控制器仅适用于Node对象。它需要完全访问get，list，create，update，patch，watch和delete Node对象。 V1 /节点： Get List Create Update Patch Watch Delete 路线控制器路由控制器侦听Node对象创建并适当地配置路由。它需要访问Node对象。 V1 /节点： Get 服务控制器服务控制器侦听Service对象创建，更新和删除事件，然后适当地为这些服务配置端点。 要访问服务，它需要列表和监视访问权限。要更新服务，它需要修补和更新访问权限。 要为服务设置端点，需要访问create，list，get，watch和update。 V1 /服务： List Get Watch Patch Update PersistentVolumeLabels控制器PersistentVolumeLabels控制器侦听PersistentVolume（PV）创建事件，然后更新它们。该控制器需要访问以获取和更新PV。 V1 / PersistentVolume： Get List Watch Update 其他CCM核心的实现需要访问以创建事件，并且为了确保安全操作，它需要访问以创建ServiceAccounts。 V1 /事件： Create Patch Update V1 / ServiceAccount： Create CCM的RBAC ClusterRole如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: cloud-controller-managerrules:- apiGroups: - "" resources: - events verbs: - create - patch - update- apiGroups: - "" resources: - nodes verbs: - '*'- apiGroups: - "" resources: - nodes/status verbs: - patch- apiGroups: - "" resources: - services verbs: - list - patch - update - watch- apiGroups: - "" resources: - serviceaccounts verbs: - create- apiGroups: - "" resources: - persistentvolumes verbs: - get - list - update - watch- apiGroups: - "" resources: - endpoints verbs: - create - get - list - watch - update 供应商实施以下云提供商已实施CCM： Digital Ocean Oracle Azure GCE AWS 群集管理此处提供了有关配置和运行CCM的完整说明 容器镜像您创建Docker镜像并将其推送到仓库，然后在Kubernetes的pod中引用它。 image容器的属性支持与docker命令相同的语法，包括私有仓库和标记。 更新镜像 用清单构建多架构镜像 使用私人仓库 更新镜像默认拉取策略IfNotPresent会导致Kubelet跳过拉动镜像（如果已存在）。如果您想总是强制Docker拉动，可以执行以下操作之一： 将imagePullPolicy容器设置为Always。 省略imagePullPolicy并使用它:latest作为要使用的镜像的标记。 省略imagePullPolicy要使用的镜像和标记。 启用AlwaysPullImages准入控制器。 请注意，您应该避免使用:latest标记，有关详细信息，请参阅配置的最佳实践。 用清单构建多架构图像Docker CLI现在支持以下命令docker manifest中包含的子命令create，annotate并push。这些命令可用于构建和推送清单。您可以使用docker manifest inspect查看清单。 请在此处查看docker文档，请参阅我们在构建工具中如何使用它的示例&amp;i=nope&amp;files=&amp;repos=)。 这些命令完全依赖于Docker CLI，并且完全在Docker CLI上实现。您需要编辑$HOME/.docker/config.json和设置experimental密钥，enabled或者只需在调用CLI命令时将DOCKER_CLI_EXPERIMENTAL环境变量设置为enabled。 注意：请使用Docker 18.06或更高版本，以下版本有错误或不支持实验命令行选项。示例会在containerd下导致问题。 如果您在上传陈旧的清单时遇到问题，只需清理旧的清单$HOME/.docker/manifests即可重新开始。 对于Kubernetes，我们通常使用带后缀的镜像-$(ARCH)。为了向后兼容，请生成带有后缀的旧镜像。我们的想法是生成pause具有所有拱形清单的说明镜像，并说出pause-amd64哪些向后兼容旧配置或YAML文件，这些文件可能硬编码带有后缀的镜像。 使用私人仓库私人仓库管理可能需要密钥才能从中读取图像。凭证可以通过多种方式提供： 使用Google Container Registry Per-cluster 在Google Compute Engine或Google Kubernetes Engine上自动配置 所有pod都可以读取项目的私有仓库 使用AWS EC2容器仓库（ECR） 使用IAM角色和策略来控制对ECR存储库的访问 自动刷新ECR登录凭据 使用Azure容器仓库（ACR） 使用IBM Cloud Container Registry 配置节点以验证私有仓库 所有pod都可以读取任何已配置的私有仓库 需要集群管理员进行节点配置 预拉镜像 所有pod都可以使用节点上缓存的任何镜像 需要root权限才能设置所有节点 在Pod上指定ImagePullSecrets 只有提供自己密钥的pod才能访问私有仓库 下面更详细地描述每个选项。 使用Google Container Registry在Google Compute Engine（GCE）上运行时，Kubernetes对Google Container Registry（GCR）提供原生支持。如果您在GCE或Google Kubernetes Engine上运行群集，只需使用完整的镜像名称（例如gcr.io/my_project/image：tag）。 群集中的所有pod都具有此仓库中镜像的读取权限。 kubelet将使用实例的Google服务帐户向GCR进行身份验证。实例上的服务帐户将具有一个 https://www.googleapis.com/auth/devstorage.read_only，因此它可以从项目的GCR中提取，但不能推送。 使用AWS EC2 Container Registry当节点是AWS EC2实例时，Kubernetes对AWS EC2 Container Registry具有本机支持。 只需ACCOUNT.dkr.ecr.REGION.amazonaws.com/imagename:tag在Pod定义中使用完整的图像名称（例如）。 可以创建pod的群集的所有用户都可以运行使用ECR仓库中任何镜像的pod。 kubelet将获取并定期刷新ECR凭据。它需要以下权限才能执行此操作： ecr:GetAuthorizationToken ecr:BatchCheckLayerAvailability ecr:GetDownloadUrlForLayer ecr:GetRepositoryPolicy ecr:DescribeRepositories ecr:ListImages ecr:BatchGetImage 要求： 您必须使用kubelet版本v1.2.0或更新版本。（例如run /usr/bin/kubelet --version=true）。 如果您的节点位于区域A中且您的注册表位于不同的区域B中，则需要v1.3.0更新版本或更新版本。 ECR必须在您所在的地区提供 故障排除： 验证上述所有要求。 us-west-2在工作站上获取$ REGION（例如）凭据。SSH进入主机并使用这些信用卡手动运行Docker。它有用吗？ 验证kubelet是否正在运行--cloud-provider=aws。 检查kubelet日志（例如journalctl -u kubelet）以获取日志行，例如： plugins.go:56] Registering credential provider: aws-ecr-key provider.go:91] Refreshing cache for provider: *aws_credentials.ecrProvider 使用Azure容器仓库（ACR）使用Azure容器仓库时， 您可以使用管理员用户或服务主体进行身份验证。在任何一种情况下，身份验证都通过标准Docker身份验证完成 这些说明假定使用 azure-cli命令行工具。 您首先需要创建一个仓库并生成凭据，完整的文档可以在Azure容器仓库文档中找到。 创建容器仓库后，您将使用以下凭据登录： DOCKER_USER ：服务主体或管理员用户名 DOCKER_PASSWORD：服务主体密码或管理员用户密码 DOCKER_REGISTRY_SERVER： ${some-registry-name}.azurecr.io DOCKER_EMAIL：${some-email-address} 填好这些变量后，您可以配置Kubernetes Secret并使用它来部署Pod。 使用IBM Cloud Container RegistryIBM Cloud Container Registry提供了一个多租户私有镜像仓库，您可以使用它来安全地存储和共享Docker镜像。默认情况下，集成的漏洞顾问会扫描私有仓库中的镜像，以检测安全问题和潜在漏洞。IBM Cloud帐户中的用户可以访问您的镜像，也可以创建令牌以授予对仓库命名空间的访问权限。 要安装IBM Cloud Container Registry CLI插件并为镜像创建命名空间，请参阅IBM Cloud Container Registry入门。 您可以使用IBM Cloud Container Registry将容器从IBM Cloud公共镜像和私有镜像部署到defaultIBM Cloud Kubernetes Service集群的命名空间中。要将容器部署到其他名称空间，或使用来自其他IBM Cloud Container Registry区域或IBM Cloud帐户的镜像，请创建Kubernetes imagePullSecret。有关更多信息，请参阅从镜像构建容器。 配置节点以验证私有仓库 注意：如果您在Google Kubernetes Engine上运行，则.dockercfg每个节点上都会有一个包含Google Container Registry凭据的节点。你不能使用这种方法。 注意：如果您在AWS EC2上运行并且正在使用EC2容器仓库（ECR），则每个节点上的kubelet将管理和更新ECR登录凭据。你不能使用这种方法 注意：如果您可以控制节点配置，则此方法是合适的。它不能可靠地在GCE和任何其他进行自动节点替换的云提供商上运行。 Docker将私有仓库的密钥存储在$HOME/.dockercfg或$HOME/.docker/config.json文件中。如果您将相同的文件放在下面的搜索路径列表中，则kubelet会在拉取镜像时将其用作凭据提供程序。 {--root-dir:-/var/lib/kubelet}/config.json {cwd of kubelet}/config.json ${HOME}/.docker/config.json /.docker/config.json {--root-dir:-/var/lib/kubelet}/.dockercfg {cwd of kubelet}/.dockercfg ${HOME}/.dockercfg /.dockercfg 注意：您可能必须HOME=/root在环境文件中明确设置kubelet。 以下是配置节点以使用私有仓库的建议步骤。在此示例中，在桌面/笔记本电脑上运行这些： docker login [server]针对要使用的每组凭据运行。这更新$HOME/.docker/config.json。 $HOME/.docker/config.json在编辑器中查看以确保它仅包含您要使用的凭据。 获取节点列表，例如： 如果你想要这些名字： nodes=$(kubectl get nodes -o jsonpath=&#39;{range.items[*].metadata}{.name} {end}&#39;) 如果你想获得IP： nodes=$(kubectl get nodes -o jsonpath=&#39;{range .items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)]}{.address} {end}&#39;) 将本地复制.docker/config.json到上面的搜索路径列表之一。 例如： for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done 通过创建使用私有镜像的pod进行验证，例如：12345678910111213kubectl create -f - &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: private-image-test-1spec: containers: - name: uses-private-image image: $PRIVATE_IMAGE_NAME imagePullPolicy: Always command: [ "echo", "SUCCESS" ]EOFpod/private-image-test-1 created 如果一切正常，那么过了一会儿，你应该看到：12kubectl logs private-image-test-1SUCCESS 如果失败了，那么你会看到：12kubectl describe pods/private-image-test-1 | grep "Failed" Fri, 26 Jun 2015 15:36:13 -0700 Fri, 26 Jun 2015 15:39:13 -0700 19 &#123;kubelet node-i2hq&#125; spec.containers&#123;uses-private-image&#125; failed Failed to pull image "user/privaterepo:v1": Error: image user/privaterepo:v1 not found 您必须确保群集中的所有节点都具有相同的节点.docker/config.json。否则，pod将在某些节点上运行，而无法在其他节点上运行。例如，如果使用节点自动缩放，则每个实例模板都需要包含.docker/config.json或装载包含它的驱动器。 将私有仓库项添加到任何私有仓库中后，所有pod都将具有对镜像的读访问权限.docker/config.json。 预拉图像 注意：如果您在Google Kubernetes Engine上运行，则.dockercfg每个节点上都会有一个包含Google Container Registry凭据的节点。你不能使用这种方法。 注意：如果您可以控制节点配置，则此方法是合适的。它不能可靠地在GCE和任何其他进行自动节点替换的云提供商上运行。 默认情况下，kubelet将尝试从指定的仓库中提取每个镜像。但是，如果imagePullPolicy容器的属性设置为IfNotPresent或Never，则使用本地镜像（分别优先或排他）。 如果您希望依赖预先提取的镜像作为仓库身份验证的替代，则必须确保群集中的所有节点都具有相同的预拉镜像。 这可以用于预加载某些镜像以提高速度，或者作为对私有仓库进行身份验证的替代方法。 所有pod都可以读取任何预拉镜像。 在Pod上指定ImagePullSecrets 注意：此方法目前是Google Kubernetes Engine，GCE以及自动创建节点的任何云提供商的推荐方法。 Kubernetes支持在pod上指定仓库项。 使用Docker配置创建机密运行以下命令，替换相应的大写值：12kubectl create secret docker-registry myregistrykey --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAILsecret/myregistrykey created. 如果需要访问多个仓库，则可以为每个仓库创建一个秘密。 在为Pods提取镜像时，Kubelet会将任何内容合并imagePullSecrets为一个虚拟内容.docker/config.json。 Pod只能在自己的命名空间中引用镜像拉取秘密，因此每个命名空间需要执行一次此过程。 绕过kubectl会产生秘密如果由于某种原因，您需要单个项目中的多个项目.docker/config.json或需要上述命令未给出的控制，那么您可以使用json或yaml创建一个秘密。 务必： 设置数据项的名称 .dockerconfigjson base64编码docker文件并粘贴该字符串，不间断作为字段的值 data[&quot;.dockerconfigjson&quot;] 设置type为kubernetes.io/dockerconfigjson 例：12345678apiVersion: v1kind: Secretmetadata: name: myregistrykey namespace: awesomeappsdata: .dockerconfigjson: UmVhbGx5IHJlYWxseSByZWVlZWVlZWVlZWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGx5eXl5eXl5eXl5eXl5eXl5eXl5eSBsbGxsbGxsbGxsbGxsbG9vb29vb29vb29vb29vb29vb29vb29vb29vb25ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubmdnZ2dnZ2dnZ2dnZ2dnZ2dnZ2cgYXV0aCBrZXlzCg==type: kubernetes.io/dockerconfigjson 如果收到错误消息error: no objects passed to create，则可能表示base64编码的字符串无效。如果收到类似的错误消息Secret &quot;myregistrykey&quot; is invalid: data[.dockerconfigjson]: invalid value ...，则表示数据已成功取消base64编码，但无法解析为.docker/config.json文件。 参考Pod上的imagePullSecrets现在，您可以通过向imagePullSecrets pod定义添加一个部分来创建引用该秘密的pod。1234567891011apiVersion: v1kind: Podmetadata: name: foo namespace: awesomeappsspec: containers: - name: foo image: janedoe/awesomeapp:v1 imagePullSecrets: - name: myregistrykey 需要对使用私有仓库的每个pod执行此操作。 但是，可以通过在serviceAccount资源中设置imagePullSecrets来自动设置此字段。检查将ImagePullSecrets添加到服务帐户以获取详细说明。 您可以将其与每个节点结合使用.docker/config.json。凭证将被合并。这种方法适用于Google Kubernetes Engine。 用例有许多配置私有仓库的解决方案。以下是一些常见用例和建议的解决方案。 群集仅运行非专有（例如开源）镜像。无需隐藏镜像。 在Docker hub上使用公共镜像。 无需配置。 在GCE / Google Kubernetes Engine上，自动使用本地镜像来提高速度和可用性。 群集运行一些专有镜像，这些镜像像应隐藏给公司外部的人员，但对所有群集用户可见。 使用托管的私有Docker仓库。 它可能托管在Docker Hub或其他地方。 如上所述，在每个节点上手动配置.docker / config.json。 或者，使用开放读取访问权限在防火墙后面运行内部私有仓库。 不需要Kubernetes配置。 或者，在使用GCE / Google Kubernetes Engine时，请使用该项目的Google Container Registry。 与集群自动调节相比，它可以比手动节点配置更好地工作。 或者，在更改节点配置不方便的群集上，请使用imagePullSecrets。 具有专有镜像的集群，其中一些需要更严格的访问控制。 确保AlwaysPullImages准入控制器处于活动状态。否则，所有Pod都可能访问所有镜像。 将敏感数据移动到“秘密”资源中，而不是将其打包在镜像中。 一个多租户群集，每个租户都需要拥有私有仓库。 确保AlwaysPullImages准入控制器处于活动状态。否则，所有租户的所有Pod都可能访问所有图像。 运行需要授权的私有仓库。 为每个租户生成仓库凭据，保密，并为每个租户命名空间填充机密。 租户将这个秘密添加到每个命名空间的imagePullSecrets。 容器环境变量此页面描述Container环境中Container可用的资源。 容器环境Kubernetes Container环境为容器提供了几个重要资源： 文件系统，是镜像和一个或多个卷的组合。 有关Container本身的信息。 有关群集中其他对象的信息。 容器信息Container 的主机名是运行Container的Pod的名称。它可以通过 libc中的hostname命令或 gethostname函数调用获得。 Pod名称和命名空间可通过向下API作为环境变量使用 。 Pod定义中的用户定义环境变量也可用于Container，Docker镜像中静态指定的任何环境变量也是如此。 群集信息创建Container时运行的所有服务的列表可作为环境变量用于该Container。这些环境变量与Docker链接的语法相匹配。 对于名为foo的映射到名为bar的Container 的服务，定义了以下变量：12FOO_SERVICE_HOST=&lt;the host the service is running on&gt;FOO_SERVICE_PORT=&lt;the port the service is running on&gt; 服务具有专用IP地址，如果启用了DNS插件，则可通过DNS使用Container 。 运行时类特征状态： Kubernetes v1.12该页面描述了RuntimeClass资源和运行时选择机制。 此功能目前处于alpha状态，意思是：版本名称包含alpha（例如v1alpha1）。可能是马车。启用该功能可能会暴露错误。默认情况下禁用。可随时删除对功能的支持，恕不另行通知。API可能会在以后的软件版本中以不兼容的方式更改，恕不另行通知。由于错误风险增加和缺乏长期支持，建议仅在短期测试集群中使用。 运行时类RuntimeClass是一个alpha功能，用于选择用于运行pod容器的容器运行时配置。 建立作为早期的alpha功能，必须采取一些额外的设置步骤才能使用RuntimeClass功能： 启用RuntimeClass功能门（在apiservers＆kubelets上，需要1.12+版本） 安装RuntimeClass CRD 在节点上配置CRI实现（取决于运行时） 创建相应的RuntimeClass资源 1.启用RuntimeClass feature gate有关启用feature gates的说明，请参见feature gates。必须在apiservers和kubelet上启用RuntimeClass功能门。 2.安装RuntimeClass CRDRuntimeClass CustomResourceDefinition（CRD）可以在Kubernetes git repo的addons目录中找到：kubernetes / cluster / addons / runtimeclass / runtimeclass_crd.yaml 安装CRD kubectl apply -f runtimeclass_crd.yaml。 3.在节点上配置CRI实现使用RuntimeClass进行选择的配置取决于CRI实现。有关如何配置的信息，请参阅CRI实现的相应文档。由于这是一个alpha功能，并非所有CRI都支持多个RuntimeClasses。 注意： RuntimeClass当前假定整个集群中的同类节点配置（这意味着所有节点的配置方式与容器运行时相同）。任何异构性（变化的配置）必须通过调度功能独立于RuntimeClass进行管理（请参阅将Pod分配给节点）。 配置具有相应的RuntimeHandler名称，由RuntimeClass引用。RuntimeHandler必须是有效的DNS 1123子域（字母数字+ -和.字符）。 4.创建相应的RuntimeClass资源步骤3中的配置设置应各自具有关联的RuntimeHandler名称，用于标识配置。对于每个RuntimeHandler（以及可选的空””处理程序），创建相应的RuntimeClass对象。 RuntimeClass资源当前只有2个重要字段：RuntimeClass name（metadata.name）和RuntimeHandler（spec.runtimeHandler）。对象定义如下所示：1234567apiVersion: node.k8s.io/v1alpha1 # RuntimeClass is defined in the node.k8s.io API groupkind: RuntimeClassmetadata: name: myclass # The name the RuntimeClass will be referenced by # RuntimeClass is a non-namespaced resourcespec: runtimeHandler: myconfiguration # The name of the corresponding CRI configuration 注意：建议将RuntimeClass写入操作（create / update / patch / delete）限制为群集管理员。这通常是默认值。有关详细信息，请参阅授权概述。 用法为集群配置RuntimeClasses后，使用它们非常简单。runtimeClassName在Pod规范中指定a 。例如：1234567apiVersion: v1kind: Podmetadata: name: mypodspec: runtimeClassName: myclass # ... 这将指示Kubelet使用命名的RuntimeClass来运行此pod。如果命名的RuntimeClass不存在，或者CRI无法运行相应的处理程序，则pod将进入 Failed终端阶段。查找错误消息的相应事件。 如果未runtimeClassName指定，则将使用默认的RuntimeHandler，这相当于禁用RuntimeClass功能时的行为。 容器生命周期钩子此页面描述了kubelet管理的容器如何使用Container生命周期钩子框架来运行在管理生命周期中由事件触发的代码。 概观 集装箱挂钩 概观类似于许多具有组件生命周期钩子的编程语言框架，例如Angular，Kubernetes为Containers提供了生命周期钩子。钩子使Container能够了解其管理生命周期中的事件，并在执行相应的生命周期钩子时运行在处理程序中实现的代码。 容器钩子有两个暴露给容器的钩子： PostStart 在创建容器后立即执行此挂钩。但是，无法保证挂钩将在容器ENTRYPOINT之前执行。没有参数传递给处理程序。 PreStop 在容器终止之前立即调用此挂钩。它是阻塞的，意味着它是同步的，所以它必须在删除容器的调用之前完成。没有参数传递给处理程序。 终止行为的更详细描述可以在终端中找到 。 钩子处理程序实现容器可以通过实现和注册该钩子的处理程序来访问钩子。可以为Container实现两种类型的钩子处理程序： Exec - 执行特定命令，例如pre-stop.sh，在Container的cgroups和名称空间内。命令消耗的资源将根据Container计算。 HTTP - 对Container上的特定端点执行HTTP请求。 钩子处理程序执行调用Container生命周期管理挂钩时，Kubernetes管理系统会在为该挂钩注册的Container中执行处理程序。 钩子处理程序调用在包含Container的Pod的上下文中是同步的。这意味着对于一个PostStart钩子，Container ENTRYPOINT和钩子异步发射。但是，如果挂钩运行或挂起太长时间，则Container无法达到某种running状态。 PreStop钩子的行为类似。如果钩子在执行期间挂起，则Pod阶段将保持Terminating状态并在terminationGracePeriodSecondspod结束后被杀死。如果一个 PostStart或PreStophook失败，则会终止Container。 用户应使其钩子处理程序尽可能轻量级。但是，有些情况下，长时间运行的命令是有意义的，例如在停止Container之前保存状态。 挂钩送货保证钩子传递至少是一次，这意味着可以为任何给定事件多次调用钩子，例如for PostStart或PreStop。由钩子实现来正确处理这个问题。 通常，只进行单次交付。例如，如果HTTP挂钩接收器关闭且无法获取流量，则不会尝试重新发送。然而，在一些罕见的情况下，可能会发生双重递送。例如，如果一个kubelet在发送一个钩子的过程中重新启动，那么在该kubelet重新启动后可能会重新发送一个钩子。 调试Hook处理程序在Pod事件中不公开Hook处理程序的日志。如果处理程序由于某种原因失败，它会广播一个事件。因为PostStart，这是FailedPostStartHook事件，因为PreStop这是FailedPreStopHook事件。您可以通过运行来查看这些事件kubectl describe pod &lt;pod_name&gt;。以下是运行此命令的一些事件输出示例：123456789101112Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 &#123;default-scheduler &#125; Normal Scheduled Successfully assigned test-1730497541-cq1d2 to gke-test-cluster-default-pool-a07e5d30-siqd 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Pulling pulling image "test:1.0" 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Created Created container with docker id 5c6a256a2567; Security:[seccomp=unconfined] 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Pulled Successfully pulled image "test:1.0" 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Started Started container with docker id 5c6a256a2567 38s 38s 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Killing Killing container with docker id 5c6a256a2567: PostStart handler: Error executing in Docker Container: 1 37s 37s 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Killing Killing container with docker id 8df9fdfd7054: PostStart handler: Error executing in Docker Container: 1 38s 37s 2 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; Warning FailedSync Error syncing pod, skipping: failed to "StartContainer" for "main" with RunContainerError: "PostStart handler: Error executing in Docker Container: 1" 1m 22s 2 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Warning FailedPostStartHook WorkloadsPodsPod概述此页面概述Pod了Kubernetes对象模型中最小的可部署对象。 了解Pods 使用Pods Pod模板 了解Pods一个pod是在创建或部署Kubernetes对象模型Kubernetes-最小最简单的单元的基本构建块。Pod表示群集上正在运行的进程。 Pod封装了一个应用程序容器（或者，在某些情况下，多个容器），存储资源，一个唯一的网络IP以及控制容器应该如何运行的选项。Pod表示部署单元：Kubernetes中的单个应用程序实例，可能包含单个容器或少量紧密耦合且共享资源的容器。 Docker是Kubernetes Pod中最常用的容器运行时，但Pods也支持其他容器运行时。 Kubernetes集群中的Pod可以以两种主要方式使用： 运行单个容器的Pod。“one-container-per-Pod”模型是最常见的Kubernetes用例; 在这种情况下，您可以将Pod视为单个容器的包装，而Kubernetes直接管理Pod而不是容器。 运行多个需要协同工作的容器的Pod。Pod可以封装由多个共址容器组成的应用程序，这些容器紧密耦合并需要共享资源。这些共处一地的容器可能形成一个统一的服务单元 - 一个容器从共享卷向公众提供文件，而一个单独的“sidecar”容器刷新或更新这些文件。Pod将这些容器和存储资源作为单个可管理实体包装在一起。 该Kubernetes博客对pod用例一些额外的信息。有关更多信息，请参阅： 分布式系统工具包：复合容器的模式 容器设计模式 每个Pod都用于运行给定应用程序的单个实例。如果要水平扩展应用程序（例如，运行多个实例），则应使用多个Pod，每个实例一个。在Kubernetes中，这通常被称为复制。复制Pod通常由称为Controller的抽象创建和管理。有关更多信息，请参阅Pod和控制器。 Pod如何管理多个容器Pod旨在支持多个协作流程（作为容器），形成一个有凝聚力的服务单元。Pod中的容器自动位于群集中的同一物理或虚拟机上，并共同调度。容器可以共享资源和依赖关系，彼此通信，并协调它们何时以及如何终止。 请注意，在单个Pod中对多个共存和共同管理的容器进行分组是一个相对高级的用例。您应该仅在容器紧密耦合的特定实例中使用此模式。例如，您可能有一个容器充当共享卷中文件的Web服务器，以及一个单独的“sidecar”容器，用于从远程源更新这些文件，如下图所示： pod diagram Pod为其组成容器提供两种共享资源：网络和存储。 联网 每个Pod都分配有唯一的IP地址。Pod中的每个容器都共享网络命名空间，包括IP地址和网络端口。Pod内的容器可以使用相互通信localhost。当Pod中的容器与Pod 外部的实体通信时，它们必须协调它们如何使用共享网络资源（例如端口）。 存储 Pod可以指定一组共享存储卷。Pod中的所有容器都可以访问共享卷，允许这些容器共享数据。如果需要重新启动其中一个容器，则卷还允许Pod中的持久数据存活。见卷上Kubernetes如何实现一个pod里的共享存储更多的信息。 使用Pods你很少直接在Kubernetes - 甚至是单身Pod中创建单独的Pod。这是因为Pods被设计为相对短暂的一次性实体。当创建Pod（由您直接创建或由Controller间接创建）时，它将被安排在群集中的节点上运行。Pod保留在该节点上，直到进程终止，pod对象被删除，pod 因资源不足而被驱逐，或者Node失败。 注意：不应将重新启动Pod重新启动Pod中的容器。Pod本身不会运行，但是容器运行的环境会持续存在，直到删除为止。 pod本身不能自我修复。如果将Pod调度到失败的节点，或者调度操作本身失败，则删除Pod; 同样，由于缺乏资源或节点维护，Pod将无法在驱逐中存活。Kubernetes使用更高级别的抽象，称为Controller，它处理管理相对可处理的Pod实例的工作。因此，虽然可以直接使用Pod，但在Kubernetes中使用Controller管理pod更为常见。见pod和控制器上Kubernetes如何使用控制器来实现pod缩放和愈合的更多信息。 pod和控制器Controller可以为您创建和管理多个Pod，处理复制和部署，并在集群范围内提供自我修复功能。例如，如果节点发生故障，Controller可能会通过在不同节点上安排相同的替换来自动替换Pod。 包含一个或多个pod的控制器的一些示例包括： 部署 StatefulSet DaemonSet 通常，控制器使用您提供的Pod模板来创建它负责的Pod。 Pod模板Pod模板是pod规范，包含在其他对象中，例如 Replication Controllers，Jobs和 DaemonSets。控制器使用Pod模板制作实际的pod。下面的示例是Pod的简单清单，其中包含一个打印消息的容器。1234567891011apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! &amp;&amp; sleep 3600'] pod模板不是指定所有副本的当前所需状态，而是像cookie 切割机。切割 cookie后，cookie与切割机无关。没有“量子纠缠”。对模板的后续更改甚至切换到新模板对已创建的pod没有直接影响。类似地，随后可以直接更新由复制控制器创建的pod。这与pod有意对比，pod确实指定了属于pod的所有容器的当前所需状态。这种方法从根本上简化了系统语义并增加了原语的灵活性。 Podspods是可以创建和管理Kubernetes计算的最小可部署单元。 什么是Pod？ pod的动机 pod的使用 考虑的替代方案 pod的耐久性（或缺乏） 终止pod pod容器的特权模式 API对象 什么是Pod？一个pod（如在whales或pea pod中）是一组一个或多个容器（如Docker容器），具有共享存储/网络，以及如何运行容器的规范。pod的内容始终位于同一位置并共同调度，并在共享上下文中运行。pod模拟特定于应用程序的“逻辑主机” - 它包含一个或多个相对紧密耦合的应用程序容器 - 在预容器世界中，在同一物理或虚拟机上执行意味着在同一逻辑主机上执行。 虽然Kubernetes支持的容器运行时间多于Docker，但Docker是最常见的运行时，它有助于用Docker术语描述pod。 pod的共享上下文是一组Linux命名空间，cgroup，以及可能的隔离方面 - 与隔离Docker容器相同的东西。在pod的上下文中，各个应用程序可能会应用进一步的子隔离。 Pod中的容器共享IP地址和端口空间，并且可以通过它们找到彼此localhost。他们还可以使用标准的进程间通信（如SystemV信号量或POSIX共享内存）相互通信。不同pod中的容器具有不同的IP地址，并且在没有特殊配置的情况下无法通过IPC进行通信 。这些容器通常通过Pod IP地址相互通信。 pod中的应用程序还可以访问共享卷，共享卷被定义为pod的一部分，可以安装到每个应用程序的文件系统中。 就Docker构造而言，pod被建模为一组具有共享命名空间和共享卷的Docker容器 。 与单个应用程序容器一样，pod被认为是相对短暂的（而不是持久的）实体。正如在pod的生命周期中所讨论的，创建pod，分配唯一ID（UID），并调度到它们保留的节点，直到终止（根据重启策略）或删除。如果节点终止，则在超时期限之后，将调度计划到该节点的Pod进行删除。给定的pod（由UID定义）不会“重新安排”到新节点; 相反，它可以被相同的pod替换，如果需要，甚至可以使用相同的名称，但是使用新的UID（有关更多详细信息，请参阅复制控制器）。 当某些东西被认为具有与容量相同的生命周期时，例如卷，这意味着只要该容器（具有该UID）存在就存在。如果由于任何原因删除了该pod，即使创建了相同的替换，相关的东西（例如卷）也会被销毁并重新创建。 pod图一个多容器窗格，包含文件提取程序和Web服务器，该服务器使用持久卷在容器之间共享存储。 pod的动机管理Pod是多个合作过程模式的模型，形成了一个有凝聚力的服务单元。它们通过提供比其组成应用程序集更高级别的抽象来简化应用程序部署和管理。Pod用作部署，水平扩展和复制的单元。对容器中的容器自动处理共置（共同调度），共享命运（例如终止），协调复制，资源共享和依赖关系管理。 资源共享和沟通Pod可以实现其成员之间的数据共享和通信。 pod中的应用程序都使用相同的网络命名空间（相同的IP和端口空间），因此可以相互“找到”并使用它们进行通信localhost。因此，pod中的应用程序必须协调它们对端口的使用。每个pod在平面共享网络空间中具有IP地址，该网络空间与网络上的其他物理计算机和pod完全通信。 主机名设置为pod中应用程序容器的pod名称。关于网络的更多细节。 除了定义在pod中运行的应用程序容器之外，pod还指定了一组共享存储卷。卷使数据能够在容器重新启动后继续存在，并在容器内的应用程序之间共享。 pod的使用Pod可用于托管垂直集成的应用程序堆栈（例如LAMP），但其主要动机是支持共址，共同管理的帮助程序，例如： 内容管理系统，文件和数据加载器，本地缓存管理器等。 日志和检查点备份，压缩，旋转，快照等 数据变更观察者，日志零售商，日志和监控适配器，活动发布者等。 代理，网桥和适配器 控制器，管理器，配置器和更新器 通常，单个pod不用于运行同一应用程序的多个实例。 有关更长的说明，请参阅分布式系统工具包：复合容器的模式。 考虑的替代方案为什么不在一个（Docker）容器中运行多个程序？ 透明度。使基础架构内的容器对基础架构可见，使基础架构能够为这些容器提供服务，例如进程管理和资源监视。这为用户提供了许多便利。 解耦软件依赖关系。各个容器可以独立地进行版本化，重建和重新部署。Kubernetes甚至有一天可能会支持单个容器的实时更新。 便于使用。用户无需运行自己的流程管理器，担心信号和退出代码传播等。 效率。由于基础设施承担更多责任，因此集装箱的重量可以更轻。 为什么不支持基于亲和力的容器协同调度？ 这种方法可以提供协同定位，但不会提供pod的大部分好处，例如资源共享，IPC，保证命运共享和简化管理。 pod的耐久性（或缺乏）pod不应被视为耐用实体。它们将无法在调度故障，节点故障或其他驱逐（例如由于缺乏资源）或节点维护的情况下存活。 通常，用户不需要直接创建pod。他们应该几乎总是使用控制器，即使是singletons，例如， 部署。控制器提供集群范围的自我修复，以及复制和部署管理。像StatefulSet这样的控制器 也可以为有状态的pod提供支持。 使用集合API作为主要的面向用户的原语在集群调度系统中相对常见，包括Borg，Marathon，Aurora和Tupperware。 Pod作为基元公开，以便于： 调度程序和控制器可插拔性 支持pod级操作，无需通过控制器API“代理”它们 pod生命周期与控制器生命周期的解耦，例如引导 控制器和服务的分离 - 端点控制器只是监视pod 具有集群级功能的Kubelet级功能的清晰组合 - Kubelet实际上是“pod控制器” 高可用性应用程序，它们将期望在终止之前更换pod，并且肯定在删除之前，例如在计划驱逐或图像预取的情况下。 终止pod因为pod表示集群中节点上的正在运行的进程，所以允许这些进程在不再需要时优雅地终止（与使用KILL信号猛烈杀死并且没有机会清理）非常重要。用户应该能够请求删除并知道进程何时终止，但也能够确保删除最终完成。当用户请求删除pod时，系统会在允许pod强制终止之前记录预期的宽限期，并将TERM信号发送到每个容器中的主进程。宽限期到期后，KILL信号将发送到这些进程，然后从API服务器中删除该pod。如果在等待进程终止时重新启动Kubelet或容器管理器， 一个示例流程： 用户发送删除Pod的命令，默认宽限期（30秒） API服务器中的Pod随着时间的推移而更新，其中Pod被视为“死”以及宽限期。 在客户端命令中列出时，Pod显示为“终止” （与3同时）当Kubelet看到Pod已被标记为终止，因为已经设置了2中的时间，它开始了pod关闭过程。 如果其中一个Pod的容器定义了一个preStop挂钩，则会在容器内部调用它。如果在preStop宽限期到期后钩子仍在运行，则以小（2秒）延长的宽限期调用步骤2。 容器被发送TERM信号。请注意，并非Pod中的所有容器都会同时收到TERM信号，并且preStop如果它们关闭的顺序很重要，则每个容器都需要一个钩子。 （与3同时）Pod从端点列表中删除以进行维护，并且不再被视为复制控制器的运行pod集的一部分。缓慢关闭的窗格无法继续提供流量，因为负载平衡器（如服务代理）会将其从旋转中移除。 当宽限期到期时，仍然在Pod中运行的任何进程都将被SIGKILL杀死。 Kubelet将通过设置宽限期0（立即删除）完成删除API服务器上的Pod。Pod从API中消失，不再从客户端可见。 默认情况下，所有删除在30秒内都是正常的。该kubectl delete命令支持--grace-period=&lt;seconds&gt;允许用户覆盖默认值并指定其自己的值的选项。值0force删除 pod。在kubectl版本&gt; = 1.5时，必须指定一个额外的标志--force一起--grace-period=0，以执行力的缺失。 强制删除pod强制删除pod被定义为立即从群集状态和etcd删除pod。当执行强制删除时，许可证持有者不会等待来自kubelet的确认该pod已在其运行的节点上终止。它会立即删除API中的pod，以便可以使用相同的名称创建新的pod。在节点上，设置为立即终止的pod在被强制终止之前仍将被给予一个小的宽限期。 强制删除可能对某些pod有潜在危险，应谨慎执行。如果是StatefulSet pod，请参阅任务文档以从StatefulSet中删除 Pod 。 pod容器的特权模式从Kubernetes v1.1开始，pod中的任何容器都可以使用容器规范中的privileged标志启用特权模式SecurityContext。这对于想要使用Linux功能（如操作网络堆栈和访问设备）的容器非常有用。容器内的进程获得与容器外部进程可用的几乎相同的权限。使用特权模式，将网络和卷插件编写为不需要编译到kubelet的独立窗格应该更容易。 如果主服务器正在运行Kubernetes v1.1或更高版本，并且节点运行的版本低于v1.1，那么api-server将接受新的特权pod，但不会启动。他们将处于待决状态。如果用户呼叫kubectl describe pod FooPodName，用户可以查看pod处于暂挂状态的原因。describe命令输出中的events表将说：1Error validating pod "FooPodName"."FooPodNamespace" from api, ignoring: spec.containers[0].securityContext.privileged: forbidden '&lt;*&gt;(0xc2089d3248)true' 如果主服务器运行的版本低于v1.1，则无法创建特权pod。如果用户尝试创建具有特权容器的pod，则用户将收到以下错误：1The Pod "FooPodName" is invalid. spec.containers[0].securityContext.privileged: forbidden '&lt;*&gt;(0xc20b222db0)true' API对象Pod是Kubernetes REST API中的顶级资源。有关API对象的更多详细信息，请参阅： Pod API对象。 Pod生命周期该页面描述了Pod的生命周期。 Pod阶段 Pod条件 容器探针 Pod和Container状态 Pod准备gate 重启政策 Pod寿命 例子 Pod阶段Pod的status字段是 PodStatus 对象，它有一个phase字段。 Pod的阶段是Pod在其生命周期中的简单，高级摘要。该阶段不是对Container或Pod状态的全面观察汇总，也不是一个综合状态机。 Pod阶段值的数量和含义受到严密保护。除了这里记录的内容之外，没有任何关于具有给定phase值的Pod的假设。 以下是可能的值phase： 值 描述 Pending Pod已被Kubernetes系统接受，但尚未创建一个或多个Container图像。这包括计划之前的时间以及通过网络下载图像所花费的时间，这可能需要一段时间。 Running Pod已绑定到节点，并且已创建所有Container。至少有一个Container仍在运行，或者正在启动或重新启动。 Succeeded Pod中的所有容器都已成功终止，并且不会重新启动。 Failed Pod中的所有容器都已终止，并且至少有一个Container已终止失败。也就是说，Container要么退出非零状态，要么被系统终止。 Unknown 由于某种原因，无法获得Pod的状态，这通常是由于与Pod的主机通信时出错。 Pod条件Pod有一个PodStatus，它有一个PodConditions数组， Pod已经或没有通过它。PodCondition数组的每个元素都有六个可能的字段： 该lastProbeTime字段提供上次探测Pod条件的时间戳。 该lastTransitionTime字段提供Pod最后从一个状态转换到另一个状态的时间戳。 该message字段是人类可读的消息，指示有关转换的详细信息。 该reason字段是该条件最后一次转换的唯一，单字，CamelCase原因。 该status字段是一个字符串，可能的值为“ True”，“ False”和“ Unknown”。 该type字段是一个包含以下可能值的字符串： PodScheduled：Pod已被安排到一个节点; Ready：Pod可以提供请求，应该添加到所有匹配服务的负载平衡池中; Initialized：所有init容器 都已成功启动; Unschedulable：调度程序现在无法调度Pod，例如由于缺少资源或其他限制; ContainersReady：Pod中的所有容器都已准备就绪。 容器探针一个探头是通过周期性地执行的诊断kubelet 上的容器。为了执行诊断，kubelet调用Container实现的 Handler。有三种类型的处理程序： ExecAction：在Container内执行指定的命令。如果命令以状态代码0退出，则认为诊断成功。 TCPSocketAction：对指定端口上的Container的IP地址执行TCP检查。如果端口打开，则诊断被认为是成功的。 HTTPGetAction：对指定端口和路径上的Container的IP地址执行HTTP Get请求。如果响应的状态代码大于或等于200且小于400，则认为诊断成功。 每个探针都有三个结果之一： 成功：Container通过了诊断。 失败：容器未通过诊断。 未知：诊断失败，因此不应采取任何措施。 在运行容器时，kubelet可以选择性地执行和响应两种探测器： livenessProbe：指示Container是否正在运行。如果活动探测失败，则kubelet会杀死Container，并且Container将受其重启策略的约束。如果Container未提供活动探测，则默认状态为Success。 readinessProbe：指示Container是否已准备好为请求提供服务。如果准备就绪探测失败，则端点控制器会从与Pod匹配的所有服务的端点中删除Pod的IP地址。初始延迟之前的默认准备状态是Failure。如果Container未提供就绪探测，则默认状态为Success。 什么时候应该使用活力或准备探针？如果您的Container中的进程在遇到问题或变得不健康时能够自行崩溃，则您不一定需要活动探测器; kubelet将根据Pod的内容自动执行正确的操作restartPolicy。 如果您希望在探测失败时杀死并重新启动Container，则指定活动探测，并指定restartPolicyAlways或OnFailure。 如果您只想在探测成功时开始向Pod发送流量，请指定准备探测。在这种情况下，准备情况探测可能与活动探测相同，但规范中存在准备探测意味着Pod将在不接收任何流量的情况下启动，并且仅在探测开始成功后才开始接收流量。 如果Container需要在启动期间处理大型数据，配置文件或迁移，请指定就绪性探针。 如果您希望Container能够自行维护，您可以指定一个就绪探针，用于检查特定于就绪状态的端点，该端点与活动探针不同。 请注意，如果您只想在删除Pod时排除请求，则不一定需要准备探测; 在删除时，无论准备情况探测是否存在，Pod都会自动将其置于未准备状态。Pod在等待Pod中的容器停止时仍处于未准备状态。 有关如何设置活动或准备情况探测的详细信息，请参阅 配置活动和准备探测。 Pod和Container状态有关Pod容器状态的详细信息，请参阅 PodStatus 和 ContainerStatus。请注意，报告为Pod状态的信息取决于当前的 ContainerState。 Pod准备gate特征状态： Kubernetes v1.12 此功能目前处于测试状态 为了通过注入额外的反馈或信号来增加Pod准备的可扩展性PodStatus，Kubernetes 1.11引入了一个名为Pod ready ++的功能。您可以使用新的字段ReadinessGate中PodSpec指定波德准备进行评估附加条件。如果Kubernetes在status.conditionsPod 的字段中找不到这样的条件，则条件的状态默认为“ False”。以下是一个例子：12345678910111213141516171819Kind: Pod...spec: readinessGates: - conditionType: "www.example.com/feature-1"status: conditions: - type: Ready # this is a builtin PodCondition status: "True" lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z - type: "www.example.com/feature-1" # an extra PodCondition status: "False" lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z containerStatuses: - containerID: docker://abcd... ready: true... 新Pod条件必须符合Kubernetes 标签密钥格式。由于该kubectl patch命令仍然不支持修补对象状态，因此必须PATCH使用其中一个KubeClient库通过操作注入新的Pod条件。 随着新Pod条件的引入，只有 当以下两个语句都成立时，才会评估Pod是否就绪： Pod中的所有容器都已准备就绪。 指定的所有条件ReadinessGates均为“ True”。 为了便于对Pod准备评估进行此更改，ContainersReady引入了一个新的Pod条件 来捕获旧的Pod Ready条件。 在K8s 1.11中，作为alpha功能，必须通过将PodReadinessGates 功能门设置 为true 来明确启用“Pod Ready ++”功能。 在K8s 1.12中，默认情况下启用该功能。 重启政策PodSpec的restartPolicy字段可能包含Always，OnFailure和Never。默认值为Always。 restartPolicy适用于Pod中的所有容器。restartPolicy仅指由同一节点上的kubelet重新启动Container。由kubelet重新启动的已退出容器将以指数退避延迟（10秒，20秒，40秒……）重新启动，上限为五分钟，并在成功执行十分钟后重置。正如Pods文档中所讨论的 ，一旦绑定到节点，Pod将永远不会被反弹到另一个节点。 Pod寿命一般来说，pod不会消失，直到有人摧毁它们。这可能是人或控制者。此规则的唯一例外是具有phase成功或失败超过一定持续时间（由terminated-pod-gc-thresholdmaster确定）的Pod将过期并自动销毁。 有三种控制器可供选择： 使用Job for Pods预期终止，例如批量计算。作业仅适用于 restartPolicy等于OnFailure或Never的Pod。 对不希望终止的Pod（例如，Web服务器）使用ReplicationController， ReplicaSet或 Deployment。ReplicationControllers仅适用于具有restartPolicyAlways的Pod。 使用需要为每台计算机运行一个的Pod的DaemonSet，因为它们提供特定于计算机的系统服务。 所有三种类型的控制器都包含PodTemplate。建议创建适当的控制器并让它创建Pod，而不是自己直接创建Pod。这是因为Pods单独对机器故障没有弹性，但是控制器是。 如果节点死亡或与群集的其余部分断开连接，Kubernetes会应用策略phase将丢失节点上的所有Pod设置为Failed。 例子高级活动探测示例活动探测由kubelet执行，因此所有请求都在kubelet网络名称空间中进行。12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: labels: test: liveness name: liveness-httpspec: containers: - args: - /server image: k8s.gcr.io/liveness livenessProbe: httpGet: # when "host" is not defined, "PodIP" will be used # host: my-host # when "scheme" is not defined, "HTTP" scheme will be used. Only "HTTP" and "HTTPS" are allowed # scheme: HTTPS path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 15 timeoutSeconds: 1 name: liveness 示例状态 Pod正在运行并有一个Container。集装箱出口成功。 记录完成事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：Pod phase成功。 从不：Pod phase成功。 Pod正在运行并有一个Container。容器退出失败。 记录失败事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：Pod phase变得失败。 Pod正在运行并有两个容器。容器1出现故障。 记录失败事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：不要重启容器; Pod phase保持运行状态。 如果Container 1未运行，并且Container 2退出： 记录失败事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：Pod phase变得失败。 Pod正在运行并有一个Container。容器耗尽内存。 记录失败事件。 记录OOM事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：记录失败事件; Pod phase保持运行状态。 Pod正在运行，磁盘已经死亡。 杀死所有容器。 记录适当的事件。 Pod phase变得失败。 如果在控制器下运行，Pod将在其他位置重新创建。 Pod正在运行，其节点已分段。 杀死所有容器。 记录适当的事件。 Pod phase变得失败。 如果在控制器下运行，Pod将在其他位置重新创建。 初始容器此页面提供了Init Containers的概述，它是在应用程序容器之前运行的专用容器，可以包含应用程序映像中不存在的实用程序或设置脚本。 了解Init容器 Init容器可以用于什么？ 详细的行为 支持和兼容性 了解Init容器一个pod能够在其内运行的应用程序的多个容器，但它也可以有一个或多个初始化容器，该容器的应用容器启动之前运行。 Init容器与常规容器完全相同，除了： 他们总是跑完成。 每个人必须在下一个启动之前成功完成。 如果Init容器的Init容器失败，Kubernetes会重复重启Pod，直到Init容器成功。但是，如果Pod具有restartPolicyNever，则不会重新启动。 要将Container指定为Init容器，请将initContainersPodSpec上的字段添加 为应用程序数组旁边的Container类型的JSON containers数组。init容器的状态在.status.initContainerStatuses字段中作为容器状态的数组返回（类似于.status.containerStatuses字段）。 与常规容器的差异Init Containers支持应用容器的所有字段和功能，包括资源限制，卷和安全设置。但是，Init容器的资源请求和限制的处理方式略有不同，这些内容在下面的参考资料中有说明。此外，Init Containers不支持就绪探针，因为它们必须在Pod准备好之前运行完成。 如果为Pod指定了多个Init容器，则按顺序一次运行一个Container。每一个都必须在下一次运行之前成功。当所有Init容器都运行完成后，Kubernetes会初始化Pod并像往常一样运行应用程序容器。 Init容器可以用于什么？由于Init Containers具有来自应用容器的单独镜像，因此它们对于启动相关代码具有一些优势： 出于安全原因，它们可以包含并运行不希望包含在应用容器镜像中的实用程序。 它们可以包含应用程序镜像中不存在的用于设置的实用程序或自定义代码。例如，没有必要使镜像FROM的另一个镜像只使用像工具 sed，awk，python，或dig在安装过程中。 应用程序映像构建器和部署者角色可以独立工作，而无需共同构建单个应用程序镜像。 他们使用Linux命名空间，以便他们从应用程序容器中获得不同的文件系统视图。因此，他们可以访问应用容器无法访问的秘密。 它们在任何应用程序容器启动之前运行完成，而应用程序容器并行运行，因此Init容器提供了一种简单的方法来阻止或延迟应用容器的启动，直到满足一组前置条件。 例子以下是有关如何使用Init Containers的一些想法： 等待使用shell命令创建服务，例如： 我在{1..100}; 做睡觉1; 如果挖我的服务; 然后退出0; 网络连接; 完成; 退出1 使用以下命令从向下API向远程服务器注册此Pod： curl -X POST http：// $ MANAGEMENT_SERVICE_HOST：$ MANAGEMENT_SERVICE_PORT / register -d’instal = $（）IP = $（）” 等待一段时间，然后使用类似命令启动app Container sleep 60。 将git存储库克隆到卷中。 将值放入配置文件并运行模板工具以动态生成主应用程序Container的配置文件。例如，将POD_IP值放在配置中，并使用Jinja生成主应用程序配置文件。 可以在StatefulSets文档 和Production Pods指南中找到更详细的用法示例。 初始容器正在使用中以下针对Kubernetes 1.5的yaml文件概述了一个具有两个Init容器的简单Pod。第一个等待，myservice第二个等待mydb。一旦两个容器完成，Pod就会开始。123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myapp annotations: pod.beta.kubernetes.io/init-containers: '[ &#123; "name": "init-myservice", "image": "busybox", "command": ["sh", "-c", "until nslookup myservice; do echo waiting for myservice; sleep 2; done;"] &#125;, &#123; "name": "init-mydb", "image": "busybox", "command": ["sh", "-c", "until nslookup mydb; do echo waiting for mydb; sleep 2; done;"] &#125; ]'spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] Kubernetes 1.6中有一种新语法，尽管旧的注释语法仍适用于1.6和1.7。新语法必须用于1.8或更高版本。我们已将Init Containers的声明移至spec：123456789101112131415161718apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] initContainers: - name: init-myservice image: busybox command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'] - name: init-mydb image: busybox command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'] 1.5语法仍适用于1.6，但我们建议使用1.6语法。在Kubernetes 1.6中，Init Containers在API中成为了一个领域。beta注释在1.6和1.7中仍然受到尊重，但在1.8或更高版本中不受支持。 下面YAML文件概述了mydb与myservice服务：12345678910111213141516171819kind: ServiceapiVersion: v1metadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9376---kind: ServiceapiVersion: v1metadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9377 可以使用以下命令启动和调试此Pod：12345678910111213141516171819202122232425262728293031323334353637383940$ kubectl create -f myapp.yamlpod/myapp-pod created$ kubectl get -f myapp.yamlNAME READY STATUS RESTARTS AGEmyapp-pod 0/1 Init:0/2 0 6m$ kubectl describe -f myapp.yamlName: myapp-podNamespace: default[...]Labels: app=myappStatus: Pending[...]Init Containers: init-myservice:[...] State: Running[...] init-mydb:[...] State: Waiting Reason: PodInitializing Ready: False[...]Containers: myapp-container:[...] State: Waiting Reason: PodInitializing Ready: False[...]Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 16s 16s 1 &#123;default-scheduler &#125; Normal Scheduled Successfully assigned myapp-pod to 172.17.4.201 16s 16s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Pulling pulling image "busybox" 13s 13s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Pulled Successfully pulled image "busybox" 13s 13s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Created Created container with docker id 5ced34a04634; Security:[seccomp=unconfined] 13s 13s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Started Started container with docker id 5ced34a04634$ kubectl logs myapp-pod -c init-myservice # Inspect the first init container$ kubectl logs myapp-pod -c init-mydb # Inspect the second init container 一旦我们启动mydb和myservice服务，我们就可以看到Init Containers完成并myapp-pod创建了：123456$ kubectl create -f services.yamlservice/myservice createdservice/mydb created$ kubectl get -f myapp.yamlNAME READY STATUS RESTARTS AGEmyapp-pod 1/1 Running 0 9m 这个例子非常简单，但应该为您创建自己的Init容器提供一些灵感。 详细的行为在Pod启动期间，初始化网络和卷后，初始容器将按顺序启动。每个Container必须在下一个Container启动之前成功退出。如果Container由于运行时未能启动或因故障退出，则根据Pod重试restartPolicy。但是，如果将Pod restartPolicy设置为Always，则Init Containers将使用 RestartPolicyOnFailure。 在Ready所有Init容器都成功之前，Pod不能。Init容器上的端口不在服务下聚合。正在初始化的Pod处于Pending状态，但应将条件Initializing设置为true。 如果重新启动 Pod，则必须再次执行所有Init Containers。 Init容器规范的更改仅限于容器镜像字段。更改Init Container镜像字段相当于重新启动Pod。 由于Init Containers可以重新启动，重试或重新执行，因此Init Container代码应该是幂等的。特别是，EmptyDirs 应该为输出文件已经存在的可能性准备写入文件的代码。 Init Containers具有应用Container的所有字段。但是，Kubernetes禁止readinessProbe使用，因为Init Containers无法定义与完成不同的准备情况。这在验证期间强制执行。 使用activeDeadlineSeconds上podlivenessProbe的容器，以防止初始化容器从永远失败。活动截止日期包括Init Containers。 Pod中每个应用程序和Init容器的名称必须是唯一的; 任何与另一个名称共享名称的Container都会引发验证错误。 资源给定Init Containers的排序和执行，适用以下资源使用规则： 在所有Init Containers上定义的任何特定资源请求或限制的最高值是有效的init请求/限制 Pod 对资源的有效请求/限制是以下值中的较高者： 资源的所有应用容器请求/限制的总和 资源的有效init请求/限制 调度是基于有效的请求/限制完成的，这意味着Init Containers可以预留在Pod生命周期内未使用的初始化资源。 Pod的有效QoS层的QoS层是Init Containers和app容器的QoS层。 根据有效的Pod请求和限制应用配额和限制。 Pod级别cgroup基于有效的Pod请求和限制，与调度程序相同。 Pod重启原因Pod可以重新启动，导致重新执行Init Containers，原因如下： 用户更新PodSpec，导致Init容器映像发生更改。App Container图像更改仅重新启动应用程序Container。 Pod基础架构容器重新启动。这种情况并不常见，必须由对节点具有root访问权限的人员来完成。 Pod中的所有容器都被终止，同时restartPolicy设置为Always，强制重新启动，并且Init Container完成记录由于垃圾回收而丢失。 支持和兼容性具有Apiserver 1.6.0或更高版本的群集支持使用该.spec.initContainers字段的Init Containers 。以前的版本使用alpha或beta注释支持Init Containers。该.spec.initContainers字段还镜像为alpha和beta注释，以便Kubelet 1.3.0或更高版本可以执行Init Containers，因此版本1.6 apiserver可以安全地回滚到1.5.x版，而不会丢失现有创建的pod的Init Container功能。 在Apiserver和Kubelet 1.8.0或更高版本中，删除了对alpha和beta注释的支持，需要从不推荐的注释转换到 .spec.initContainers字段。 此功能已在1.6中退出测试版。可以在应用程序containers阵列旁边的PodSpec中指定Init容器。beta注释值仍将受到尊重并覆盖PodSpec字段值，但是，它们在1.6和1.7中已弃用。在1.8中，不再支持注释，必须将其转换为PodSpec字段。 Pod Preset此页面提供PodPresets的概述，PodPresets是在创建时将特定信息注入pod的对象。信息可以包括秘密，卷，卷安装和环境变量。 了解Pod预设 这个怎么运作 启用Pod预设 了解Pod预设Pod Preset是一种API资源，用于在创建时将其他运行时需求注入Pod。您可以使用标签选择器 指定应用给定Pod预设的Pod。 使用Pod预设允许pod模板作者不必显式提供每个pod的所有信息。这样，使用特定服务的pod模板的作者不需要知道有关该服务的所有详细信息。 有关背景的更多信息，请参阅PodPreset的设计方案。 这个怎么运作Kubernetes提供了一个准入控制器（PodPreset），当启用时，它将Pod Presets应用于传入的pod创建请求。发生pod创建请求时，系统会执行以下操作： 检索所有PodPresets可用的。 检查任何标签选择器是否PodPreset与正在创建的pod上的标签匹配。 尝试将所定义的各种资源合并PodPreset到正在创建的Pod中。 出错时，抛出一个记录pod上合并错误的事件，并创建pod 而不从中注入任何资源PodPreset。 注释生成的修改后的Pod规范，以指示它已被修改PodPreset。注释是形式的 podpreset.admission.kubernetes.io/podpreset-&lt;pod-preset name&gt;: &quot;&lt;resource version&gt;&quot;。 每个Pod可以匹配零个或多个Pod Presets; 并且每个PodPreset都可以应用于零个或多个pod。当 PodPreset应用于一个或多个Pod时，Kubernetes会修改Pod规范。对于更改Env，EnvFrom和 VolumeMounts，Kubernetes修改在波德所有容器容器规范; 对于更改Volume，Kubernetes修改Pod规范。 注意： Pod Preset能够.spec.containers在适当的时候修改Pod规范中的字段。没有从POD预置资源定义将被应用到initContainers外地。 禁用特定Pod的Pod预设在某些情况下，您希望Pod不会被任何Pod Preset突变改变。在这些情况下，您可以在表单的Pod Spec中添加注释：podpreset.admission.kubernetes.io/exclude: &quot;true&quot;。 启用Pod预设要在群集中使用Pod Presets，您必须确保以下内容： 您已启用API类型settings.k8s.io/v1alpha1/podpreset。例如，这可以通过包含settings.k8s.io/v1alpha1=true在--runtime-configAPI服务器的选项中来完成。在minikube中，--extra-config=apiserver.runtime-config=settings.k8s.io/v1alpha1=true在启动集群时添加此标志 。 您已启用准入控制器PodPreset。执行此操作的一种方法是包含PodPreset在--enable-admission-plugins为API服务器指定的选项值中。在minikube中，--extra-config=apiserver.enable-admission-plugins=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PodPreset 在启动集群时添加此标志 。 您已通过PodPreset在将使用的命名空间中创建对象来定义Pod预设。 中断本指南适用于想要构建高可用性应用程序的应用程序所有者，因此需要了解Pod可能发生的中断类型。 它也适用于希望执行自动群集操作的群集管理员，例如升级和自动缩放群集。 自愿和非自愿中断 处理中断 中断预算如何运作 PDB示例 分离群集所有者和应用程序所有者角色 如何在群集上执行破坏性操作 自愿和非自愿中断在有人（一个人或一个控制器）摧毁它们，或者存在不可避免的硬件或系统软件错误之前，Pod不会消失。 我们将这些不可避免的案例称为对应用程序的非自愿中断。例如： 支持节点的物理机的硬件故障 集群管理员错误地删除了VM（实例） 云提供商或虚拟机管理程序故障使虚拟机消失 内核恐慌 由于群集网络分区，节点从群集中消失 由于节点资源不足而导致pod被驱逐。 除资源不足外，大多数用户都应熟悉所有这些条件; 它们不是Kubernetes特有的。 我们将其他案件称为自愿中断。其中包括应用程序所有者启动的操作和群集管理员启动的操作。典型应用程序所有者操作包 删除管理pod的部署或其他控制器 更新部署的pod模板导致重新启动 直接删除pod（例如意外） 群集管理员操作包括：- 耗尽节点进行修复或升级。 从群集中排出节点以缩小群集（了解群集自动缩放 ）。 从节点中删除pod以允许其他内容适合该节点。 这些操作可以由集群管理员直接执行，也可以由集群管理员或集群主机提供商自动运行。 请咨询您的集群管理员或咨询您的云提供商或分发文档，以确定是否为您的集群启用了任何自愿中断源。如果未启用，则可以跳过创建Pod中断预算。 处理中断以下是一些缓解非自愿中断的方法： 确保您的pod 请求所需的资源。 如果需要更高的可用性，请复制应用程序。（了解运行复制的 无状态 和有状态应用程序。） 为了在运行复制的应用程序时获得更高的可用性，可以跨机架（使用反关联）或跨区域（如果使用 多区域群集）分布应用程序 。 自愿中断的频率各不相同。在基本的Kubernetes集群上，根本没有自愿中断。但是，您的群集管理员或托管服务提供商可能会运行一些导致自愿中断的其他服务。例如，推出节点软件更新可能会导致自愿中断。此外，群集（节点）自动缩放的某些实现可能会导致自动中断以进行碎片整理和压缩节点。您的集群管理员或托管服务提供商应记录预期的自愿中断级别（如果有）。 Kubernetes提供的功能可以帮助您在频繁的自愿中断的同时运行高可用性应用程序。我们将这组功能称为 中断预算。 中断预算如何运作应用程序所有者可以PodDisruptionBudget为每个应用程序创建一个对象（PDB）。PDB限制复制应用程序的pod的数量，这些pod与自愿中断同时发生故障。例如，基于仲裁的应用程序希望确保运行的副本数量永远不会低于仲裁所需的数量。Web前端可能希望确保服务负载的副本数量永远不会低于总数的某个百分比。 集群管理器和托管提供商应使用通过调用Eviction API 而不是直接删除pod来遵守Pod Disruption Budgets的工具。示例是kubectl drain命令和Kubernetes-on-GCE集群升级脚本（cluster/gce/upgrade.sh）。 当集群管理员想要耗尽节点时，他们使用该kubectl drain命令。该工具试图驱逐机器上的所有pod。可以暂时拒绝逐出请求，并且该工具定期重试所有失败的请求，直到所有pod终止，或者直到达到可配置的超时。 PDB指定应用程序可以容忍的副本数量，相对于预期的副本数量。例如，具有部署.spec.replicas: 5应该在任何给定时间具有5个pod。如果其PDB允许一次有4个，则Eviction API将允许一次自动中断一个而不是两个pod。 组成应用程序的pod组使用标签选择器指定，与应用程序控制器使用的标签选择器相同（部署，有状态集等）。 “预期”数量的pod是根据.spec.replicaspods控制器计算出来的。使用.metadata.ownerReferences对象的pod从pod中发现控制器。 PDB不能防止非自愿中断发生，但它们确实违背了预算。 由于滚动升级到应用程序而被删除或不可用的Pod确实会计入中断预算，但是在执行滚动升级时，控制器（如部署和有状态集）不受PDB限制 - 在应用程序更新期间处理故障在控制器规范中。（了解有关更新部署的信息。） 当吊舱使用驱逐API逐出，它是正常终止（见 terminationGracePeriodSeconds在PodSpec。） PDB示例考虑具有3个节点的群集中，node-1通过node-3。群集正在运行多个应用程序。其中一人有3个副本最初称 pod-a，pod-b和pod-c。pod-x还示出了另一个没有PDB的不相关的pod。最初，pod的布局如下： 节点-1 节点-2- 节点-3- pod-a 可用 pod-b 可用 pod-c 可用 pod-x 可用 所有3个pod都是部署的一部分，它们共同拥有一个PDB，要求所有3个pod中至少有2个可用。 例如，假设集群管理员想要重新启动到新的内核版本来修复内核中的错误。群集管理员首先尝试node-1使用该kubectl drain命令消耗。该工具试图驱逐pod-a和pod-x。这立即成功。两个pod同时进入该terminating。这使集群处于以下状态 节点-1 耗尽 节点-2- 节点-3- pod-a 终止 pod-b 可用 pod-c 可用 pod-x 终止 部署注意到其中一个pod正在终止，因此它会创建一个名为的替换pod-d。由于node-1是封锁的，它落在另一个节点上。还创造pod-y了一些替代品pod-x。 （注意：对于一个StatefulSet，pod-a它将被称为类似的东西pod-1，需要在它被替换之前完全终止，也可以被调用，pod-1但是可以创建不同的UID。否则，该示例也适用于StatefulSet。） 现在集群处于以下状态： 节点-1 耗尽 节点-2- 节点-3- pod-a 终止 pod-b 可用 pod-c 可用 pod-x 终止 pod-b 开始 POD-Y 在某些时候，pod终止，集群看起来像这样： 节点-1 耗尽 节点-2- 节点-3- pod-b 可用 pod-c 可用 pod-b 开始 POD-Y 此时，如果一个不耐烦的集群管理员试图耗尽，node-2或者 node-3排除命令将阻塞，因为部署只有2个可用的pod，并且其PDB至少需要2.经过一段时间后，pod-d变为可用。 群集状态现在看起来像这样： 节点-1 耗尽 节点-2- 节点-3- pod-b 可用 pod-c 可用 pod-b 可用 POD-Y 现在，集群管理员试图耗尽node-2。drain命令将尝试以某种顺序驱逐两个pod，pod-b先说然后再说 pod-d。它将成功驱逐pod-b。但是，当它试图逐出时pod-d，它将被拒绝，因为这将只留下一个可用于部署的pod。 部署创建了pod-b被叫的替代品pod-e。因为集群中没有足够的资源来安排 pod-e排水将再次阻塞。群集可能最终处于此状态： 节点-1 耗尽 节点-2- 节点-3- 没有节点 pod-b 可用 pod-c 可用 pod-e 待定 pod-b 可用 POD-Y 此时，集群管理员需要将节点添加回集群以继续升级。 你可以看到Kubernetes如何改变发生中断的速度，根据： 应用程序需要多少个副本 优雅地关闭实例需要多长时间 启动新实例需要多长时间 控制器的类型 集群的资源容量 分离群集所有者和应用程序所有者角色通常，将群集管理器和应用程序所有者视为彼此知之甚少的单独角色很有用。在这些情况下，这种职责分离可能有意义： 当有许多应用程序团队共享Kubernetes集群时，角色有自然的专业化 当第三方工具或服务用于自动化集群管理时 Pod Disruption Budgets通过在角色之间提供接口来支持这种角色分离。 如果您的组织中没有这样的责任分离，则可能不需要使用Pod Disruption Budgets。 如何在群集上执行破坏性操作如果您是群集管理员，并且需要对群集中的所有节点执行中断操作，例如节点或系统软件升级，则可以使用以下选项： 在升级期间接受停机时间。 故障转移到另一个完整的副本群集。 没有停机时间，但对于重复的节点以及人类协调切换的努力可能都是昂贵的。 编写容错中断应用程序并使用PDB。 没有停机时间。 最小的资源重复。 允许更多自动化群集管理。 编写容忍破坏性的应用程序很棘手，但容忍自愿中断的工作很大程度上与支持自动缩放和容忍非自愿中断的工作重叠。 控制器ReplicaSetReplicaSet是下一代复制控制器。现在ReplicaSet和 Replication Controller之间的唯一区别是选择器支持。ReplicaSet支持新的基于集合的选择器要求，如标签用户指南中所述， 而Replication Controller仅支持基于等同的选择器要求。 如何使用ReplicaSet 何时使用ReplicaSet 例 编写副本集规范 使用ReplicaSet ReplicaSet的替代品 如何使用ReplicaSet大多数kubectl支持复制控制器的命令也支持ReplicaSet。rolling-update命令是一个例外 。如果您想要滚动更新功能，请考虑使用部署。此外， rolling-update命令是必需的，而Deployments是声明性的，因此我们建议通过rollout命令使用Deployments 。 虽然ReplicaSet可以独立使用，但今天它主要被 Deployments用作协调pod创建，删除和更新的机制。使用“部署”时，您不必担心管理它们创建的副本集。部署拥有并管理其ReplicaSet。 何时使用ReplicaSetReplicaSet确保在任何给定时间运行指定数量的pod副本。但是，Deployment是一个更高级别的概念，它管理ReplicaSet并为pod提供声明性更新以及许多其他有用的功能。因此，除非您需要自定义更新编排或根本不需要更新，否则我们建议使用部署而不是直接使用ReplicaSet。 这实际上意味着您可能永远不需要操作ReplicaSet对象：改为使用Deployment，并在spec部分中定义您的应用程序。 例123456789101112131415161718192021222324252627282930313233343536373839#controllers/frontend.yamlapiVersion: apps/v1kind: ReplicaSetmetadata: name: frontend labels: app: guestbook tier: frontendspec: # modify replicas according to your case replicas: 3 selector: matchLabels: tier: frontend matchExpressions: - &#123;key: tier, operator: In, values: [frontend]&#125; template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the 'value: dns' line above, and uncomment the # line below. # value: env ports: - containerPort: 80 将此清单保存frontend.yaml到Kubernetes集群并将其提交到Kubernetes集群应该创建已定义的ReplicaSet及其管理的pod。123456789101112131415161718192021222324252627282930313233343536$ kubectl create -f http://k8s.io/examples/controllers/frontend.yamlreplicaset.apps/frontend created$ kubectl describe rs/frontendName: frontendNamespace: defaultSelector: tier=frontend,tier in (frontend)Labels: app=guestbook tier=frontendAnnotations: &lt;none&gt;Replicas: 3 current / 3 desiredPods Status: 3 Running / 0 Waiting / 0 Succeeded / 0 FailedPod Template: Labels: app=guestbook tier=frontend Containers: php-redis: Image: gcr.io/google_samples/gb-frontend:v3 Port: 80/TCP Requests: cpu: 100m memory: 100Mi Environment: GET_HOSTS_FROM: dns Mounts: &lt;none&gt; Volumes: &lt;none&gt;Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 &#123;replicaset-controller &#125; Normal SuccessfulCreate Created pod: frontend-qhloh 1m 1m 1 &#123;replicaset-controller &#125; Normal SuccessfulCreate Created pod: frontend-dnjpy 1m 1m 1 &#123;replicaset-controller &#125; Normal SuccessfulCreate Created pod: frontend-9si5l$ kubectl get podsNAME READY STATUS RESTARTS AGEfrontend-9si5l 1/1 Running 0 1mfrontend-dnjpy 1/1 Running 0 1mfrontend-qhloh 1/1 Running 0 1m 编写副本集规范与所有其他Kubernetes API对象，一个ReplicaSet需要apiVersion，kind和metadata领域。有关使用清单的一般信息，请参阅使用kubectl进行对象管理。 ReplicaSet还需要一个.spec部分。 Pod模板这.spec.template是唯一必需的领域.spec。这.spec.template是一个 pod模板。它与pod具有完全相同的架构 ，除了它是嵌套的并且没有apiVersion或kind。 除了pod的必填字段外，ReplicaSet中的pod模板还必须指定适当的标签和适当的重新启动策略。 对于标签，请确保不与其他控制器重叠。有关更多信息，请参阅pod选择器。 对于重新启动策略，唯一允许的值.spec.template.spec.restartPolicy是Always，这是默认值。 对于本地容器重新启动，ReplicaSet委托给节点上的代理程序，例如Kubelet或Docker。 Pod选择器该.spec.selector字段是标签选择器。ReplicaSet使用与选择器匹配的标签管理所有pod。它不区分它创建或删除的pod以及另一个人或进程创建或删除的pod。这允许替换ReplicaSet而不影响正在运行的pod。 在.spec.template.metadata.labels必须匹配.spec.selector，否则会被API被拒绝。 在Kubernetes 1.9中，apps/v1ReplicaSet类型的API版本是当前版本，默认情况下已启用。apps/v1beta2不推荐使用API版本。 此外，您通常不应创建任何标签与此选择器匹配的pod，可以直接与另一个ReplicaSet一起创建，也可以与其他控制器（如Deployment）一起创建。如果这样做，ReplicaSet会认为它创建了其他pod。Kubernetes并没有阻止你这样做。 如果最终有多个具有重叠选择器的控制器，则必须自己管理删除。 副本集上的标签ReplicaSet本身可以有标签（.metadata.labels）。通常，您可以将它们设置为相同.spec.template.metadata.labels。但是，允许它们不同，并且.metadata.labels不会影响ReplicaSet的行为。 副本您可以通过设置指定应同时运行的pod数量.spec.replicas。在任何时间运行的数字可能更高或更低，例如，如果副本只是增加或减少，或者如果正常关闭吊舱，并且提前开始更换。 如果未指定.spec.replicas，则默认为1。 使用ReplicaSet删除ReplicaSet及其Pod要删除ReplicaSet及其所有Pod，请使用kubectl delete。该垃圾收集器在默认情况下会自动删除所有相关的荚。 使用REST API或client-go库时，必须设置propagationPolicy为Background或Foreground删除选项。例如：1234kubectl proxy --port=8080curl -X DELETE 'localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend' \&gt; -d '&#123;"kind":"DeleteOptions","apiVersion":"v1","propagationPolicy":"Foreground"&#125;' \&gt; -H "Content-Type: application/json" 仅删除副本集您可以删除副本集，而不会影响使用kubectl delete该--cascade=false选项的任何pod 。使用REST API或client-go库时，必须设置propagationPolicy为Orphan，例如：1234kubectl proxy --port=8080curl -X DELETE 'localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend' \&gt; -d '&#123;"kind":"DeleteOptions","apiVersion":"v1","propagationPolicy":"Orphan"&#125;' \&gt; -H "Content-Type: application/json" 删除原始文件后，您可以创建一个新的ReplicaSet来替换它。只要旧的和新.spec.selector的相同，那么新的将采用旧的豆荚。但是，它不会做任何努力使现有的pod匹配一个新的，不同的pod模板。要以受控方式将pod更新为新规范，请使用滚动更新。 从副本集隔离pod可以通过更改标签来从ReplicaSet的目标集中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的Pod将自动替换（假设副本的数量也未更改）。 缩放副本集只需更新.spec.replicas字段即可轻松扩展或缩小ReplicaSet 。ReplicaSet控制器确保具有匹配标签选择器的所需数量的pod可用且可操作。 ReplicaSet作为水平Pod自动缩放器目标ReplicaSet也可以是 Horizontal Pod Autoscalers (HPA)的目标 。也就是说，HPA可以自动缩放ReplicaSet。以下是针对我们在上一个示例中创建的ReplicaSet的示例HPA。123456789101112#controllers/hpa-rs.yaml apiVersion: autoscaling/v1kind: HorizontalPodAutoscalermetadata: name: frontend-scalerspec: scaleTargetRef: kind: ReplicaSet name: frontend minReplicas: 3 maxReplicas: 10 targetCPUUtilizationPercentage: 50 将此清单保存hpa-rs.yaml到Kubernetes集群并将其提交到Kubernetes集群应该创建定义的HPA，该HPA根据复制的pod的CPU使用情况自动调整目标ReplicaSet。1kubectl create -f https://k8s.io/examples/controllers/hpa-rs.yaml 或者，您可以使用该kubectl autoscale命令来完成相同的操作（并且它更容易！）1kubectl autoscale rs frontend --max=10 ReplicaSet的替代品部署（推荐）Deployment是一个更高级别的API对象，它以类似的方式更新其底层ReplicaSet及其Pod kubectl rolling-update。如果您需要此滚动更新功能，则建议进行部署，因为kubectl rolling-update它们不同于声明式，服务器端，并具有其他功能。有关使用部署运行无状态应用程序的更多信息，请阅读使用部署运行无状态应用程序。 Bare Pods与用户直接创建pod的情况不同，ReplicaSet会替换因任何原因而被删除或终止的pod，例如在节点故障或破坏性节点维护（例如内核升级）的情况下。因此，即使您的应用程序只需要一个pod，我们也建议您使用ReplicaSet。可以想象它与流程主管类似，只是它监控多个节点上的多个pod而不是单个节点上的单个进程。ReplicaSet将本地容器重新启动委派给节点上的某个代理程序（例如，Kubelet或Docker）。 Job对于预期会自行终止的pod（即批处理作业），请使用Job而不是ReplicaSet。 DaemonSetDaemonSet对于提供机器级功能的pod，例如机器监视或机器日志记录，请使用ReplicaSet而不是ReplicaSet。这些pod的生命周期与机器生命周期相关：pod需要在其他pod启动之前在机器上运行，并且当机器准备好重新启动/关闭时可以安全终止。 ReplicationController 注意：现在建议使用配置ReplicaSet的Deployment来设置复制。 ReplicationController确保pod副本的指定数量的在任何一个时间运行。换句话说，ReplicationController确保一个pod或一组同类pod总是可用。 ReplicationController的工作原理 运行示例ReplicationController 编写ReplicationController规范 使用ReplicationControllers 常见的使用模式 编写复制程序 ReplicationController的职责 API对象 ReplicationController的替代品 欲获得更多信息 ReplicationController的工作原理如果存在太多pod，则ReplicationController将终止额外的pod。如果太少，ReplicationController将启动更多pod。与手动创建的pod不同，ReplicationController维护的pod在失败，删除或终止时会自动替换。例如，在内核升级等破坏性维护之后，会在节点上重新创建pod。因此，即使应用程序只需要一个pod，也应该使用ReplicationController。ReplicationController类似于进程管理程序，但是ReplicationController不是监视单个节点上的各个进程，而是监视多个节点上的多个pod。 在讨论中，ReplicationController通常缩写为“rc”或“rcs”，并且作为kubectl命令中的快捷方式。 一个简单的例子是创建一个ReplicationController对象，以无限期地可靠地运行Pod的一个实例。更复杂的用例是运行复制服务的几个相同副本，例如Web服务器。 运行示例ReplicationController此示例ReplicationController配置运行nginx Web服务器的三个副本。1234567891011121314151617181920#controllers/replication.yaml apiVersion: v1kind: ReplicationControllermetadata: name: nginxspec: replicas: 3 selector: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 通过下载示例文件然后运行此命令来运行示例作业：12$ kubectl create -f https://k8s.io/examples/controllers/replication.yamlreplicationcontroller/nginx created 使用以下命令检查ReplicationController的状态：1234567891011121314151617181920212223$ kubectl describe replicationcontrollers/nginxName: nginxNamespace: defaultSelector: app=nginxLabels: app=nginxAnnotations: &lt;none&gt;Replicas: 3 current / 3 desiredPods Status: 0 Running / 3 Waiting / 0 Succeeded / 0 FailedPod Template: Labels: app=nginx Containers: nginx: Image: nginx Port: 80/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- ---- ------ ------- 20s 20s 1 &#123;replication-controller &#125; Normal SuccessfulCreate Created pod: nginx-qrm3m 20s 20s 1 &#123;replication-controller &#125; Normal SuccessfulCreate Created pod: nginx-3ntk0 20s 20s 1 &#123;replication-controller &#125; Normal SuccessfulCreate Created pod: nginx-4ok8v 这里创建了三个pod，但没有一个正在运行，可能是因为正在拉动图像。稍后，相同的命令可能会显示： 1Pods Status: 3 Running / 0 Waiting / 0 Succeeded / 0 Failed 要以机器可读的形式列出属于ReplicationController的所有pod，可以使用如下命令：123 $ pods=$(kubectl get pods --selector=app=nginx --output=jsonpath=&#123;.items..metadata.name&#125;)echo $podsnginx-3ntk0 nginx-4ok8v nginx-qrm3m 这里，选择器与ReplicationController的选择器相同（在kubectl describe输出中看到 ，并以不同的形式显示replication.yaml。该--output=jsonpath选项指定一个表达式，它只从返回列表中的每个pod获取名称。 编写ReplicationController规范与所有其他Kubernetes配置，一个ReplicationController需要apiVersion，kind和metadata领域。有关使用配置文件的一般信息，请参阅对象管理。 ReplicationController还需要一个.spec部分。 Pod模板这.spec.template是唯一必需的领域.spec。 这.spec.template是一个pod模板。它与pod具有完全相同的架构，除了它是嵌套的并且没有apiVersion或kind。 除了Pod的必需字段之外，ReplicationController中的pod模板还必须指定适当的标签和适当的重新启动策略。对于标签，请确保不要与其他控制器重叠。请参阅pod选择器。 只允许.spec.template.spec.restartPolicy等于Always，如果未指定，则为默认值。 对于本地容器重新启动，ReplicationControllers委托给节点上的代理程序，例如Kubelet或Docker。 ReplicationController上的标签ReplicationController本身可以有labels（.metadata.labels）。通常，您可以将它们设置为相同.spec.template.metadata.labels; 如果.metadata.labels未指定，则默认为.spec.template.metadata.labels。但是，允许它们不同，并且.metadata.labels不会影响ReplicationController的行为。 Pod选择器该.spec.selector字段是标签选择器。ReplicationController管理具有与选择器匹配的标签的所有pod。它不区分它创建或删除的pod以及另一个人或进程创建或删除的pod。这允许在不影响正在运行的pod的情况下替换ReplicationController。 如果指定，则.spec.template.metadata.labels必须等于.spec.selector，否则将被API拒绝。如果.spec.selector未指定，则默认为.spec.template.metadata.labels。 此外，您通常不应创建任何标签与此选择器匹配的pod，可以直接创建，与另一个ReplicationController或其他控制器（如Job）匹配。如果这样做，ReplicationController会认为它创建了其他pod。Kubernetes并没有阻止你这样做。 如果最终有多个具有重叠选择器的控制器，则必须自己管理删除（见下文）。 多个副本您可以通过设置.spec.replicas要同时运行的窗格数来指定应同时运行的窗格数。在任何时间运行的数字可能更高或更低，例如，如果副本只是增加或减少，或者如果正常关闭吊舱，并且提前开始更换。 如果未指定.spec.replicas，则默认为1。 使用ReplicationControllers删除ReplicationController及其Pod要删除ReplicationController及其所有pod，请使用kubectl delete。在删除ReplicationController本身之前，Kubectl会将ReplicationController缩放为零并等待它删除每个pod。如果此kubectl命令被中断，则可以重新启动它。 使用REST API或转到客户端库时，需要显式执行这些步骤（将副本扩展为0，等待窗格删除，然后删除ReplicationController）。 仅删除ReplicationController您可以删除ReplicationController而不影响其任何pod。 使用kubectl，指定--cascade=false选项kubectl delete。 使用REST API或转到客户端库时，只需删除ReplicationController对象即可。 删除原始文件后，您可以创建一个新的ReplicationController来替换它。只要旧的和新.spec.selector的相同，那么新的将采用旧的pod。但是，它不会做任何努力使现有的pod匹配一个新的，不同的pod模板。要以受控方式将pod更新为新规范，请使用滚动更新。 从ReplicationController中隔离pod可以通过更改标签来从ReplicationController的目标集中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的Pod将自动替换（假设副本的数量也未更改）。 常见的使用模式重新安排如上所述，无论您是要保持运行1个pod还是1000个，ReplicationController都将确保存在指定数量的pod，即使在节点发生故障或pod终止时（例如，由于另一个控制剂）。 缩放通过简单地更新replicas字段，ReplicationController可以手动或通过自动缩放控制代理轻松扩展或缩小副本数量。 滚动更新ReplicationController旨在通过逐个替换pod来促进对服务的滚动更新。 如＃1353中所述，建议的方法是创建一个具有1个副本的新ReplicationController，逐个扩展新的（+1）和旧（-1）控制器，然后在它达到0个副本后删除旧控制器。无论意外故障如何，这都可以预测更新pod的集合。 理想情况下，滚动更新控制器会考虑应用程序准备情况，并确保在任何给定时间内有足够数量的pod可以高效地运行。 这两个ReplicationControllers需要创建具有至少一个区分标签的pod，例如pod的主容器的image标签，因为它通常是图像更新，可以激发滚动更新。 滚动更新在客户端工具中实现 kubectl rolling-update。访问kubectl rolling-update任务以获得更具体的示例。 多个发行tracks除了在滚动更新正在进行时运行多个版本的应用程序之外，通常使用多个版本跟踪长时间运行多个版本，甚至连续运行多个版本。轨道将按标签区分。 例如，服务可能会定位所有pod tier in (frontend), environment in (prod)。现在说你有10个复制的pod组成这个层。但是你希望能够’canary’这个组件的新版本。您可以replicas为大部分副本设置一个设置为9 的ReplicationController ，带有标签tier=frontend, environment=prod, track=stable，另一个replicas设置为1的带有标签的ReplicationController 用于canarytier=frontend, environment=prod, track=canary。现在该服务涵盖了canary和non-canary pods。但是你可以分别搞乱ReplicationControllers来测试，监视结果等。 将ReplicationControllers与Services一起使用多个ReplicationControllers可以位于单个服务之后，例如，某些流量转到旧版本，有些流量转到新版本。 ReplicationController永远不会自行终止，但预计它不会像服务一样长寿。服务可以由多个ReplicationControllers控制的pod组成，并且预计可以在服务的生命周期内创建和销毁许多ReplicationController（例如，执行运行服务的pod的更新）。服务本身及其客户端都应该忽略维护服务pod的ReplicationControllers。 编写复制程序由ReplicationController创建的Pod旨在是可互换的和语义相同的，尽管它们的配置可能随着时间的推移变得异构。这显然适用于复制的无状态服务器，但ReplicationControllers也可用于维护主选，分片和工作池应用程序的可用性。此类应用程序应使用动态工作分配机制，例如RabbitMQ工作队列，而不是静态/一次性定制每个pod的配置，这被视为反模式。执行的任何pod自定义，例如资源的垂直自动调整（例如，cpu或内存），应由另一个在线控制器进程执行，与ReplicationController本身不同。 ReplicationController的职责ReplicationController只是确保所需数量的pod与其标签选择器匹配并且可以运行。目前，只有已终止的广告连播从其计数中排除。将来，可以考虑系统提供的准备情况和其他信息，我们可以对替换策略添加更多控制，并且我们计划发出可以由外部客户使用的事件，以实现任意复杂的替换和/或扩展下行政策。 ReplicationController永远受限于这种狭隘的责任。它本身不会执行准备就绪或活力探测。它不是执行自动缩放，而是由外部自动缩放器控制（如＃492中所述），这将改变其replicas字段。我们不会将调度策略（例如，传播）添加到ReplicationController。它也不应该验证控制的pod与当前指定的模板匹配，因为这会妨碍自动调整大小和其他自动化过程。同样，完成期限，排序依赖性，配置扩展和其他功能属于其他地方。我们甚至计划分析批量pod创建的机制（＃170）。 ReplicationController旨在成为可组合的构建块原语。我们希望在它和其他补充原语之上构建更高级别的API和/或工具，以便将来用户使用。kubectl目前支持的“宏”操作（运行，缩放，滚动更新）是概念验证的例子。例如，我们可以想象像Asgard管理ReplicationControllers，自动缩放器，服务，调度策略，canary等。 API对象复制控制器是Kubernetes REST API中的顶级资源。有关API对象的更多详细信息，请访问： ReplicationController API对象。 ReplicationController的替代品ReplicaSetReplicaSet是支持新的基于集合的标签选择器的下一代ReplicationController 。它主要用作Deployment协调pod创建，删除和更新的机制。请注意，除非您需要自定义更新编排或根本不需要更新，否则我们建议您使用“部署”而不是直接使用“副本集”。 部署（推荐）Deployment是一个更高级别的API对象，它以类似的方式更新其基础副本集及其Pod kubectl rolling-update。如果您需要此滚动更新功能，则建议进行部署，因为kubectl rolling-update它们不同于声明式，服务器端，并具有其他功能。 pod与用户直接创建pod的情况不同，ReplicationController替换因任何原因而被删除或终止的pod，例如在节点故障或破坏性节点维护（例如内核升级）的情况下。因此，即使您的应用程序只需要一个pod，我们也建议您使用ReplicationController。可以想象它与流程主管类似，只是它监控多个节点上的多个pod而不是单个节点上的单个进程。ReplicationController将本地容器重新启动委派给节点上的某个代理（例如，Kubelet或Docker）。 jobJob对于预期会自行终止的pod（即批处理作业），请使用而不是ReplicationController。 DaemonSetDaemonSet对于提供机器级功能的pod，例如机器监视或机器日志记录，请使用而不是ReplicationController。这些pod的生命周期与机器生命周期相关：pod需要在其他pod启动之前在机器上运行，并且当机器准备好重新启动/关闭时可以安全终止。 欲获得更多信息读取运行无状态AP复制控制器。 部署一个部署控制器提供声明更新pod和 ReplicaSets。 您在Deployment对象中描述了所需的状态，Deployment控制器以受控速率将实际状态更改为所需状态。您可以定义部署以创建新的ReplicaSet，或者删除现有的部署并使用新的部署采用所有资源。 注意：您不应管理部署所拥有的ReplicaSet。应通过操作Deployment对象来涵盖所有用例。如果您的用例未在下面介绍，请考虑在主Kubernetes存储库中打开一个问题。 用例 创建部署 更新部署 回滚部署 扩展部署 暂停和恢复部署 部署状态 清理政策 用例 编写部署规范 部署的替代方案 用例以下是部署的典型用例： 创建部署以部署副本集。ReplicaSet在后台创建Pod。检查卷展栏的状态以查看它是否成功。 通过更新Deployment的PodTemplateSpec来声明 Pod 的新状态。创建一个新的ReplicaSet，Deployment部署管理以受控速率将Pod从旧ReplicaSet移动到新ReplicaSet。每个新的ReplicaSet都会更新Deployment的修订版。 如果部署的当前状态不稳定，则回滚到早期的部署修订版。每次回滚都会更新Deployment的修订版。 扩展部署以促进更多负载。 暂停部署以将多个修复程序应用于其PodTemplateSpec，然后恢复它以启动新的部署。 使用部署的状态作为卷展栏卡住的指示符。 清理不再需要的旧ReplicaSet。 创建部署以下是部署的示例。它创建一个ReplicaSet来调出三个Pod nginx：12345678910111213141516171819202122#controllers/nginx-deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 在这个例子中： nginx-deployment创建名为的部署，由.metadata.name字段指示。 部署创建三个复制的Pod，由replicas字段指示。 该selector字段定义了Deployment如何找到要管理的Pod。在这种情况下，您只需选择Pod模板（app: nginx）中定义的标签。但是，只要Pod模板本身满足规则，就可以使用更复杂的选择规则。 注意： matchLabels是{key，value}对的映射。matchLabels映射中的单个{key，value} 等效matchExpressions于其元素，其键字段为“key”，运算符为“In”，值数组仅包含“value”。要求是AND。 该template字段包含以下子字段： app: nginx使用该labels字段标记Pod 。 Pod模板的规范或.template.spec字段表示Pod 运行一个容器nginx，该容器在版本1.7.9下运行nginx Docker Hub映像。 创建一个容器并nginx使用该name字段命名。 nginx在版本运行图像1.7.9。 打开端口，80以便容器可以发送和接受流量。 要创建此部署，请运行以下命令：1kubectl create -f https://k8s.io/examples/controllers/nginx-deployment.yaml 注意：您可以指定--record标志以写入在资源批注中执行的命令kubernetes.io/change-cause。它对于将来的内省非常有用，例如，可以查看每个Deployment修订版中执行的命令。 接下来，运行kubectl get deployments。输出类似于以下内容：12NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 0 0 0 1s 检查群集中的“部署”时，将显示以下字段： NAME 列出群集中的部署名称。 DESIRED显示应用程序的所需副本数，您在创建部署时定义这些副本。这是理想的状态。 CURRENT 显示当前正在运行的副本数量。 UP-TO-DATE 显示已更新以实现所需状态的副本数。 AVAILABLE 显示用户可以使用的应用程序副本数。 AGE 显示应用程序运行的时间。 请注意每个字段中的值如何与Deployment规范中的值相对应： 根据.spec.replicas字段，所需副本的数量为3 。 根据.status.replicas字段，当前副本的数量为0 。 根据.status.updatedReplicas字段，最新副本的数量为0 。 根据.status.availableReplicas字段，可用副本的数量为0 。 要查看“部署”卷展栏状态，请运行kubectl rollout status deployment.v1.apps/nginx-deployment。此命令返回以下输出：12Waiting for rollout to finish: 2 out of 3 new replicas have been updated...deployment.apps/nginx-deployment successfully rolled out kubectl get deployments几秒钟后再次运行：12NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 3 3 3 18s 请注意，Deployment已创建所有三个副本，并且所有副本都是最新的（它们包含最新的Pod模板）并且可用（Pod状态至少为Deployment的.spec.minReadySeconds字段值准备就绪）。 要查看rs部署创建的ReplicaSet（），请运行kubectl get rs：12NAME DESIRED CURRENT READY AGEnginx-deployment-2035384211 3 3 3 18s 请注意，ReplicaSet的名称始终格式为[DEPLOYMENT-NAME]-[POD-TEMPLATE-HASH-VALUE]。创建部署时会自动生成哈希值。 要查看为每个pod自动生成的标签，请运行kubectl get pods --show-labels。返回以下输出：1234NAME READY STATUS RESTARTS AGE LABELSnginx-deployment-2035384211-7ci7o 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211nginx-deployment-2035384211-kzszj 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211nginx-deployment-2035384211-qqcnn 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211 创建的ReplicaSet确保始终有三个Pod nginx在运行。 注意：您必须在部署中指定适当的选择器和Pod模板标签（在本例中 app: nginx）。不要将标签或选择器与其他控制器（包括其他部署和StatefulSet）重叠。Kubernetes不会阻止您重叠，如果多个控制器具有重叠的选择器，那么这些控制器可能会发生冲突并出现意外行为。 Pod-template-hash标签 注意：请勿更改此标签。 pod-template-hash部署控制器将标签添加到部署创建或采用的每个ReplicaSet。 此标签可确保部署的子ReplicaSet不重叠。它是通过散列PodTemplateReplicaSet并使用生成的散列作为添加到ReplicaSet选择器，Pod模板标签以及ReplicaSet可能具有的任何现有Pod中的标签值生成的。 更新部署 注意：当且仅当部署的pod模板（即.spec.template）更改时，才会触发Deployment的部署，例如，如果更新模板的标签或容器图像。其他更新（例如扩展部署）不会触发部署。 假设您现在想要更新nginx Pod以使用nginx:1.9.1镜像而不是nginx:1.7.9图像。12$ kubectl --record deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deploymentnginx=nginx:1.9.1 image updated 或者，您可以edit部署和改变.spec.template.spec.containers[0].image从nginx:1.7.9到nginx:1.9.1： 12$ kubectl edit deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment edited 要查看卷展栏状态，请运行：123$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 2 out of 3 new replicas have been updated...deployment.apps/nginx-deployment successfully rolled out 部署成功后，您可能需要get部署：123$ kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 3 3 3 36s 最新副本的数量表示Deployment已将副本更新为最新配置。当前副本表示此部署管理的副本总数，可用副本表示可用的当前副本数。 您可以运行kubectl get rs以查看部署通过创建新的ReplicaSet并将其扩展到3个副本来更新Pod，以及将旧的ReplicaSet缩减为0个副本。1234$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1564180365 3 3 3 6snginx-deployment-2035384211 0 0 0 36s get pods现在运行应该只显示新的Pod：12345$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-1564180365-khku8 1/1 Running 0 14snginx-deployment-1564180365-nacti 1/1 Running 0 14snginx-deployment-1564180365-z9gth 1/1 Running 0 14s 下次要更新这些Pod时，只需再次更新Deployment的pod模板。 部署可以确保在更新时只有一定数量的Pod可能会关闭。默认情况下，它确保至少比所需的Pod数量少25％（最大不可用25％）。 部署还可以确保在所需数量的Pod之上只能创建一定数量的Pod。默认情况下，它确保最多比所需数量的Pod多25％（最大浪涌25％）。 例如，如果仔细查看上面的部署，您将看到它首先创建了一个新的Pod，然后删除了一些旧的Pod并创建了新的Pod。在有足够数量的新Pod出现之前，它不会杀死旧的Pod，并且在足够数量的旧Pod被杀之前不会创建新的Pod。它确保可用Pod的数量至少为2，并且Pod的总数最多为4。12345678910111213141516171819202122232425262728293031323334353637$ kubectl describe deploymentsName: nginx-deploymentNamespace: defaultCreationTimestamp: Thu, 30 Nov 2017 10:56:25 +0000Labels: app=nginxAnnotations: deployment.kubernetes.io/revision=2Selector: app=nginxReplicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: app=nginx Containers: nginx: Image: nginx:1.9.1 Port: 80/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: nginx-deployment-1564180365 (3/3 replicas created)Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 2m deployment-controller Scaled up replica set nginx-deployment-2035384211 to 3 Normal ScalingReplicaSet 24s deployment-controller Scaled up replica set nginx-deployment-1564180365 to 1 Normal ScalingReplicaSet 22s deployment-controller Scaled down replica set nginx-deployment-2035384211 to 2 Normal ScalingReplicaSet 22s deployment-controller Scaled up replica set nginx-deployment-1564180365 to 2 Normal ScalingReplicaSet 19s deployment-controller Scaled down replica set nginx-deployment-2035384211 to 1 Normal ScalingReplicaSet 19s deployment-controller Scaled up replica set nginx-deployment-1564180365 to 3 Normal ScalingReplicaSet 14s deployment-controller Scaled down replica set nginx-deployment-2035384211 to 0 在这里，您可以看到，当您第一次创建部署时，它创建了一个ReplicaSet（nginx-deployment-2035384211）并直接将其扩展到3个副本。更新部署时，它创建了一个新的ReplicaSet（nginx-deployment-1564180365）并将其扩展为1，然后将旧的ReplicaSet缩小为2，这样至少有2个Pod可用，最多创建了4个Pod一直。然后，它继续使用相同的滚动更新策略向上和向下扩展新旧ReplicaSet。最后，您将在新的ReplicaSet中拥有3个可用副本，并将旧的ReplicaSet缩小为0。 Rollover (aka multiple updates in-flight)每次部署控制器观察到新的部署对象时，如果没有现有的ReplicaSet，则会创建ReplicaSet以显示所需的Pod。现有的ReplicaSet控制其标签匹配.spec.selector但模板不匹配的Pod .spec.template按比例缩小。最终，新的ReplicaSet将缩放到，.spec.replicas并且所有旧的ReplicaSet将缩放为0。 如果在现有部署过程中更新部署，则部署将根据更新创建新的ReplicaSet并开始向上扩展，并将翻转之前正在扩展的ReplicaSet - 它会将其添加到其列表中旧的ReplicaSet和将开始缩小它。 例如，假设您创建了一个部署以创建5个副本nginx:1.7.9，但是nginx:1.9.1当仅创建了3个副本时，则更新部署以创建5个副本nginx:1.7.9。在这种情况下，部署将立即开始杀死nginx:1.7.9它创建的3个Pod，并将开始创建 nginx:1.9.1Pod。nginx:1.7.9在更改课程之前，它不会等待创建5个副本。 标签选择器更新通常不鼓励进行标签选择器更新，建议您事先规划选择器。在任何情况下，如果您需要执行标签选择器更新，请务必小心谨慎，并确保您已掌握所有含义。 注意：在API版本中apps/v1，部署的标签选择器在创建后是不可变的。 选择器添加要求使用新标签更新部署规范中的pod模板标签，否则将返回验证错误。此更改是非重叠的，这意味着新选择器不会选择使用旧选择器创建的ReplicaSet和Pod，从而导致孤立所有旧ReplicaSet并创建新的ReplicaSet。 选择器更新 - 即更改选择器键中的现有值 - 导致与添加相同的行为。 选择器删除 - 即从部署选择器中删除现有密钥 - 不需要对pod模板标签进行任何更改。没有现有的ReplicaSet是孤立的，并且未创建新的ReplicaSet，但请注意，已删除的标签仍存在于任何现有的Pod和ReplicaSet中。 回滚部署有时您可能想要回滚部署; 例如，当部署不稳定时，例如崩溃循环。默认情况下，所有Deployment的卷展栏历史记录都保留在系统中，以便您可以随时回滚（可以通过修改修订历史记录限制来更改）。 注意：触发Deployment的部署时会创建Deployment的修订版。这意味着当且仅当部署的pod模板（.spec.template）发生更改时才会创建新修订，例如，如果更新模板的标签或容器图像。其他更新（例如扩展部署）不会创建部署版本，因此您可以方便地同时进行手动或自动扩展。这意味着当您回滚到早期版本时，仅回滚Deployment的pod模板部分。 假设您在更新部署时输入了拼写错误，方法是将图像名称nginx:1.91替换为nginx:1.9.1： 12$ kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=truedeployment.apps/nginx-deployment image updated 推出将被卡住。12$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 1 out of 3 new replicas have been updated... 按Ctrl-C可停止上面的卷展状态监视。有关卡片推出的更多信息， 请在此处阅读更多信息。 您将看到旧副本的数量（nginx-deployment-1564180365和nginx-deployment-2035384211）为2，新副本（nginx-deployment-3066724191）为1。12345$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1564180365 3 3 3 25snginx-deployment-2035384211 0 0 0 36snginx-deployment-3066724191 1 1 0 6s 查看创建的Pod，您将看到由新ReplicaSet创建的1 Pod陷入图像拉环。123456$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-1564180365-70iae 1/1 Running 0 25snginx-deployment-1564180365-jbqqo 1/1 Running 0 25snginx-deployment-1564180365-hysrc 1/1 Running 0 25snginx-deployment-3066724191-08mng 0/1 ImagePullBackOff 0 6s 注意： Deployment控制器将自动停止错误的卷展栏，并将停止扩展新的ReplicaSet。这取决于maxUnavailable您指定的rollingUpdate参数（特别是）。默认情况下，Kubernetes将值设置为25％。 1234567891011121314151617181920212223242526272829303132333435363738$ kubectl describe deploymentName: nginx-deploymentNamespace: defaultCreationTimestamp: Tue, 15 Mar 2016 14:48:04 -0700Labels: app=nginxSelector: app=nginxReplicas: 3 desired | 1 updated | 4 total | 3 available | 1 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: app=nginx Containers: nginx: Image: nginx:1.91 Port: 80/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True ReplicaSetUpdatedOldReplicaSets: nginx-deployment-1564180365 (3/3 replicas created)NewReplicaSet: nginx-deployment-3066724191 (1/1 replicas created)Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-2035384211 to 3 22s 22s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 1 22s 22s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 2 22s 22s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 2 21s 21s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 1 21s 21s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 3 13s 13s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 0 13s 13s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-3066724191 to 1 要解决此问题，您需要回滚到稳定的以前版本的Deployment。 检查部署的部署历史记录首先，检查此部署的修订版：123456$ kubectl rollout history deployment.v1.apps/nginx-deploymentdeployments "nginx-deployment"REVISION CHANGE-CAUSE1 kubectl create --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml --record=true2 kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true3 kube ctl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=true CHANGE-CAUSEkubernetes.io/change-cause在创建时从部署批注复制到其修订版。您可以CHANGE-CAUSE通过以下方式指定消息： 注释部署 kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause=&quot;image updated to 1.9.1&quot; 附加--record标志以保存kubectl对资源进行更改的命令。 手动编辑资源的清单。 要进一步查看每个修订的详细信息，请运行：1234567891011121314$ kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2deployments "nginx-deployment" revision 2 Labels: app=nginx pod-template-hash=1159050644 Annotations: kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true Containers: nginx: Image: nginx:1.9.1 Port: 80/TCP QoS Tier: cpu: BestEffort memory: BestEffort Environment Variables: &lt;none&gt; No volumes. 回滚到以前的版本现在，您已决定撤消当前的卷展栏并回滚到上一版本：12$ kubectl rollout undo deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment 或者，您可以通过在--to-revision以下位置指定回滚到特定修订：12$ kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=2deployment.apps/nginx-deployment 有关与推出相关的命令的更多详细信息，请阅读kubectl rollout。 部署现在回滚到以前的稳定版本。如您所见，DeploymentRollback从Deployment控制器生成用于回滚到版本2 的事件。12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ kubectl get deployment nginx-deploymentNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 3 3 3 30m$ kubectl describe deployment nginx-deploymentName: nginx-deploymentNamespace: defaultCreationTimestamp: Sun, 02 Sep 2018 18:17:55 -0500Labels: app=nginxAnnotations: deployment.kubernetes.io/revision=4 kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=trueSelector: app=nginxReplicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: app=nginx Containers: nginx: Image: nginx:1.9.1 Port: 80/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: nginx-deployment-c4747d96c (3/3 replicas created)Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 12m deployment-controller Scaled up replica set nginx-deployment-75675f5897 to 3 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-c4747d96c to 1 Normal ScalingReplicaSet 11m deployment-controller Scaled down replica set nginx-deployment-75675f5897 to 2 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-c4747d96c to 2 Normal ScalingReplicaSet 11m deployment-controller Scaled down replica set nginx-deployment-75675f5897 to 1 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-c4747d96c to 3 Normal ScalingReplicaSet 11m deployment-controller Scaled down replica set nginx-deployment-75675f5897 to 0 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-595696685f to 1 Normal DeploymentRollback 15s deployment-controller Rolled back deployment "nginx-deployment" to revision 2 Normal ScalingReplicaSet 15s deployment-controller Scaled down replica set nginx-deployment-595696685f to 0 扩展部署您可以使用以下命令扩展部署：12$ kubectl scale deployment.v1.apps/nginx-deployment --replicas=10deployment.apps/nginx-deployment scaled 假设在群集中启用了水平pod自动缩放，则可以为Deployment设置自动缩放器，并根据现有Pod的CPU利用率选择要运行的最小和最大Pod数。 12$ kubectl autoscale deployment.v1.apps/nginx-deployment --min=10 --max=15 --cpu-percent=80deployment.apps/nginx-deployment scaled 比例缩放RollingUpdate Deployments支持同时运行多个版本的应用程序。当您或自动扩展器扩展正在部署（正在进行或暂停）的RollingUpdate部署时，部署控制器将平衡现有活动副本集（具有Pod的副本集）中的其他副本，以降低风险。这称为比例缩放。 例如，您正在运行具有10个副本的部署，maxSurge = 3和maxUnavailable = 2。123$ kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 10 10 10 10 50s 您更新到一个新的映像，该映像恰好在集群内部无法解析。12$ kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:sometagdeployment.apps/nginx-deployment image updated 图像更新使用ReplicaSet nginx-deployment-1989198191开始新的部署，但由于maxUnavailable您在上面提到的要求而被阻止 。1234$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1989198191 5 5 0 9snginx-deployment-618515232 8 8 8 1m 然后出现一个新的部署扩展请求。自动缩放器将部署副本增加到15.部署控制器需要决定在哪里添加这些新的5个副本。如果您没有使用比例缩放，则所有5个都将添加到新的ReplicaSet中。通过比例缩放，您可以在所有ReplicaSet上传播其他副本。具有最多副本的ReplicaSets和较低比例的较大比例将转到具有较少副本的ReplicaSet。任何剩余物都会添加到具有最多副本的ReplicaSet中。零副本的ReplicaSet不会按比例放大。 在上面的示例中，3个副本将添加到旧的ReplicaSet中，2个副本将添加到新的ReplicaSet中。假设新副本变得健康，推出过程最终应将所有副本移动到新的ReplicaSet。1234567$ kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 15 18 7 8 7m$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1989198191 7 7 0 7mnginx-deployment-618515232 11 11 11 7m 暂停和恢复部署您可以在触发一个或多个更新之前暂停部署，然后恢复它。这将允许您在暂停和恢复之间应用多个修复，而不会触发不必要的部署。 例如，使用刚刚创建的部署：123456$ kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx 3 3 3 3 1m$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-2142116321 3 3 3 1m 通过运行以下命令暂停：12$ kubectl rollout pause deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment paused 然后更新部署的映像：12$ kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1deployment.apps/nginx-deployment image updated 请注意，没有新的卷展栏开始：12345678$ kubectl rollout history deployment.v1.apps/nginx-deploymentdeployments "nginx"REVISION CHANGE-CAUSE1 &lt;none&gt;$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-2142116321 3 3 3 2m 您可以根据需要进行更多更新，例如，更新将使用的资源：12$ kubectl set resources deployment.v1.apps/nginx-deployment -c=nginx --limits=cpu=200m,memory=512Mideployment.apps/nginx-deployment resource requirements updated 暂停之前部署的初始状态将继续其功能，但只要部署暂停，部署的新更新将不会产生任何影响。 最后，恢复部署并观察一个新的ReplicaSet，提供所有新的更新：1234567891011121314151617181920212223$ kubectl rollout resume deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment resumed$ kubectl get rs -wNAME DESIRED CURRENT READY AGEnginx-2142116321 2 2 2 2mnginx-3926361531 2 2 0 6snginx-3926361531 2 2 1 18snginx-2142116321 1 2 2 2mnginx-2142116321 1 2 2 2mnginx-3926361531 3 2 1 18snginx-3926361531 3 2 1 18snginx-2142116321 1 1 1 2mnginx-3926361531 3 3 1 18snginx-3926361531 3 3 2 19snginx-2142116321 0 1 1 2mnginx-2142116321 0 1 1 2mnginx-2142116321 0 0 0 2mnginx-3926361531 3 3 3 20s^C$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-2142116321 0 0 0 2mnginx-3926361531 3 3 3 28s 注意：在恢复暂停部署之前，无法回滚暂停部署。 部署状态部署在其生命周期中进入各种状态。它可以前进，同时推出新ReplicaSet，也可以是完整的，也可以不取得进展。 进步部署当执行以下任务之一时，Kubernetes将部署标记为进度： 部署创建一个新的ReplicaSet。 部署正在扩展其最新的ReplicaSet。 部署正在缩减其旧的ReplicaSet。 新Pod已准备就绪或可用（至少准备MinReadySeconds）。 您可以使用监视部署的进度kubectl rollout status。 完成部署Kubernetes 在具有以下特征时将部署标记为完成： 与部署关联的所有副本都已更新为您指定的最新版本，这意味着您已请求的任何更新已完成。 可以使用与部署关联的所有副本。 没有旧的部署副本正在运行。 您可以使用检查部署是否已完成kubectl rollout status。如果卷展栏成功完成，则kubectl rollout status返回零退出代码。 12345$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 2 of 3 updated replicas are available...deployment.apps/nginx-deployment successfully rolled out$ echo $?0 部署失败您的部署可能会在尝试部署其最新的ReplicaSet时遇到困难，而无需完成。这可能是由于以下一些因素造成的： 配额不足 准备探针失败 图像拉错误 权限不足 限制范围 应用程序运行时配置错误 检测此情况的一种方法是在部署规范中指定截止时间参数:(.spec.progressDeadlineSeconds）。.spec.progressDeadlineSeconds表示部署控制器在指示（在“部署”状态中）部署进度已停止之前等待的秒数。 以下kubectl命令设置规范progressDeadlineSeconds以使控制器报告在10分钟后缺少部署进度： 12$ kubectl patch deployment.v1.apps/nginx-deployment -p '&#123;"spec":&#123;"progressDeadlineSeconds":600&#125;&#125;'deployment.apps/nginx-deployment patched 超过截止日期后，Deployment控制器会向Deployment部署一个具有以下属性的DeploymentCondition .status.conditions： 类型=进展 状态=假 原因= ProgressDeadlineExceeded 有关状态条件的更多信息，请参阅Kubernetes API约定。 注意：除了报告状态条件之外，Kubernetes不对停顿的部署采取任何操作 Reason=ProgressDeadlineExceeded。更高级别的协调器可以利用它并相应地采取相应措施，例如，将部署回滚到其先前版本。 注意：如果您暂停部署，Kubernetes不会根据您指定的截止日期检查进度。您可以安全地在部署和暂停期间暂停部署，而不会触发超出截止日期的条件。 由于您设置的超时时间较短或者由于任何其他可被视为瞬态的错误，您可能会遇到部署的暂时性错误。例如，假设您的配额不足。如果您描述部署，您将注意到以下部分： 123456789$ kubectl describe deployment nginx-deployment&lt;...&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True ReplicaSetUpdated ReplicaFailure True FailedCreate&lt;...&gt; 如果您运行kubectl get deployment nginx-deployment -o yaml，部署状态可能如下所示：12345678910111213141516171819202122232425status: availableReplicas: 2 conditions: - lastTransitionTime: 2016-10-04T12:25:39Z lastUpdateTime: 2016-10-04T12:25:39Z message: Replica set "nginx-deployment-4262182780" is progressing. reason: ReplicaSetUpdated status: "True" type: Progressing - lastTransitionTime: 2016-10-04T12:25:42Z lastUpdateTime: 2016-10-04T12:25:42Z message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: "True" type: Available - lastTransitionTime: 2016-10-04T12:25:39Z lastUpdateTime: 2016-10-04T12:25:39Z message: 'Error creating: pods "nginx-deployment-4262182780-" is forbidden: exceeded quota: object-counts, requested: pods=1, used: pods=3, limited: pods=2' reason: FailedCreate status: "True" type: ReplicaFailure observedGeneration: 3 replicas: 2 unavailableReplicas: 2 最终，一旦超出部署进度截止日期，Kubernetes将更新状态和进度条件的原因：123456Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing False ProgressDeadlineExceeded ReplicaFailure True FailedCreate 您可以通过缩小部署，缩小可能正在运行的其他控制器或增加命名空间中的配额来解决配额不足的问题。如果您满足配额条件，然后部署控制器完成“部署”卷展栏，您将看到部署状态更新成功条件（Status=True和Reason=NewReplicaSetAvailable）。12345Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable Type=Available与Status=True您的部署具有最小可用性手段。最低可用性由部署策略中指定的参数决定。Type=Progressing和 Status=True表示您的部署正处于推出过程中并且正在进行中或已成功完成其进度并且所需的最小新副本可用（请参阅详细信息的条件原因 - 在我们的情况下 Reason=NewReplicaSetAvailable意味着部署完成）。 您可以使用检查部署是否未能进展kubectl rollout status。kubectl rollout status 如果部署已超过进度截止日期，则返回非零退出代码。 12345$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 2 out of 3 new replicas have been updated...error: deployment "nginx" exceeded its progress deadline$ echo $?1 在失败的部署上运行适用于完整部署的所有操作也适用于失败的部署。如果需要在“部署”窗格模板中应用多个调整，可以向上/向下缩放，回滚到以前的版本，甚至可以暂停它。 清理政策您可以.spec.revisionHistoryLimit在部署中设置字段，以指定要保留此部署的旧ReplicaSet数。其余的将在后台进行垃圾收集。默认情况下，它是10。 注意：将此字段显式设置为0将导致清理部署的所有历史记录，从而部署将无法回滚。 用例Canary部署如果要使用部署将发布部署到用户或服务器的子集，则可以按照管理资源中描述的canary模式创建多个部署，每个版本一个 。 编写部署规范与所有其他Kubernetes CONFIGS，部署需求apiVersion，kind以及metadata各个领域。有关使用配置文件的一般信息，请参阅部署应用程序，配置容器以及使用kubectl管理资源文档。 部署还需要一个.spec部分。 Pod模板这.spec.template是唯一必需的领域.spec。 这.spec.template是一个pod模板。它与Pod具有完全相同的架构，除了它是嵌套的并且没有 apiVersion或kind。 除了Pod的必填字段外，部署中的pod模板还必须指定适当的标签和适当的重新启动策略。对于标签，请确保不要与其他控制器重叠。见选择器）。 只允许.spec.template.spec.restartPolicy等于Always，如果未指定，则为默认值。 副本.spec.replicas是一个可选字段，指定所需Pod的数量。默认为1。 选择.spec.selector是一个可选字段，用于指定 此部署所针对的Pod 的标签选择器。 .spec.selector必须匹配.spec.template.metadata.labels，否则它将被API拒绝。 在API版本apps/v1，.spec.selector并且.metadata.labels不默认.spec.template.metadata.labels，如果没有设置。所以必须明确设置它们。另请注意，.spec.selector在创建部署后，它是不可变的apps/v1。 部署可以终止其标签与选择器匹配的Pod，如果它们的模板不同.spec.template或者此类Pod的总数超过.spec.replicas。.spec.template如果Pod 的数量小于所需的数量，它会调出新的Pod 。 注意：您不应通过创建另一个部署或通过创建另一个控制器（如ReplicaSet或ReplicationController）来创建其标签与此选择器匹配的其他pod。如果您这样做，第一个部署认为它创建了这些其他pod。Kubernetes并没有阻止你这样做。 如果您有多个具有重叠选择器的控制器，控制器将相互争斗并且行为不正确。 战略.spec.strategy指定用于替换旧Pod的策略。 .spec.strategy.type可以是“重新创建”或“RollingUpdate”。“RollingUpdate”是默认值。 重新创建部署所有现有的Pod都会在创建新的Pod之前被杀死.spec.strategy.type==Recreate。 滚动更新部署部署时会以滚动更新 方式更新Pod .spec.strategy.type==RollingUpdate。您可以指定maxUnavailable并maxSurge控制滚动更新过程。 maxUnavailable .spec.strategy.rollingUpdate.maxUnavailable是一个可选字段，指定更新过程中可用的最大Pod数。该值可以是绝对数（例如，5）或所需Pod的百分比（例如，10％）。通过四舍五入计算绝对数字的百分比。如果.spec.strategy.rollingUpdate.maxSurge为0，则该值不能为0.默认值为25％。 例如，当此值设置为30％时，旧的ReplicaSet可以在滚动更新开始时立即按比例缩小到所需Pod的70％。准备好新的Pod后，可以进一步缩小旧的ReplicaSet，然后扩展新的ReplicaSet，确保在更新期间始终可用的Pod总数至少是所需Pod的70％。 Max Surge .spec.strategy.rollingUpdate.maxSurge是一个可选字段，指定可以在所需数量的Pod上创建的最大Pod数。该值可以是绝对数（例如，5）或所需Pod的百分比（例如，10％）。如果MaxUnavailable为0，则该值不能为0.绝对数量是通过向上舍入的百分比计算的。默认值为25％。 例如，当此值设置为30％时，可以在滚动更新开始时立即按比例放大新的ReplicaSet，这样旧的和新的Pod的总数不会超过所需Pod的130％。一旦旧的Pod被杀死，新的ReplicaSet可以进一步扩展，确保在更新期间随时运行的Pod总数最多为所需Pod的130％。 进度截止日期.spec.progressDeadlineSeconds是一个可选字段，指定在系统报告部署失败进度之前等待部署进度的秒数 - 表示为带有Type=Progressing，Status=False。的条件。以及Reason=ProgressDeadlineExceeded资源的状态。部署控制器将继续重试部署。将来，一旦实现自动回滚，部署控制器将在观察到这种情况后立即回滚部署。 如果指定，则此字段必须大于.spec.minReadySeconds。 Min Ready Seconds.spec.minReadySeconds是一个可选字段，指定新创建的Pod应该在没有任何容器崩溃的情况下准备好的最小秒数，以使其可用。默认为0（Pod一旦准备好就会被视为可用）。要了解有关何时认为Pod已准备就绪的详细信息，请参阅容器探测器。 回滚现场.spec.rollbackTo已被弃用的API版本extensions/v1beta1和apps/v1beta1，并在API版本不再支持开始apps/v1beta2。相反，应该使用回滚到先前版本中的kubectl rollout undo介绍。 修订历史限制部署的修订历史记录存储在它控制的副本集中。 .spec.revisionHistoryLimit是一个可选字段，指定要保留以允许回滚的旧ReplicaSet的数量。其理想值取决于新部署的频率和稳定性。如果未设置此字段，则默认情况下将保留所有旧的ReplicaSet，消耗资源etcd并拥挤输出kubectl get rs。每个Deployment修订版的配置都存储在其ReplicaSet中; 因此，一旦删除旧的ReplicaSet，您将无法回滚到该部署版本。 更具体地说，将此字段设置为零意味着将清除所有具有0副本的旧ReplicaSet。在这种情况下，无法撤消新的“部署”卷展栏，因为它的修订历史记录已清除。 已暂停.spec.paused是一个可选的布尔字段，用于暂停和恢复部署。暂停部署与未暂停部署之间的唯一区别是，暂停部署的PodTemplateSpec的任何更改都不会触发新的部署，只要它暂停即可。默认情况下，部署在创建时不会暂停。 部署的替代方案kubectl滚动更新kubectl rolling update以类似的方式更新Pod和ReplicationControllers。但建议使用部署，因为它们是声明性的，服务器端，并且具有其他功能，例如即使在滚动更新完成后回滚到任何先前的修订版。]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Shadowsocks客户端]]></title>
    <url>%2F2019%2F01%2F11%2FCentOS%E4%B8%8A%E5%AE%89%E8%A3%85Shadowsocks%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[CentOS上安装Shadowsocks客户端Shadowsocks简介Shadowsocks，是一种加密的传输方式（一种基于 Socks5 代理方式的网络数据加密传输包）；SS 是目前主流的科学上网方式，是目前最稳定最好用的科学上网工具之一。 安装安装pippip是Python的包管理工具，我们接下来是使用pip安装的Shadowsocks。 通过yum管理工具安装： 1yum install -y pip 镜像库没有这个包，那么可以手动安装: 12curl "https://bootstrap.pypa.io/get-pip.py" -o "get-pip.py"python get-pip.py 安装Shadowsocks客户端12pip install --upgrade pippip install shadowsocks 新建配置文件vi /etc/shadowsocks.json：12345678910&#123;"server":"x.x.x.x","server_port":25247,"local_address": "127.0.0.1","local_port":25252,"password":"123456","timeout":1000,"method":"aes-256-cfb","workers": 10&#125; 编写启动服务vi /etc/systemd/system/shadowsocks.service:123456789[Unit]Description=shadowsocks[Service]TimeoutStartSec=30ExecStart=/usr/bin/sslocal -c /etc/shadowsocks.json[Install]WantedBy=multi-user.target 启动服务systemctl start shadowsocks，运行 curl --socks5 127.0.0.1:25252 http://httpbin.org/ip ， 返回你ss服务器ip，则说明Shadowsocks客户端启动成功。 使用Privoxy把shadowsocks转换为Http代理Privoxy简介Privoxy是一个代理辅助工具，这里用Privoxy把Shadowsocks socks5代理转换为http代理。可以作为kubernetes的docker容器需要访问google的服务，也同时可以作为命令行的代理，本实例用作命令行代理。 安装使用yum安装：1yum install privoxy -y 修改配置文件vi /etc/privoxy/config，加入一行代码12forward-socks5 / 127.0.0.1:25252 .listen-address 127.0.0.1:8118 #这里的ip也可以是k8s的ip 启动服务systemctl start privoxy，执行命令curl -x localhost:8118 google.com，返回数据则表示服务启动成功 全局设置编辑文件vi /etc/profile：12export http_proxy=http://127.0.0.1:8118export https_proxy=http://127.0.0.1:8118 使配置生效1source /etc/profile 测试代码curl www.google.com，返回数据则成功设置全局命令行代理]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Frp内网穿透反向代理的端口转发实现本地服务器]]></title>
    <url>%2F2019%2F01%2F07%2F%E5%9F%BA%E4%BA%8EFrp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[基于frp内网穿透反向代理的端口转发实现本地服务器frp简介frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。 利用处于内网或防火墙后的机器，对外网环境提供 http 或 https 服务。 对于 http, https 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个80端口。 利用处于内网或防火墙后的机器，对外网环境提供 tcp 和 udp 服务，例如在家里通过 ssh 访问处于公司内网环境内的主机。 使用准备条件公网服务器一台，内网服务器一台，公网服务器绑定域名1个。 开始搭建公网服务器ssh连接到公网服务器上，新建目录 1mkdir -p /usr/local/frp 根据对应的操作系统及架构，从 Release 页面下载最新版本的程序。 1wget https://github.com/fatedier/frp/releases/download/v0.22.0/frp_0.22.0_linux_arm64.tar.gz 解压 1tar -zxvf frp_0.22.0_linux_arm64.tar.gz 首先删掉frpc、frpc.ini两个文件，然后再进行配置修改frps.ini文件，这里使用了最简化的配置： 1234567891011# frps.ini[common]bind_port = 7000vhost_http_port = 6081max_pool_count = 20allow_ports = 2000-3000,6081,4000-50000 #端口白名单dashboard_port = 7500dashboard_user = admindashboard_pwd = admintoken = 123456 #客户端也要配置一样的tokenauthentication_timeout = 90000 #超时时间，如果客户端遇到服务启动认证失败，大概率是时区问题，服务器设置一下就好了 保存然后启动服务1./frps -c ./frps.ini 这是前台启动，后台启动命令为 1nohup ./frps -c ./frps.ini &amp; 可以通过访问http://xx.xx.xx.xx:7500/static/#/proxies/tcp访问frp服务的监控界面，账号密码与上面配置的一致。 内网服务器根据对应的操作系统及架构，从 Release 页面下载最新版本的程序。 1wget https://github.com/fatedier/frp/releases/download/v0.22.0/frp_0.22.0_linux_arm64.tar.gz 解压 1tar -zxvf frp_0.22.0_linux_arm64.tar.gz 首先删掉frpc、frpc.ini两个文件，然后再进行配置修改 frpc.ini 文件。 123456789101112131415161718# frpc.ini[common]server_addr = xx.xx.xx.xx #公网ip地址server_port = 7000token = 123456 #公网通过ssh访问内部服务器[ssh]type = tcp #连接协议local_ip = 127.0.0.1local_port = 22 #ssh默认端口号remote_port = 6000 #自定义的访问内部ssh端口号 #公网访问内部web服务器以http方式[web]type = http #访问协议local_port = 8081 #内网web服务的端口号custom_domains = strongcat.top #所绑定的公网服务器域名，一级、二级域名都可以 保存然后执行启动 1./frpc -c ./frpc.ini 这是前台启动，后台启动命令为 1nohup ./frpc -c ./frpc.ini &amp; 认证超时解决办法一般认证超时的原因是由于2个服务器之间时间不同，可以通过命令tzselect修改时区，按照步骤设置时区1$ tzselect 同步服务器时间123sudo yum install ntptimedatectl set-timezone Asia/Shanghaitimedatectl set-ntp yes 查看时间确保同步timedatectl 开机自启动我用的是centOS7的操作系统，为了防止因为网络或者重启问题Frp失效，所以写了一个开机启动服务，公网服务器配置： 12345678910111213[Unit]Description=frp[Service]TimeoutStartSec=30Type=simpleExecStart=/root/frp/frp_0.22.0_linux_386/frps -c /root/frp/frp_0.22.0_linux_386/frps.iniExecStop=/bin/kill $MAINPIDRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target 内网服务器配置：123456789101112131415[Unit]Description=frpAfter=network.targetWants=network.target[Service]TimeoutStartSec=30Type=simpleExecStart=/root/frp/frp_0.22.0_linux_386/frpc -c /root/frp/frp_0.22.0_linux_386/frpc.iniExecStop=/bin/kill $MAINPIDRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target 文件保存到/etc/systemd/system/frp.service中，并执行systemctl daemon-reload，systemctl start frp,开机启动systemctl enable frp 外网ssh访问内网服务器（直接使用配置里面数据演示） 1ssh -oPort=6000 root@x.x.x.x 将 www.strongcat.top 的域名 A 记录解析到 IP x.x.x.x，如果服务器已经有对应的域名，也可以将 CNAME 记录解析到服务器原先的域名。 通过浏览器访问 http://www.yourdomain.com:8080 即可访问到处于内网机器上的 web 服务。 有些系统默认自带防火墙，需要开通端口 123firewall-cmd --zone=public --add-port=6000/tcp --permanent systemctl stop firewalld.service systemctl start firewalld.service 如果遇到authorization timeout错误的话，需要进行2个服务器之间的时间同步。2边服务器都执行下面的命令：1234567891011#下载ntpdateyum install -y ntpdate#调整时区为上海，也就是北京时间+8区cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeyes | cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime#使用NTP来同步时间ntpdate us.pool.ntp.org#定时同步时间（每隔10分钟同步时钟）crontab -l &gt;/tmp/crontab.bakecho "*/10 * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP" &gt;&gt; /tmp/crontab.bakcrontab /tmp/crontab.bak 如果是像我这种笔记本的话，可以设置系统关闭盖子的动作1vim /etc/systemd/logind.conf 12345678910111213HandlePowerKey 按下电源键后的行为，默认power offHandleSleepKey 按下挂起键后的行为，默认suspendHandleHibernateKey 按下休眠键后的行为，默认hibernateHandleLidSwitch 合上笔记本盖后的行为，默认suspendignore 忽略，跳过power off 关机eboot 重启halt 挂起suspend shell内建指令，可暂停目前正在执行的shell。若要恢复，则必须使用SIGCONT信息。所有的进程都会暂停，但不是消失（halt是进程关闭）hibernate 让笔记本进入休眠状态hybrid-sleep 混合睡眠，主要是为台式机设计的，是睡眠和休眠的结合体，当你选择Hybird时，系统会像休眠一样把内存里的数据从头到尾复制到硬盘里 ，然后进入睡眠状态，即内存和CPU还是活动的，其他设置不活动，这样你想用电脑时就可以快速恢复到之前的状态了，笔记本一般不用这个功能。lock 仅锁屏，计算机继续工作。 更多指令可以参考这篇博客 最后重新加载服务使配置生效1systemctl restart systemd-logind 进阶（配合nginx实现域名转发）购买域名购买域名，国内需要备案，然后再阿里云中添加域名，创建域名解析，如图所示 安装nginx1docker pull nginx 新建文件nginx.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # frp的接收http请求的反向代理 server &#123; listen 80; server_name *.strongsickcat.com strongsickcat.com; location / &#123; # 7071端口即为frp监听的http端口 proxy_pass http://127.0.0.1:8080; proxy_set_header Host $host:80; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade"; proxy_connect_timeout 7d; proxy_send_timeout 7d; proxy_read_timeout 7d; &#125; # 防止爬虫抓取 if ($http_user_agent ~* "360Spider|JikeSpider|Spider|spider|bot|Bot|2345Explorer|curl|wget|webZIP|qihoobot|Baiduspider|Googlebot|Googlebot-Mobile|Googlebot-Image|Mediapartners-Google|Adsbot-Google|Feedfetcher-Google|Yahoo! Slurp|Yahoo! Slurp China|YoudaoBot|Sosospider|Sogou spider|Sogou web spider|MSNBot|ia_archiver|Tomato Bot|NSPlayer|bingbot") &#123; return 403; &#125; &#125;&#125; docker启动nginx1docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx 附上frp客户端与服务端配置123456789101112#frps.ini[common]bind_port = 7000max_pool_count = 20allow_ports = 4000-50000dashboard_port = 7500dashboard_user = admindashboard_pwd = 742041978token = 2524668868authentication_timeout = 900vhost_http_port = 8080subdomain_host = strongsickcat.com 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#客户端 frpc.ini[common]server_addr = 106.15.226.184server_port = 7000token = 2524668868admin_addr = 127.0.0.1admin_port = 7400[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 6000[test_static_file]type = tcpremote_port = 16001plugin = static_fileplugin_local_path = /root/fileplugin_strip_prefix = staticplugin_http_user = adminplugin_http_passwd = 742041978[kibana]type = http# local_port代表你想要暴露给外网的本地web服务端口local_port = 5601# subdomain 在全局范围内要确保唯一，每个代理服务的subdomain不能重名，否则会影响正常使用。# 客户端的subdomain需和服务端的subdomain_host配合使用subdomain = kibana[elasticsearch]type = httplocal_port = 9200subdomain = elasticsearch[mysql]type = tcplocal_port = 3306remote_port = 13306[prometheus]type = httplocal_port = 9090subdomain = prometheus[prometheus-linux]type = tcplocal_port = 9100remote_port = 9100[prometheus-mysql]type = tcplocal_port = 9104remote_port = 9104[grafana]type = httplocal_port = 3000subdomain = grafana[prometheusa]type = tcplocal_port = 9090remote_port = 9090 按照我的配置文件，可以直接通过子域名访问kibana服务http://kibana.strongsickcat.com:8080]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selenium测试框架]]></title>
    <url>%2F2019%2F01%2F04%2FSelenium%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Selenium官网 Selenium简介Selenium可以对浏览器进行自动化测试。它主要用于自动化Web应用程序以进行测试，但当然不仅限于此。无聊的基于Web的管理任务也可以自动化。 Selenium得到了一些最大的浏览器供应商的支持，这些供应商已采取（或正在采取）将Selenium作为其浏览器本机部分的步骤。它也是无数其他浏览器自动化工具，API和框架的核心技术。支持多种语言，在java中可以作为自动化测试框架，在python中可以模拟页面用户点击对自动化爬虫进行补充。 支持的浏览器： Selenium使用Selenium提供了一种非常简单的开发方式，例如用Chrome开发的话，去开发者工具下载Katalon Selenium IDE，如图所示。 开始录制录制过程中，IDE会自动帮我们把命令行插入到测试用例中，包括： 单击链接 输入值 从下拉框选择数据 单击按钮或者选择框点击开始录制，在最上方输入网站域名，后期可以通过更换域名来实现不同域名下的应用的测试。 使用上下文菜单添加验证和断言使用Selenium IDE录制，转到显示测试应用程序的浏览器，然后右键单击页面上的任意位置。您将看到一个显示验证和/或断言命令的上下文菜单。Selenium命令有三种“风格”：动作，访问器和断言。 动作是通常操纵应用程序状态的命令。他们执行“点击此链接”和“选择该选项”之类的操作。如果操作失败或出错，则停止执行当前测试。 访问者检查应用程序的状态并将结果存储在变量中，例如“storeTitle”。它们还用于自动生成断言。 断言与访问器类似，但它们验证应用程序的状态是否符合预期。示例包括“确保页面标题为X”和“验证是否选中此复选框”。 脚本语法命令很简单，由2个参数构成： verifyText //div//a[2] Login 这些参数并不总是必需的;这取决于命令。在某些情况下，两者都是必需的，在其他情况下需要一个参数，而在另一些情况下，命令可能根本不需要参数。这里有几个例子： chooseCancelOnNextPrompt pause 500 type id=phone (555) 666-7066 type id=address1 ${myVariableAddress} 命令参考描述了每个命令的参数要求。 参数有所不同，但它们通常是： Locators用于标识页面内UI元素的定位器。 text patterns用于验证或声明预期页面内容的文本模式。 text patterns or selenium variables文本模式或selenium变量，用于在输入字段中输入文本或从选项列表中选择选项。常用的Selenium命令 open 打开url页面 click 执行单击操作，并可选择等待加载新页面。 verifyTitle/assertTitle 验证预期的页面标题。 verifyTextPresent 验证预期文本是否在页面上的某个位置。 verifyText 验证预期文本及其相应的HTML标记出现在页面上。 verifyTable 验证表的预期内容。 验证页面元素断言与验证的选择 assert 错误后会不继续执行并中断当前的测试用例 verify 错误后会继续执行的最佳用途是对测试命令进行逻辑分组，并使用“assert”后跟一个或多个“verify”测试命令启动每个组。一个例子如下： verifyElementPresent Command Target Value verifyElementPresent //div/p/img 此命令验证页面上是否存在由&lt;img&gt; HTML标记的存在指定的图像，并且它遵循&lt;div&gt;标记和&lt;p&gt;标记。第一个（也是唯一的）参数是一个定位器，用于告诉Selenese命令如何查找元素。verifyElementPresent可用于检查页面中是否存在任何HTML标记。您可以检查链接，段落，分区&lt;div&gt;等是否存在。以下是一些示例。 Command Target Value verifyElementPresent //div/p verifyElementPresent //div/a verifyElementPresent id=Login verifyElementPresent link=Go to Marketing Research verifyElementPresent //a[2] verifyElementPresent //head/title verifyText必须在测试文本及其UI元素时使用verifyText。 verifyText必须使用定位器。如果选择XPath或DOM定位器，则可以验证特定文本是否显示在页面上相对于页面上其他UI组件的特定位置。Command | Target | Value—|— |—verifyText |//table/tr/td/div/p | This is my text and it occurs right after the div inside the table. 定位元素对于许多Selenium命令，需要一个目标。此目标标识Web应用程序内容中的元素，并包含位置策略，后跟位置格式为locatorType = location。在许多情况下可以省略定位器类型。下面解释各种定位器类型，每个定位器类型都有示例。 按标识符定位例如，页面源可以具有id和name属性，如下所示：12345678910&lt;html&gt; &lt;body&gt; &lt;form id="loginForm"&gt; &lt;input name="username" type="text" /&gt; &lt;input name="password" type="password" /&gt; &lt;input name="continue" type="submit" value="Login" /&gt; &lt;input name="continue" type="button" value="Clear" /&gt; &lt;/form&gt; &lt;/body&gt;&lt;html&gt; 以下定位器策略将返回上面由行号指示的HTML片段中的元素： identifier=loginForm (3) identifier=password (5) identifier=continue (6) continue (6)由于定位器的标识符类型是默认值，因此上面的前三个示例中的标识符=不是必需的。 通过id定位 id=loginForm (3) 通过名称定位 name=username (4) name=continue value=Clear (7) name=continue Clear (7) name=continue type=button (7) 与某些类型的XPath和DOM定位器不同，上面三种类型的定位器允许Selenium测试UI元素，而与其在页面上的位置无关。因此，如果页面结构和组织被更改，测试仍将通过。您可能想也可能不想测试页面结构是否发生变化。在Web设计者经常更改页面但其功能必须经过回归测试的情况下，通过id和name属性进行测试，或者通过任何HTML属性进行测试变得非常重要。 由于只有xpath定位符以“//”开头，因此在指定XPath定位符时不必包含xpath =标签。 xpath=/html/body/form[1] (3) - 绝对路径（如果HTML仅稍微更改，则会中断） //form[1] (3) - HTML中的第一个表单元素 xpath=//form[@id=’loginForm’] (3) - 表单元素，其属性名为“id”，值为“loginForm” xpath=//form[input/@name=’username’] (3) - 带有输入子元素的第一个表单元素，其属性名为“name”，值为“username” //input[@name=’username’] (4) - 第一个输入元素，其属性名为“name”，值为“username” //form[@id=’loginForm’]/input[1] (4) - 表单元素的第一个输入子元素，其属性名为“id”，值为“loginForm” //input[@name=’continue’][@type=’button’] (7) -输入名为’name’的属性和值’continue’以及名为’type’的属性和值’button’ //form[@id=’loginForm’]/input[4] (7) - 表单元素的第四个输入子元素，其属性名为“id”，值为“loginForm” 主要的语法参考Xpath可以使用浏览器的devtools复制XPath： 通过链接文本查找超链接 这是一种使用链接文本在网页中查找超链接的简单方法。如果存在具有相同文本的两个链接，则将使用第一个匹配。1234567&lt;html&gt; &lt;body&gt; &lt;p&gt;Are you sure you want to do this?&lt;/p&gt; &lt;a href="continue.html"&gt;Continue&lt;/a&gt; &lt;a href="cancel.html"&gt;Cancel&lt;/a&gt;&lt;/body&gt;&lt;html&gt; link=Continue (4) link=Cancel (5) 通过CSS定位 12345678910&lt;html&gt; &lt;body&gt; &lt;form id="loginForm"&gt; &lt;input class="required" name="username" type="text" /&gt; &lt;input class="required passfield" name="password" type="password" /&gt; &lt;input name="continue" type="submit" value="Login" /&gt; &lt;input name="continue" type="button" value="Clear" /&gt; &lt;/form&gt;&lt;/body&gt;&lt;html&gt; css=form#loginForm (3) css=input[name=”username”] (4) css=input.required[type=”text”] (4) css=input.passfield (5) css=#loginForm input[type=”button”] (7) css=#loginForm input:nth-child(2) (5) 可以参考 the W3C publication 没有明确的设定选择器的话，将会默认使用id选择器 存储命令和Selenium变量可以使用Selenium变量在脚本开头存储常量。此外，当与数据驱动的测试设计（在后面的部分中讨论）结合使用时，Selenium变量可用于存储从命令行，从另一个程序或从文件传递到测试程序的值。 plain store命令是许多存储命令中最基本的命令，可用于在selenium变量中简单地存储常量值。它需要两个参数，即要存储的文本值和一个selenium变量。在为变量选择名称时，请使用仅包含字母数字字符的标准变量命名约定。 Command Target Value store paul@mysite.org userName 稍后在脚本中，将需要使用变量的存储值。要访问变量的值，请将变量括在大括号（{}）中，并在其前面加上美元符号。 Command Target Value verifyText //div/p ${userName} 变量的常见用途是存储输入字段的输入 Command Target Value type id=login ${userName} storeText StoreText对应于verifyText。它使用定位器来标识特定的页面文本。如果找到该文本，则存储在变量中。 StoreText可用于从正在测试的页面中提取文本。 echo命令可以用来打印变量 Alerts, Popups, and Multiple Windows123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;script type="text/javascript"&gt; function output(resultText)&#123; document.getElementById('output').childNodes[0].nodeValue=resultText; &#125; function show_confirm()&#123; var confirmation=confirm("Chose an option."); if (confirmation==true)&#123; output("Confirmed."); &#125; else&#123; output("Rejected!"); &#125; &#125; function show_alert()&#123; alert("I'm blocking!"); output("Alert is gone."); &#125; function show_prompt()&#123; var response = prompt("What's the best web QA tool?","Selenium"); output(response); &#125; function open_window(windowName)&#123; window.open("newWindow.html",windowName); &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;input type="button" id="btnConfirm" onclick="show_confirm()" value="Show confirm box" /&gt; &lt;input type="button" id="btnAlert" onclick="show_alert()" value="Show alert" /&gt; &lt;input type="button" id="btnPrompt" onclick="show_prompt()" value="Show prompt" /&gt; &lt;a href="newWindow.html" id="lnkNewWindow" target="_blank"&gt;New Window Link&lt;/a&gt; &lt;input type="button" id="btnNewNamelessWindow" onclick="open_window()" value="Open Nameless Window" /&gt; &lt;input type="button" id="btnNewNamedWindow" onclick="open_window('Mike')" value="Open Named Window" /&gt; &lt;br /&gt; &lt;span id="output"&gt; &lt;/span&gt;&lt;/body&gt;&lt;/html&gt; Command Description assertFoo(pattern) 如果模式与弹出窗口的文本不匹配，则抛出错误 assertFooPresent 如果弹出窗口不可用则抛出错误 assertFooNotPresent 如果存在任何弹出窗口则抛出错误 storeFoo(variable) 将弹出文本存储在变量中 storeFooPresent(variable) 将弹出窗口的文本存储在变量中并返回true或false 在Selenium下运行时，不会显示JavaScript弹出窗口。这是因为函数调用实际上是由Selenium自己的JavaScript在运行时覆盖的。但是，仅仅因为你看不到弹出窗口并不意味着你不必处理它。要处理弹出窗口，必须调用其assertFoo（模式）函数。如果您未能断言是否存在弹出窗口，则您的下一个命令将被阻止，您将收到类似于以下错误的错误[错误]错误error] Error: There was an unexpected Confirmation! [Chose an option.] Alerts让我们从Alerts开始，因为它们是最简单的弹出窗口。首先，在浏览器中打开上面的HTML示例，然后单击“Show alert”按钮。您会注意到，在您关闭警报后，页面上会显示“警报已消失。”文本。现在使用Selenium IDE录制完成相同的步骤，并在关闭警报后验证是否添加了文本。您的测试看起来像这样： Command Target value open / click btnAlert assertAlert I’m blocking! verifyTextPresent Alert is gone. 您可能会想“这很奇怪，我从未试图断言该警报。”但这是Selenium-IDE处理并为您关闭警报。如果您删除该步骤并重播测试，您将获得以下内容 [error] Error: There was an unexpected Alert! [I&#39;m blocking!]. 如果您只想声明警报存在但是不知道或不关心它包含哪个文本，则可以使用assertAlertPresent。这将返回true或false，错误地停止测试。 Confirmations确认的行为与警报的行为大致相同，其中assertConfirmation和assertConfirmationPresent提供与其警报对应物相同的特征。但是，默认情况下，Selenium会在弹出确认时选择“确定”。尝试单击示例页面中的“显示确认框”按钮，但单击弹出窗口中的“取消”按钮，然后断言输出文本。您的测试可能如下所示： Command Target value open / click btnAlert chooseCancelOnNextConfirmation assertConfirmation Choose an option. verifyTextPresent Rejected chooseCancelOnNextConfirmation函数告诉Selenium所有后续确认都应该返回false。可以通过调用chooseOkOnNextConfirmation来重置它。 可能会注意到您无法重播此测试，因为Selenium抱怨存在未经处理的确认。这是因为Selenium-IDE记录的事件顺序导致click和chooseCancelOnNextConfirmation被置于错误的顺序（如果考虑它就有意义，Selenium在打开确认之前无法知道正在取消）切换这两个命令，你的测试运行正常。 Prompts提示的行为与警报的行为大致相同，其中assertPrompt和assertPromptPresent提供与其警报对应项相同的特征。默认情况下，Selenium会在弹出提示时等待您输入数据。尝试单击示例页面中的“显示提示”按钮，然后在提示中输入“Selenium”。测试可能如下所示： Command Target value open / answerOnNextPrompt Selenium! click id=btnPrompt assertPrompt What’s the best web QA tool? verifyTextPresent Selenium! 如果在提示中选择取消，您可能会注意到answerOnNextPrompt只显示空白目标。 Selenium对取消和提示上的空白条目基本上是一样的。 调试断点要设置断点，请选择一个命令，单击鼠标右键，然后从上下文菜单中选择“切换断点”。然后单击“运行”按钮以从开始到断点运行测试用例。从测试用例的中间位置到结束位置运行测试用例或者到达起始点之后的断点有时也很有用。例如，假设您的测试用例首先登录到网站，然后执行一系列测试，并且您正在尝试调试其中一个测试。但是，您只需要登录一次，但是在开发测试时需要不断重新运行测试。您可以登录一次，然后从测试用例的登录部分之后的起点运行测试用例。这将阻止您每次重新运行测试用例时都必须手动注销。 按步骤执行测试要一次执行一个测试用例（“step through”），只需重复按此按钮。 Find Button“查找”按钮用于查看当前显示的网页（在浏览器中）中当前选定的Selenium命令中使用的UI元素。在为命令的第一个参数构建定位器时，这非常有用（请参阅定位元素一节）。它可以与标识网页上UI元素的任何命令一起使用，例如，单击，单击和等待，键入，以及某些断言和验证命令等。 从表视图中，选择具有locator参数的任何命令。单击“查找”按钮。现在查看网页：应该有一个明亮的绿色矩形，包围locator参数指定的元素。 Java中应用Selenium项目地址 我在本地录制了一个简单的脚本，选择导出到java+junit，类似下面：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class SearchGoogle &#123; private WebDriver driver; private boolean acceptNextAlert = true; private StringBuffer verificationErrors = new StringBuffer(); private SeleniumConfigure seleniumConfigure = SeleniumConfigureParse.getSeleniumConfigure(); @Before public void setUp() &#123; driver = DriverUtil.getDriver(); driver .manage().window().maximize();//全屏 driver.manage().timeouts().implicitlyWait(30, TimeUnit.SECONDS); &#125; @Test public void testSearchGoogle() &#123; driver.get(seleniumConfigure.getBaseUrl()); driver.findElement(By.name("q")).click(); driver.findElement(By.name("q")).clear(); driver.findElement(By.name("q")).sendKeys("google"); driver.findElement(By.name("q")).sendKeys(Keys.ENTER); &#125; @After public void tearDown() &#123; driver.quit(); String verificationErrorString = verificationErrors.toString(); if (!"".equals(verificationErrorString)) &#123; fail(verificationErrorString); &#125; &#125; private boolean isElementPresent(By by) &#123; try &#123; driver.findElement(by); return true; &#125; catch (NoSuchElementException e) &#123; return false; &#125; &#125; private boolean isAlertPresent() &#123; try &#123; driver.switchTo().alert(); return true; &#125; catch (NoAlertPresentException e) &#123; return false; &#125; &#125; private String closeAlertAndGetItsText() &#123; try &#123; Alert alert = driver.switchTo().alert(); String alertText = alert.getText(); if (acceptNextAlert) &#123; alert.accept(); &#125; else &#123; alert.dismiss(); &#125; return alertText; &#125; finally &#123; acceptNextAlert = true; &#125; &#125;&#125; 新建项目，pom.xml如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283 &lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;choerodon&lt;/groupId&gt; &lt;artifactId&gt;selenium&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt; &lt;artifactId&gt;selenium-server&lt;/artifactId&gt; &lt;version&gt;3.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.yaml/snakeyaml --&gt; &lt;dependency&gt; &lt;groupId&gt;org.yaml&lt;/groupId&gt; &lt;artifactId&gt;snakeyaml&lt;/artifactId&gt; &lt;version&gt;1.23&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;!--&lt;dependency&gt;--&gt; &lt;!--&lt;groupId&gt;org.projectlombok&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;lombok&lt;/artifactId&gt;--&gt; &lt;!--&lt;version&gt;1.18.4&lt;/version&gt;--&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;!--&lt;/dependency&gt;--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0-M3&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.surefire&lt;/groupId&gt; &lt;artifactId&gt;surefire-junit47&lt;/artifactId&gt; &lt;version&gt;3.0.0-M3&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;basedir&#125;/output&lt;/outputDirectory&gt; &lt;outputName&gt;测试报告&lt;/outputName&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--&lt;plugin&gt;--&gt; &lt;!--&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt;--&gt; &lt;!--&lt;version&gt;2.1&lt;/version&gt;--&gt; &lt;!--&lt;configuration&gt;--&gt; &lt;!--&lt;outputDirectory&gt;$&#123;basedir&#125;/output&lt;/outputDirectory&gt;--&gt; &lt;!--&lt;outputName&gt;测试报告&lt;/outputName&gt;--&gt; &lt;!--&lt;/configuration&gt;--&gt; &lt;!--&lt;/plugin&gt;--&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 与Docker结合 使用远程的驱动服务来测试，目前只支持Chrome和FireFox，本地如果要起服务，请在docker中执行下面的命令启动服务 123docker pull elgalu/seleniumdocker run -d --name=grid -p 4444:24444 -p 5900:25900 -e TZ="Asia/Shanghai" -e MAX_INSTANCES=20 -e MAX_SESSIONS=20 -v /Users/dinghuang/Documents/Tool/selenium/shm:/dev/shm --privileged elgalu/seleniumdocker exec grid wait_all_done 30s 可以在http://localhost:4444/grid/console中查看详情 关闭服务命令： 12docker exec grid stopdocker stop grid 在JAVA代码中，可以通过远程的docker容器启动浏览器进行测试 1webDriver = new RemoteWebDriver(new URL("http://localhost:4444/wd/hub"), browser);]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在GitHub Page使用HEXO搭建博客]]></title>
    <url>%2F2018%2F09%2F21%2F%E5%A6%82%E4%BD%95%E5%9C%A8GitHub%20Page%E4%BD%BF%E7%94%A8HEXO%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[如何在使用GitHub Page搭建HEXO博客项目地址 准备工作 安装Git 安装Node.js 注册Github账号 创建新的仓库 名称必须为 用户名.github.io 添加本地电脑的SSH认证，如图所示在本地命令工具中输入ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot;一路回车之后会得到两个文件：id_rsa和id_rsa.pub，然后用带格式的编辑器（比方说notepad++或者sublime）打开id_rsa.pub，复制里面的所有内容，然粘贴到KEY里面。 安装HEXO 打开命令行工具npm install -g hexo-cli 安装 Hexo 完成后，分步执行（即输入代码之后敲回车）下列命令，Hexo 将会在指定文件夹中新建所需要的文件。hexo init &lt;folder&gt;在文件夹内执行npm install 成功后，博客项目成功初始化 配置NEXT主题 安装NEXT主题 mkdir themes/nextcurl -s https://api.github.com/repos/iissnan/hexo-theme-next/releases/latest | grep tarball_url | cut -d &#39;&quot;&#39; -f 4 | wget -i - -O- | tar -zx -C themes/next --strip-components=1修改站点配置文件_config.yml12345678910111213141516title: 一只病猫subtitle: 静坐常思己过，闲谈莫论人非description: 学习、生活、闲谈、足球author: 强壮的病猫language: zh-Hanstimezone: Asia/Shanghaitheme: nexturl: https://dinghuang.github.io/deploy: type: git repo: https://github.com/dinghuang/dinghuang.github.io.git branch: master#开启swiftype搜索，后面的id在swiftype官网申请，[具体操作][3]swiftype_key: HcRPHRrBuwozvgUoLNyX#要放到仓库的静态资源都放在source文件夹中，.md会被转换成HTML，所以这里要忽略skip_render: README.md 配置NEXT主题设置主题配置文件./themes/next/_config.yml，可以参考本项目的配置。NEXT强大之处在于继承了很多第三方服务插件，不过类似评论搜索功能的插件被墙了，外网是可以用的。具体参考 设置标签分类参考链接，在文章开头，引入：12345title: 设计模式date: 2018-07-18 09:43:00tags: - JAVAcategories: JAVA 更多配置请参考官方文档 提交 输入命令npm install hexo-deployer-git --save 创建文章hexo new &quot;你想要的文章标题填在这个双引号里&quot; 文章会生成在./source/_posts/设计模式.md进行修改后hexo clean ; hexo genarate 然后输入hexo deploy此时文章已经成功部署。]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VPS搭建SS]]></title>
    <url>%2F2018%2F09%2F08%2FVPS%E6%90%AD%E5%BB%BASS%2F</url>
    <content type="text"><![CDATA[购买VPS服务器声明：本教程仅供学习用 购买地址 推荐vultr的原因是，vultr支持支付宝、服务器较多，价格虽然不算便宜，但是网速稳定。各个机房速度测试，直接ping 域名地理位置 官方测试服务器ip 下载测试文件123456789101112131415Frankfurt, DE fra-de-ping.vultr.com 100M 1000MAmsterdam, NL ams-nl-ping.vultr.com 100M 1000MParis, France par-fr-ping.vultr.com 100M 1000MLondon, UK lon-gb-ping.vultr.com 100M 1000MSingapore sgp-ping.vultr.com 100M 1000MNew York (NJ) nj-us-ping.vultr.com 100M 1000MTokyo, Japan hnd-jp-ping.vultr.com 100M 1000MChicago, Illinois il-us-ping.vultr.com 100M 1000MAtlanta, Georgia ga-us-ping.vultr.com 100M 1000MMiami, Florida fl-us-ping.vultr.com 100M 1000MSeattle, Washington wa-us-ping.vultr.com 100M 1000MDallas, Texas tx-us-ping.vultr.com 100M 1000MSilicon Valley, California sjo-ca-us-ping.vultr.com 100M 1000MLos Angeles, California lax-ca-us-ping.vultr.com 100M 1000MSydney, Australia syd-au-ping.vultr.com 100M 1000M 经过测试，大陆地区，Tokyo的速度是最快的，延迟在50ms左右。 搭建ShadowSocksR服务ssh连接购买的服务器ssh -p22 root@xx.xx.xx.xx搭建ssr服务wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.shchmod +x shadowsocksR.sh./shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log根据提示输入相关配置相关指令：卸载: ./shadowsocksR.sh uninstall启动：/etc/init.d/shadowsocks start停止：/etc/init.d/shadowsocks stop重启：/etc/init.d/shadowsocks restart状态：/etc/init.d/shadowsocks status配置文件路径：/etc/shadowsocks.json日志文件路径：/var/log/shadowsocks.log代码安装目录：/usr/local/shadowsocks如果要配置多个用户，多个端口，打开配置文件路径，修改如下：1234567891011121314151617&#123; "server":"0.0.0.0", "server_ipv6":"[::]", "server_port":9001, "local_address":"127.0.0.1", "local_port":1080, "port_password":&#123; "9001":"123456", "9002":"123456", "9003":"123456" &#125;, "timeout":300, "method":"aes-256-cfb", "protocol":"origin", "obfs":"plain", "fast_open":false&#125; 设置相关端口后要在防火墙打开相关端口的通讯，Centos默认使用firewall命令，如下所示：sudo firewall-cmd --zone=public --add-port=3000/tcp --permanentsudo firewall-cmd --reloadfirewall-cmd --list-all 优化网络1.系统层面vi /etc/sysctl.conf 123456789101112131415161718192021222324252627282930313233343536373839404142# max open filesfs.file-max = 1024000# max read buffernet.core.rmem_max = 67108864# max write buffernet.core.wmem_max = 67108864# default read buffernet.core.rmem_default = 65536# default write buffernet.core.wmem_default = 65536# max processor input queuenet.core.netdev_max_backlog = 4096# max backlognet.core.somaxconn = 4096# resist SYN flood attacksnet.ipv4.tcp_syncookies = 1# reuse timewait sockets when safenet.ipv4.tcp_tw_reuse = 1# turn off fast timewait sockets recyclingnet.ipv4.tcp_tw_recycle = 0# short FIN timeoutnet.ipv4.tcp_fin_timeout = 30# short keepalive timenet.ipv4.tcp_keepalive_time = 1200# outbound port rangenet.ipv4.ip_local_port_range = 10000 65000# max SYN backlognet.ipv4.tcp_max_syn_backlog = 4096# max timewait sockets held by system simultaneouslynet.ipv4.tcp_max_tw_buckets = 5000# TCP receive buffernet.ipv4.tcp_rmem = 4096 87380 67108864# TCP write buffernet.ipv4.tcp_wmem = 4096 65536 67108864# turn on path MTU discoverynet.ipv4.tcp_mtu_probing = 1# for high-latency networknet.ipv4.tcp_congestion_control = htcp# forward ipv4net.ipv4.ip_forward = 1 保存生效sysctl -p其中最后的hybla是为高延迟网络（如美国，欧洲）准备的算法，需要内核支持，测试内核是否支持，在终端输入：sysctl net.ipv4.tcp_available_congestion_control如果结果中有hybla，则证明你的内核已开启hybla，如果没有hybla，可以用命令modprobe tcp_hybla开启。 对于低延迟的网络（如日本，香港等），可以使用htcp，可以非常显著的提高速度，首先使用modprobe tcp_htcp开启，再将net.ipv4.tcp_congestion_control = hybla改为net.ipv4.tcp_congestion_control = htcp，建议EC2日本用户使用这个算法。 2.TCP优化1.修改文件句柄数限制如果是ubuntu/centos均可修改/etc/sysctl.conf找到fs.file-max这一行，修改其值为1024000，并保存退出。然后执行sysctl -p使其生效修改vi /etc/security/limits.conf文件，加入 12* soft nofile 512000* hard nofile 1024000 针对centos,还需要修改vi /etc/pam.d/common-session文件，加入session required pam_limits.so 2.修改vi /etc/profile文件，加入ulimit -SHn 1024000然后重启服务器执行ulimit -n，查询返回1024000即可。 sysctl.conf报错解决方法修复modprobe的：12rm -f /sbin/modprobe ln -s /bin/true /sbin/modprobe 修复sysctl的：12rm -f /sbin/sysctl ln -s /bin/true /sbin/sysctl 3.软件辅助优化软件辅助优化都得参考系统内核，查看是否适用，如果不适用，可以修改系统内核。 2.1 锐速 锐速是TCP底层加速软件,官方已停止推出永久免费版本,但网上有破解版可以继续使用。需要购买的话先到锐速官网注册帐号,并确认内核版本是否支持锐速的版本。 一键安装速锐破解版 wget -N --no-check-certificate https://github.com/91yun/serverspeeder/raw/master/serverspeeder.sh &amp;&amp; bash serverspeeder.sh一键卸载 chattr -i /serverspeeder/etc/apx* &amp;&amp; /serverspeeder/bin/serverSpeeder.sh uninstall -f设置 12345Enter your accelerated interface(s) [eth0]: eth0Enter your outbound bandwidth [1000000 kbps]: 1000000Enter your inbound bandwidth [1000000 kbps]: 1000000Configure shortRtt-bypass [0 ms]: 0Auto load ServerSpeeder on linux start-up? [n]:y 是否开机自启Run ServerSpeeder now? [y]:y #是否现在启动执行lsmod，看到有appex0模块即说明锐速已正常安装并启动。 至此，安装就结束了，但还有后续配置。修改vi /serverspeeder/etc/config文件的几个参数以使锐速更好的工作 123456accppp="1" #加速PPTP、L2TP V-P-N；设为1表示开启，设为0表示关闭advinacc="1" #高级入向加速开关；设为 1 表示开启，设为 0 表示关闭；开启此功能可以得到更好的流入方向流量加速效果；maxmode="1" #最大传输模式；设为 1 表示开启；设为 0 表示关闭；开启后会进一步提高加速效果，但是可能会降低有效数据率。rsc="1" #网卡接收端合并开关；设为 1 表示开启，设为 0 表示关闭；在有些较新的网卡驱动中，带有 RSC 算法的，需要打开该功能。l2wQLimit="512 4096" #从 LAN 到 WAN 加速引擎在缓冲池充满和空闲时分别能够缓存的数据包队列的长度的上限；该值设置的高会获得更好的加速效果，但是会消耗更多的内存w2lQLimit="512 4096" #从 WAN 到 LAN 加速引擎在缓冲池充满和空闲时分别能够缓存的数据包队列的长度的上限；该值设置的高会获得更好的加速效果，但是会消耗更多的内存 重读配置以使配置生效/serverspeeder/bin/serverSpeeder.sh reload 查看锐速当前状态/serverspeeder/bin/serverSpeeder.sh stats 查看所有命令/serverspeeder/bin/serverSpeeder.sh help 停止/serverspeeder/bin/serverSpeeder.sh stop 启动/serverspeeder/bin/serverSpeeder.sh start 重启锐速/serverspeeder/bin/serverSpeeder.sh restart 2.1 安装Google BBR 要求内核版本4.13.5-1.el7.elrepo.x86_64 以上12rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpmyum --enablerepo=elrepo-kernel install kernel-ml -y 检查内核是否更新rpm -qa | grep kernel启动grub2-set-default 1重启shutdown -r now查看是否生效uname -r安装Google BBR123echo 'net.core.default_qdisc=fq' | sudo tee -a /etc/sysctl.confecho 'net.ipv4.tcp_congestion_control=bbr' | sudo tee -a /etc/sysctl.confsysctl -p 检查是否安装成功sysctl net.ipv4.tcp_available_congestion_control执行命令后，看是否是提示“net.ipv4.tcp_available_congestion_control = bbr cubic reno”执行命令，是否提示bbrlsmod | grep bbr]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2018%2F07%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[菜鸟教程文档 设计模式设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。 代码案例 1.创建型模式这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 1.1. 工厂模式主要解决：主要解决接口选择的问题。 何时使用：我们明确地计划不同条件下创建不同实例时。 优点： 一个调用者想创建一个对象，只要知道其名称就可以了 扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以 屏蔽产品的具体实现，调用者只关心产品的接口 缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 如何解决：让其子类实现工厂接口，返回的也是一个抽象的产品。 使用场景： 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 2、数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，”POP3”、”IMAP”、”HTTP”，可以把这三个作为产品类，共同实现一个接口。 注意事项：作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。 1234567891011121314151617181920212223242526272829303132public interface Car &#123; void run();&#125;public class ExpensiveCar implements Car &#123; @Override public void run() &#123; System.out.println("expensiveCar.run"); &#125;&#125;public class LitterCar implements Car &#123; @Override public void run() &#123; System.out.println("littleCard.run"); &#125;&#125;public class CarFactory &#123; public Car getCar(String type) &#123; if (type == null) &#123; return null; &#125; if (type.equals("litterCar")) &#123; return new LitterCar(); &#125; else if (type.equals("ExpensiveCar")) &#123; return new ExpensiveCar(); &#125; return null; &#125;&#125; 1.2. 抽象工厂模式主要解决：主要解决接口选择的问题。 何时使用：系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。 优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 缺点：产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。 使用场景： 1、QQ 换皮肤，一整套一起换。 2、生成不同操作系统的程序。 注意事项：产品族难扩展，产品等级易扩展。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public interface Car &#123; void run();&#125;public class ExpensiveCar implements Car &#123; @Override public void run() &#123; System.out.println("expensiveCar.run"); &#125;&#125;public class LitterCar implements Car &#123; @Override public void run() &#123; System.out.println("littleCard.run"); &#125;&#125;public interface Passengers &#123; void getCar();&#125;public class Man implements Passengers &#123; @Override public void getCar() &#123; System.out.println("man.getCar"); &#125;&#125;public class Woman implements Passengers &#123; @Override public void getCar() &#123; System.out.println("man.getCar"); &#125;&#125;public abstract class AbstractFactory &#123; public abstract Passengers getPassengers(String user); public abstract Car getCar(String car);&#125;public class CarFactory extends AbstractFactory&#123; @Override public Passengers getPassengers(String user) &#123; return null; &#125; @Override public Car getCar(String type) &#123; if (type == null) &#123; return null; &#125; if (type.equals("litterCar")) &#123; return new LitterCar(); &#125; else if (type.equals("ExpensiveCar")) &#123; return new ExpensiveCar(); &#125; return null; &#125;&#125;public class PassengerFactory extends AbstractFactory &#123; @Override public Passengers getPassengers(String user) &#123; if (user == null) &#123; return null; &#125; if (user.equals("man")) &#123; return new Man(); &#125; else if (user.equals("woman")) &#123; return new Woman(); &#125; return null; &#125; @Override public Car getCar(String car) &#123; return null; &#125;&#125;public class FactoryProducer &#123; public static AbstractFactory getFactory(String choice) &#123; if (choice.equalsIgnoreCase("Car")) &#123; return new CarFactory(); &#125; else if (choice.equalsIgnoreCase("Passenger")) &#123; return new PassengerFactory(); &#125; return null; &#125;&#125; 1.3. 单例模式主要解决：一个全局使用的类频繁地创建与销毁。 何时使用：当您想控制实例数目，节省系统资源的时候。 优点： 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存） 避免对资源的多重占用（比如写文件操作） 缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 使用场景： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 注意事项：getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205/** * 饿汉式 * 是否 Lazy 初始化：否 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：易 * &lt;p&gt; * 描述：这种方式比较常用，但容易产生垃圾对象。 * 优点：没有加锁，执行效率会提高。 * 缺点：类加载时就初始化，浪费内存。 * 它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多 * 种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载， * 这时候初始化 instance 显然没有达到 lazy loading 的效果。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user = new User(); //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static User getUser() &#123; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 懒汉式，线程不安全 * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：否 * &lt;p&gt; * 实现难度：易 * &lt;p&gt; * 描述：这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。 * 这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user; //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static User getUser() &#123; if (user == null) &#123; System.out.println("no user"); user = new User(); &#125; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 懒汉式，线程安全 * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：易 * &lt;p&gt; * 描述：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。 * 优点：第一次调用才初始化，避免内存浪费。 * 缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。 * getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user; //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static synchronized User getUser() &#123; if (user == null) &#123; System.out.println("no User"); user = new User(); &#125; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 双检锁/双重校验锁（DCL，即 double-checked locking） * JDK 版本：JDK1.5 起 * &lt;p&gt; * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：较复杂 * &lt;p&gt; * 描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。 * getInstance() 的性能对应用程序很关键。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user; //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static User getUser() &#123; if (user == null) &#123; synchronized (User.class) &#123; if (user == null) &#123; System.out.println("no User"); user = new User(); &#125; &#125; &#125; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 登记式/静态内部类 * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：一般 * &lt;p&gt; * 描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式 * 。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。 * 这种方式同样利用了 classloader 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是： * 第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果） * ，而这种方式是 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用， * 只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance。想象一下， * 如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载 * 时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实 * 例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static class UserHolder &#123; private static final User user = new User(); &#125; private User() &#123; &#125; public static final User getUser() &#123; return UserHolder.user; &#125;&#125;public class SingletonTest &#123; public static void main(String[] args) &#123; //不合法的构造函数 //编译时错误：构造函数 User() 是私有的// User user = new User(); Runnable runnable = () -&gt; &#123; //枚举单例// User.USER.sendMessage(); User user = User.getUser(); user.showMessage(); &#125;; IntStream.range(0, 100) .forEach(i -&gt; &#123; Thread thread = new Thread(runnable); thread.start(); &#125;); &#125;&#125; 一般情况下，不建议使用懒汉方式，建议使用饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用登记方式。如果涉及到反序列化创建对象时，可以尝试使用枚举方式。如果有其他特殊的需求，可以考虑使用双检锁方式。 1.4. 建造者模式建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 一个 Builder 类会一步一步构造最终的对象。该 Builder 类是独立于其他对象的。 主要解决：主要解决在软件系统中，有时候面临着”一个复杂对象”的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定。 何时使用：一些基本部件不会变，而其组合经常变化的时候。 如何解决：将变与不变分离开。 应用实例： 去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的”套餐” JAVA 中的 StringBuilder 优点： 建造者独立，易扩展 便于控制细节风险 缺点： 产品必须有共同点，范围有限制 如内部变化复杂，会有很多的建造类 使用场景： 需要生成的对象具有复杂的内部结构 需要生成的对象内部属性本身相互依赖 注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126public interface Product &#123; public String name(); public float price(); public Production production();&#125;public interface Production &#123; public String production();&#125;public class Hand implements Production&#123; @Override public String production() &#123; return "hand"; &#125;&#125;public class Machine implements Production &#123; @Override public String production() &#123; return "Machine"; &#125;&#125;public abstract class Windows implements Product&#123; @Override public Production production()&#123; return new Hand(); &#125; @Override public abstract float price();&#125;public abstract class Mac implements Product&#123; @Override public Production production()&#123; return new Machine(); &#125; @Override public abstract float price();&#125;public class WindowsSystem extends Windows&#123; @Override public String name() &#123; return "windowsSystem"; &#125; @Override public float price() &#123; return 25.0f; &#125;&#125;public class MacSystem extends Mac &#123; @Override public String name() &#123; return "macSystem"; &#125; @Override public float price() &#123; return 30.0f; &#125;&#125;public class SystemProduct &#123; private List&lt;Product&gt; products = new ArrayList&lt;&gt;(); public void addProduct(Product product) &#123; products.add(product); &#125; public float getCost() &#123; float cost = 0.0f; for (Product product : products) &#123; cost += product.price(); &#125; return cost; &#125; public void showProducts() &#123; for (Product product : products) &#123; System.out.print("Product : " + product.name()); System.out.print(",Production : " + product.production().production()); System.out.println(", Price : " + product.price()); &#125; &#125;&#125;public class SystemProductBuilder &#123; public SystemProduct prepareMacSystem() &#123; SystemProduct systemProduct = new SystemProduct(); systemProduct.addProduct(new MacSystem()); return systemProduct; &#125; public SystemProduct prepareWindowsSystem() &#123; SystemProduct systemProduct = new SystemProduct(); systemProduct.addProduct(new WindowsSystem()); return systemProduct; &#125;&#125;public class BuilderTest &#123; public static void main(String[] args) &#123; SystemProductBuilder systemProductBuilder = new SystemProductBuilder(); SystemProduct windows = systemProductBuilder.prepareMacSystem(); System.out.println("windows product"); windows.showProducts(); System.out.println("Total Cost: " + windows.getCost()); SystemProduct allSystem = systemProductBuilder.prepareAllSystem(); System.out.println("allSystem"); allSystem.showProducts(); System.out.println("Total Cost: " + allSystem.getCost()); &#125;&#125; 1.5. 原型模式原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 主要解决：在运行期建立和删除原型。 何时使用： 当一个系统应该独立于它的产品创建，构成和表示时 当要实例化的类是在运行时刻指定时，例如，通过动态装载 为了避免创建一个与产品类层次平行的工厂类层次时 当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些 如何解决：利用已有的一个原型对象，快速地生成和原型对象一样的实例。 应用实例： 细胞分裂 JAVA 中的 Object clone() 方法 优点： 性能提高 逃避构造函数的约束 缺点： 配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候 必须实现 Cloneable 接口 使用场景： 资源优化场景 类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等 性能和安全要求的场景 通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式 一个对象多个修改者的场景 一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用 在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过 clone的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用 注意事项：与通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的。浅拷贝实现 Cloneable，重写，深拷贝是通过实现 Serializable 读取二进制流。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * 创建一个抽象类 Prototype 和扩展了 Prototype 类的实体类。下一步是定义类 PrototypeCache，该类把 Prototype * 对象存储在一个 Hashtable 中，并在请求的时候返回它们的克隆。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public abstract class Prototype implements Cloneable&#123; private String id; private String type; abstract void operation(); public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; @Override public Object clone()&#123; Object clone = null; try&#123; clone = super.clone(); &#125;catch (CloneNotSupportedException e)&#123; e.printStackTrace(); &#125; return clone; &#125;&#125;public class PrototypeOne extends Prototype &#123; public PrototypeOne()&#123; type = "prototypeOne"; &#125; @Override void operation() &#123; System.out.println("Inside PrototypeOne::draw() method."); &#125;&#125;public class PrototypeTwo extends Prototype &#123; public PrototypeTwo() &#123; type = "prototypeTwo"; &#125; @Override void operation() &#123; System.out.println("Inside PrototypeTwo::draw() method."); &#125;&#125;public class PrototypeCache &#123; private static Hashtable&lt;String,Prototype&gt; propertyMap = new Hashtable&lt;&gt;(); public static Prototype getProperType(String id)&#123; Prototype cachePrototype = propertyMap.get(id); return (Prototype) cachePrototype.clone(); &#125; public static void loadCache() &#123; PrototypeOne prototypeOne = new PrototypeOne(); prototypeOne.setId("1"); propertyMap.put(prototypeOne.getId(),prototypeOne); PrototypeTwo prototypeTwo = new PrototypeTwo(); prototypeTwo.setId("2"); propertyMap.put(prototypeTwo.getId(),prototypeTwo); &#125;&#125;public class PrototypeTest &#123; public static void main(String[] args) &#123; PrototypeCache.loadCache(); PrototypeOne prototypeOne = (PrototypeOne) PrototypeCache.getProperType("1"); System.out.println("Prototype : " + prototypeOne.getType()); PrototypeTwo prototypeTwo = (PrototypeTwo) PrototypeCache.getProperType("2"); System.out.println("Prototype : " + prototypeTwo.getType()); &#125;&#125; 2.结构型模式这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 2.1. 适配器模式适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。 我们通过下面的实例来演示适配器模式的使用。其中，音频播放器设备只能播放 mp3 文件，通过使用一个更高级的音频播放器来播放 vlc 和 mp4 文件。 主要解决：主要解决在软件系统中，常常要将一些”现存的对象”放到新的环境中，而新环境要求的接口是现对象不能满足的。 何时使用： 系统需要使用现有的类，而此类的接口不符合系统的需要 想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口 通过接口转换，将一个类插入另一个类系中（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口） 如何解决：继承或依赖（推荐）。 应用实例： 美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V JAVA JDK 1.1 提供了 Enumeration 接口，而在 1.2 中提供了 Iterator 接口，想要使用 1.2 的JDK，则要将以前系统的 Enumeration 接口转化为 Iterator 接口，这时就需要适配器模式 在 LINUX 上运行 WINDOWS 程序 JAVA 中的 jdbc 优点： 可以让任何两个没有关联的类一起运行 提高了类的复用 增加了类的透明度 灵活性好 缺点： 过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是A接口，其实内部被适配成了B接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构 由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类 使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public interface MediaPlayer &#123; public void play(String audioType, String fileName);&#125;public interface AdvancedMediaPlayer &#123; public void playVlc(String fileName); public void playMp4(String fileName);&#125;public class VlcPlayer implements AdvancedMediaPlayer &#123; @Override public void playVlc(String fileName) &#123; System.out.println("Playing vlc file. Name: " + fileName); &#125; @Override public void playMp4(String fileName) &#123; //do nothing &#125;&#125;public class Mp4Player implements AdvancedMediaPlayer &#123; @Override public void playVlc(String fileName) &#123; //do Nothing &#125; @Override public void playMp4(String fileName) &#123; System.out.println("Playing mp4 file. Name: " + fileName); &#125;&#125;public class MediaAdapter implements MediaPlayer &#123; AdvancedMediaPlayer advancedMusicPlayer; public MediaAdapter(String audioType) &#123; if (audioType.equalsIgnoreCase("vlc")) &#123; advancedMusicPlayer = new VlcPlayer(); &#125; else if (audioType.equalsIgnoreCase("mp4")) &#123; advancedMusicPlayer = new Mp4Player(); &#125; &#125; @Override public void play(String audioType, String fileName) &#123; if (audioType.equalsIgnoreCase("vlc")) &#123; advancedMusicPlayer.playVlc(fileName); &#125; else if (audioType.equalsIgnoreCase("mp4")) &#123; advancedMusicPlayer.playMp4(fileName); &#125; &#125;&#125;public class AudioPlayer implements MediaPlayer &#123; MediaAdapter mediaAdapter; @Override public void play(String audioType, String fileName) &#123; //播放 mp3 音乐文件的内置支持 if(audioType.equalsIgnoreCase("mp3"))&#123; System.out.println("Playing mp3 file. Name: "+ fileName); &#125; //mediaAdapter 提供了播放其他文件格式的支持 else if(audioType.equalsIgnoreCase("vlc") || audioType.equalsIgnoreCase("mp4"))&#123; mediaAdapter = new MediaAdapter(audioType); mediaAdapter.play(audioType, fileName); &#125; else&#123; System.out.println("Invalid media. "+ audioType + " format not supported"); &#125; &#125;&#125;public class AdapterTest &#123; public static void main(String[] args) &#123; AudioPlayer audioPlayer = new AudioPlayer(); audioPlayer.play("mp3", "beyond the horizon.mp3"); audioPlayer.play("mp4", "alone.mp4"); audioPlayer.play("vlc", "far far away.vlc"); audioPlayer.play("avi", "mind me.avi"); &#125;&#125; 2.2. 桥接模式桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。 这种模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类。这两种类型的类可被结构化改变而互不影响。 主要解决：在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活。 何时使用：实现系统可能有多个角度分类，每一种角度都可能变化。 如何解决：把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合。 应用实例： 猪八戒从天蓬元帅转世投胎到猪，转世投胎的机制将尘世划分为两个等级，即：灵魂和肉体，前者相当于抽象化，后者相当于实现化。生灵通过功能的委派，调用肉体对象的功能，使得生灵可以动态地选择 墙上的开关，可以看到的开关是抽象的，不用管里面具体怎么实现的 优点： 抽象和实现的分离 优秀的扩展能力 实现细节对客户透明 缺点：桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。 使用场景： 如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用 一个类存在两个独立变化的维度，且这两个维度都需要进行扩展 注意事项：对于两个独立变化的维度，使用桥接模式再适合不过了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public interface DrawAPI &#123; public void drawCircle(int radius, int x, int y);&#125;public class RedCircle implements DrawAPI &#123; @Override public void drawCircle(int radius, int x, int y) &#123; System.out.println("Drawing Circle[ color: red, radius: " + radius +", x: " +x+", "+ y +"]"); &#125;&#125;public class GreenCircle implements DrawAPI &#123; @Override public void drawCircle(int radius, int x, int y) &#123; System.out.println("Drawing Circle[ color: green, radius: " + radius + ", x: " + x + ", " + y + "]"); &#125;&#125;public abstract class Shape &#123; protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI) &#123; this.drawAPI = drawAPI; &#125; public abstract void draw();&#125;public class Circle extends Shape &#123; private int x, y, radius; public Circle(int x, int y, int radius, DrawAPI drawAPI) &#123; super(drawAPI); this.x = x; this.y = y; this.radius = radius; &#125; @Override public void draw() &#123; drawAPI.drawCircle(radius, x, y); &#125;&#125;public class BridgeTest &#123; public static void main(String[] args) &#123; Shape redCircle = new Circle(100, 100, 10, new RedCircle()); Shape greenCircle = new Circle(100, 100, 10, new GreenCircle()); redCircle.draw(); greenCircle.draw(); &#125;&#125; 2.3. 桥接模式过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136public class Person &#123; private String name; private String gender; private String maritalStatus; public Person(String name,String gender,String maritalStatus)&#123; this.name = name; this.gender = gender; this.maritalStatus = maritalStatus; &#125; public String getName() &#123; return name; &#125; public String getGender() &#123; return gender; &#125; public String getMaritalStatus() &#123; return maritalStatus; &#125; &#125;public interface Criteria &#123; public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons);&#125;public class CriteriaMale implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; return persons.stream().filter(person -&gt; person.getGender() .equalsIgnoreCase("MALE")).collect(Collectors.toList()); &#125;&#125;public class CriteriaFemale implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; return persons.stream().filter(person -&gt; person.getGender() .equalsIgnoreCase("FEMALE")).collect(Collectors.toList()); &#125;&#125;public class CriteriaSingle implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; return persons.stream().filter(person -&gt; person.getMaritalStatus() .equalsIgnoreCase("SINGLE")).collect(Collectors.toList()); &#125;&#125;public class AndCriteria implements Criteria &#123; private Criteria criteria; private Criteria otherCriteria; public AndCriteria(Criteria criteria, Criteria otherCriteria) &#123; this.criteria = criteria; this.otherCriteria = otherCriteria; &#125; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; firstCriteriaPersons = criteria.meetCriteria(persons); return otherCriteria.meetCriteria(firstCriteriaPersons); &#125;&#125;public class OrCriteria implements Criteria &#123; private Criteria criteria; private Criteria otherCriteria; public OrCriteria(Criteria criteria, Criteria otherCriteria) &#123; this.criteria = criteria; this.otherCriteria = otherCriteria; &#125; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; firstCriteriaItems = criteria.meetCriteria(persons); List&lt;Person&gt; otherCriteriaItems = otherCriteria.meetCriteria(persons); for (Person person : otherCriteriaItems) &#123; if(!firstCriteriaItems.contains(person))&#123; firstCriteriaItems.add(person); &#125; &#125; return firstCriteriaItems; &#125;&#125;public class CriteriaTest &#123; public static void main(String[] args) &#123; List&lt;Person&gt; persons = new ArrayList&lt;Person&gt;(); persons.add(new Person("Robert","Male", "Single")); persons.add(new Person("John","Male", "Married")); persons.add(new Person("Laura","Female", "Married")); persons.add(new Person("Diana","Female", "Single")); persons.add(new Person("Mike","Male", "Single")); persons.add(new Person("Bobby","Male", "Single")); Criteria male = new CriteriaMale(); Criteria female = new CriteriaFemale(); Criteria single = new CriteriaSingle(); Criteria singleMale = new AndCriteria(single, male); Criteria singleOrFemale = new OrCriteria(single, female); System.out.println("Males: "); printPersons(male.meetCriteria(persons)); System.out.println("\nFemales: "); printPersons(female.meetCriteria(persons)); System.out.println("\nSingle Males: "); printPersons(singleMale.meetCriteria(persons)); System.out.println("\nSingle Or Females: "); printPersons(singleOrFemale.meetCriteria(persons)); &#125; public static void printPersons(List&lt;Person&gt; persons)&#123; for (Person person : persons) &#123; System.out.println("Person : [ Name : " + person.getName() +", Gender : " + person.getGender() +", Marital Status : " + person.getMaritalStatus() +" ]"); &#125; &#125;&#125; 2.4. 组合模式组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。 这种模式创建了一个包含自己对象组的类。该类提供了修改相同对象组的方式。 我们通过下面的实例来演示组合模式的用法。实例演示了一个组织中员工的层次结构。 意图：将对象组合成树形结构以表示”部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 主要解决：它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以向处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦。 何时使用： 您想表示对象的部分-整体层次结构（树形结构） 您希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象 如何解决：树枝和叶子实现统一接口，树枝内部组合该接口。 关键代码：树枝内部组合该接口，并且含有内部属性 List，里面放 Component。 应用实例： 算术表达式包括操作数、操作符和另一个操作数，其中，另一个操作符也可以是操作数、操作符和另一个操作数 在 JAVA AWT 和 SWING 中，对于 Button 和 Checkbox 是树叶，Container 是树枝 优点： 高层模块调用简单 节点自由增加 缺点：在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。 使用场景：部分、整体场景，如树形菜单，文件、文件夹的管理。 注意事项：定义时为具体类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class Employee &#123; private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; //构造函数 public Employee(String name,String dept, int sal) &#123; this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;&gt;(); &#125; public void add(Employee e) &#123; subordinates.add(e); &#125; public void remove(Employee e) &#123; subordinates.remove(e); &#125; public List&lt;Employee&gt; getSubordinates()&#123; return subordinates; &#125; @Override public String toString() &#123; return MoreObjects.toStringHelper(this) .add("name", name) .add("dept", dept) .add("salary", salary) .add("subordinates", subordinates) .toString(); &#125;&#125;public class CompositeTest &#123; public static void main(String[] args) &#123; Employee CEO = new Employee("John", "CEO", 30000); Employee headSales = new Employee("Robert", "Head Sales", 20000); Employee headMarketing = new Employee("Michel", "Head Marketing", 20000); Employee clerk1 = new Employee("Laura", "Marketing", 10000); Employee clerk2 = new Employee("Bob", "Marketing", 10000); Employee salesExecutive1 = new Employee("Richard", "Sales", 10000); Employee salesExecutive2 = new Employee("Rob", "Sales", 10000); CEO.add(headSales); CEO.add(headMarketing); headSales.add(salesExecutive1); headSales.add(salesExecutive2); headMarketing.add(clerk1); headMarketing.add(clerk2); //打印该组织的所有员工 System.out.println(CEO); CEO.getSubordinates().forEach(employee -&gt; &#123; System.out.println(employee); employee.getSubordinates().forEach(System.out::println); &#125;); &#125;&#125; 2.5. 装饰器模式装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。 这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。 意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 主要解决：一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。 何时使用：在不想增加很多子类的情况下扩展类。 如何解决：将具体功能职责划分，同时继承装饰者模式。 关键代码： Component 类充当抽象角色，不应该具体实现 修饰类引用和继承 Component 类，具体扩展类重写父类方法。 应用实例： 孙悟空有 72 变，当他变成”庙宇”后，他的根本还是一只猴子，但是他又有了庙宇的功能 不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上。在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体。 优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点：多层装饰比较复杂。 使用场景： 扩展一个类的功能 动态增加功能，动态撤销。 注意事项：可代替继承 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public interface Decorator &#123; void draw();&#125;public class CircleDecorator implements Decorator &#123; @Override public void draw() &#123; System.out.println("Decorator: CircleDecorator"); &#125;&#125;public class RedShapeDecorator extends ShapeDecorator &#123; public RedShapeDecorator(Decorator decorator) &#123; super(decorator); &#125; @Override public void draw() &#123; decorator.draw(); setRedBorder(decorator); &#125; private void setRedBorder(Decorator decorator) &#123; System.out.println("Border Color: Red"); &#125;&#125;public abstract class ShapeDecorator implements Decorator&#123; protected Decorator decorator ; public ShapeDecorator(Decorator decorator)&#123; this.decorator = decorator; &#125; @Override public void draw() &#123; decorator.draw(); &#125;&#125;public class Rectangle implements Decorator &#123; @Override public void draw() &#123; System.out.println("Decorator: Rectangle"); &#125;&#125;public class DecoratorTest &#123; public static void main(String[] args) &#123; Decorator circle = new CircleDecorator(); Decorator redCircle = new RedShapeDecorator(new CircleDecorator()); Decorator redRectangle = new RedShapeDecorator(new Rectangle()); System.out.println("Circle with normal border"); circle.draw(); out.println("\nCircle of red border"); redCircle.draw(); out.println("\nRectangle of red border"); redRectangle.draw(); &#125;&#125; 2.6. 外观模式外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。 这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。 意图：为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 主要解决：降低访问复杂系统的内部子系统时的复杂度，简化客户端与之的接口。 何时使用： 客户端不需要知道系统内部的复杂联系，整个系统只需提供一个”接待员”即可 定义系统的入口。 如何解决：客户端不与系统耦合，外观类与系统耦合。 关键代码：在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。 应用实例： 去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便 JAVA 的三层开发模式 优点： 减少系统相互依赖 提高灵活性 提高了安全性 缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。 使用场景： 为复杂的模块或子系统提供外界访问的模块 子系统相对独立 预防低水平人员带来的风险 注意事项：在层次化结构中，可以使用外观模式定义系统中每一层的入口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public interface Facade &#123; void draw();&#125;public class RectangleFacade implements Facade &#123; @Override public void draw() &#123; System.out.println("Rectangle::draw()"); &#125;&#125;public class SquareFacade implements Facade &#123; @Override public void draw() &#123; System.out.println("Square::draw()"); &#125;&#125;public class FacadeMaker &#123; private Facade rectangleFacade; private Facade squareFacade; public FacadeMaker()&#123; rectangleFacade = new RectangleFacade(); squareFacade = new SquareFacade(); &#125; public void drawSquare()&#123; squareFacade.draw(); &#125; public void drawRectangle()&#123; rectangleFacade.draw(); &#125;&#125;public class FacadeTest &#123; public static void main(String[] args) &#123; FacadeMaker facadeMaker = new FacadeMaker(); facadeMaker.drawRectangle(); facadeMaker.drawSquare(); &#125;&#125; 2.7. 享元模式享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。 享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。 意图：运用共享技术有效地支持大量细粒度的对象。 主要解决：在有大量对象时，有可能会造成内存溢出，我们把其中共同的部分抽象出来，如果有相同的业务请求，直接返回在内存中已有的对象，避免重新创建。 何时使用： 系统中有大量对象 这些对象消耗大量内存 这些对象的状态大部分可以外部化 这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替 系统不依赖于这些对象身份，这些对象是不可分辨的 如何解决：用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象。 关键代码：用 HashMap 存储这些对象。 应用实例： JAVA 中的 String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面 数据库的数据池 优点：大大减少对象的创建，降低系统的内存，使效率提高。 缺点：提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。 使用场景： 系统有大量相似对象 需要缓冲池的场景 注意事项： 注意划分外部状态和内部状态，否则可能会引起线程安全问题 这些类必须有一个工厂对象加以控制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public interface Flyweight &#123; void draw();&#125;public class CircleFlyweight implements Flyweight &#123; private String color; private int x; private int y; private int radius; public CircleFlyweight(String color)&#123; this.color = color; &#125; public void setX(int x) &#123; this.x = x; &#125; public void setY(int y) &#123; this.y = y; &#125; public void setRadius(int radius) &#123; this.radius = radius; &#125; @Override public void draw() &#123; System.out.println("Circle: Draw() [Color : " + color +", x : " + x +", y :" + y +", radius :" + radius); &#125;&#125;public class FlyweightFactory &#123; private static final HashMap&lt;String, Flyweight&gt; circleMap = new HashMap&lt;&gt;(); public static Flyweight getCircle(String color) &#123; CircleFlyweight circle = (CircleFlyweight) circleMap.get(color); if (circle == null) &#123; circle = new CircleFlyweight(color); circleMap.put(color, circle); System.out.println("Creating circle of color : " + color); &#125; return circle; &#125;&#125;public class FlyweightTest &#123; private static final String colors[] = &#123; "Red", "Green", "Blue", "White", "Black" &#125;; public static void main(String[] args) &#123; for(int i=0; i &lt; 20; ++i) &#123; CircleFlyweight circle = (CircleFlyweight)FlyweightFactory.getCircle(getRandomColor()); circle.setX(getRandomX()); circle.setY(getRandomY()); circle.setRadius(100); circle.draw(); &#125; &#125; private static String getRandomColor() &#123; return colors[(int)(Math.random()*colors.length)]; &#125; private static int getRandomX() &#123; return (int)(Math.random()*100 ); &#125; private static int getRandomY() &#123; return (int)(Math.random()*100); &#125;&#125; 2.8. 代理模式在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 意图：为其他对象提供一种代理以控制对这个对象的访问。 主要解决：在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 何时使用：想在访问一个类时做一些控制。 如何解决：增加中间层。 关键代码：实现与被代理类组合。 应用实例： Windows 里面的快捷方式 猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类 买火车票不一定在火车站买，也可以去代售点 一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制 spring aop 优点： 职责清晰 高扩展性 智能化 缺点： 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢 实现代理模式需要额外的工作，有些代理模式的实现非常复杂 使用场景：按职责来划分，通常有以下使用场景： 远程代理 虚拟代理 Copy-on-Write 代理 保护（Protect or Access）代理 Cache代理 防火墙（Firewall）代理 同步化（Synchronization）代理 智能引用（Smart Reference）代理 注意事项： 和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口 和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface Image &#123; void display();&#125;public class RealImage implements Image &#123; private String fileName; public RealImage(String fileName) &#123; this.fileName = fileName; loadFromDisk(fileName); &#125; @Override public void display() &#123; System.out.println("Displaying " + fileName); &#125; private void loadFromDisk(String fileName) &#123; System.out.println("Loading " + fileName); &#125;&#125;public class ProxyImage implements Image&#123; private RealImage realImage; private String fileName; public ProxyImage(String fileName)&#123; this.fileName = fileName; &#125; @Override public void display() &#123; if(realImage == null)&#123; realImage = new RealImage(fileName); &#125; realImage.display(); &#125;&#125;public class ProxyTest &#123; public static void main(String[] args) &#123; Image image = new ProxyImage("test_10mb.jpg"); //图像将从磁盘加载 image.display(); System.out.println(""); //图像将无法从磁盘加载 image.display(); &#125;&#125; 3.行为型模式3.1. 责任链模式顾名思义，责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。 在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。 意图：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 主要解决：职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 何时使用：在处理消息的时候以过滤很多道。 如何解决：拦截的类都实现统一接口。 关键代码：Handler 里面聚合它自己，在 HanleRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 应用实例： 红楼梦中的”击鼓传花”。 JS 中的事件冒泡。 AVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。 优点： 降低耦合度。它将请求的发送者和接收者解耦。 简化了对象。使得对象不需要知道链的结构。 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 增加新的请求处理类很方便。 缺点： 不能保证请求一定被接收。 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 可能不容易观察运行时的特征，有碍于除错。 使用场景： 有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 在不明确指定接收者的情况下，向多个对象中的一个提交一个请求 可动态指定一组对象处理请求。 注意事项： 在 JAVA WEB 中遇到很多应用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public abstract class AbstractLogger &#123; public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3; protected int level; /** * 责任链中的下一个元素 */ protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger) &#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level, String message) &#123; if (this.level &lt;= level) &#123; write(message); &#125; if (nextLogger != null) &#123; nextLogger.logMessage(level, message); &#125; &#125; abstract protected void write(String message);&#125;public class ConsoleLogger extends AbstractLogger &#123; public ConsoleLogger(int level) &#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Standard Console::Logger: " + message); &#125;&#125;public class DebugLogger extends AbstractLogger &#123; public DebugLogger(int level) &#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Debug::Logger: " + message); &#125;&#125;public class ErrorLogger extends AbstractLogger &#123; public ErrorLogger(int level) &#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Error Console::Logger: " + message); &#125;&#125;public class ChainPatternDemo &#123; private static AbstractLogger getChainOfLoggers() &#123; AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger debugLogger = new DebugLogger(AbstractLogger.DEBUG); AbstractLogger consoleLogger = new ConsoleLogger(AbstractLogger.INFO); errorLogger.setNextLogger(debugLogger); debugLogger.setNextLogger(consoleLogger); return errorLogger; &#125; public static void main(String[] args) &#123; AbstractLogger loggerChain = getChainOfLoggers(); loggerChain.logMessage(AbstractLogger.INFO, "This is an information."); loggerChain.logMessage(AbstractLogger.DEBUG, "This is an debug level information."); loggerChain.logMessage(AbstractLogger.ERROR, "This is an error information."); &#125;&#125; 3.2. 命令模式命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。 主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用：在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 关键代码：定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口 应用实例：struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点： 降低了系统耦合度。 新的命令可以很容易添加到系统中去。 缺点：使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景：认为是命令的地方都可以使用命令模式，比如： 1、GUI 中每一个按钮都是一条命令。 2、模拟 CMD。 注意事项：系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public interface Order &#123; void execute();&#125;public class Stock &#123; private String name = "ABC"; private int quantity = 10; public void buy() &#123; System.out.println("Stock [ Name: " + name + ",Quantity:" + quantity + " ]bought "); &#125; public void sell() &#123; System.out.println("Stock [ Name: " + name + ",Quantity:" + quantity + " ]sold "); &#125;&#125;public class BuyStock implements Order &#123; private Stock abcStock; public BuyStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; @Override public void execute() &#123; abcStock.buy(); &#125;&#125;public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock) &#123; this.abcStock = abcStock; &#125; @Override public void execute() &#123; abcStock.sell(); &#125;&#125;public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;&gt;(); public void takeOrder(Order order) &#123; orderList.add(order); &#125; public void placeOrders() &#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125;public class CommandPatternDemo &#123; public static void main(String[] args) &#123; Stock abcStock = new Stock(); BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders(); &#125;&#125; 3.3. 解释器模式解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 意图：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。 主要解决：对于一些固定文法构建一个解释句子的解释器。 何时使用：如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决：构件语法树，定义终结符与非终结符。 关键代码：构件环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例：编译器、运算表达式计算。 优点： 可扩展性比较好。 增加了新的解释表达式的方式。 易于实现简单文法。 缺点： 可利用场景比较少。 对于复杂的文法比较难维护。 解释器模式会引起类膨胀。 解释器模式采用递归调用方法。 使用场景： 可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 一些重复出现的问题可以用一种简单的语言来进行表达。 一个简单语法需要解释的场景。 注意事项：可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public interface Expression &#123; public boolean interpret(String context);&#125;public class TerminalExpression implements Expression &#123; private String data; public TerminalExpression(String data) &#123; this.data = data; &#125; @Override public boolean interpret(String context) &#123; if (context.contains(data)) &#123; return true; &#125; return false; &#125;&#125;public class OrExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public OrExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) || expr2.interpret(context); &#125;&#125;public class AndExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public AndExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) &amp;&amp; expr2.interpret(context); &#125;&#125;public class InterpreterPatternDemo &#123; /** * 规则：Robert 和 John 是男性 */ public static Expression getMaleExpression() &#123; Expression robert = new TerminalExpression("Robert"); Expression john = new TerminalExpression("John"); return new OrExpression(robert, john); &#125; /** * 规则：Julie 是一个已婚的女性 */ public static Expression getMarriedWomanExpression() &#123; Expression julie = new TerminalExpression("Julie"); Expression married = new TerminalExpression("Married"); return new AndExpression(julie, married); &#125; public static void main(String[] args) &#123; Expression isMale = getMaleExpression(); Expression isMarriedWoman = getMarriedWomanExpression(); System.out.println("John is male? " + isMale.interpret("John")); System.out.println("Julie is a married women? " + isMarriedWoman.interpret("Married Julie")); &#125;&#125; 3.4. 迭代器模式迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。 迭代器模式属于行为型模式。 意图：提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示。 主要解决：不同的方式来遍历整个整合对象。 何时使用：遍历一个聚合对象。 如何解决：把在元素之间游走的责任交给迭代器，而不是聚合对象。 关键代码：定义接口：hasNext, next。 应用实例：JAVA 中的 iterator。 优点： 它支持以不同的方式遍历一个聚合对象。 迭代器简化了聚合类。 在同一个聚合上可以有多个遍历。 在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。 缺点：由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。 使用场景： 访问一个聚合对象的内容而无须暴露它的内部表示。 需要为聚合对象提供多种遍历方式。 为遍历不同的聚合结构提供一个统一的接口。 注意事项：迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface Iterator &#123; public boolean hasNext(); public Object next();&#125;public interface Container &#123; public Iterator getIterator();&#125;public class NameRepository implements Container &#123; public String[] names = &#123;"Robert", "John", "Julie", "Lora"&#125;; @Override public Iterator getIterator() &#123; return new NameIterator(); &#125; private class NameIterator implements Iterator &#123; int index; @Override public boolean hasNext() &#123; if (index &lt; names.length) &#123; return true; &#125; return false; &#125; @Override public Object next() &#123; if (this.hasNext()) &#123; return names[index++]; &#125; return null; &#125; &#125;&#125;public class IteratorPatternDemo &#123; public static void main(String[] args) &#123; NameRepository namesRepository = new NameRepository(); for (Iterator iter = namesRepository.getIterator(); iter.hasNext(); ) &#123; String name = (String) iter.next(); System.out.println("Name : " + name); &#125; &#125;&#125; 3.5. 中介者模式中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。 意图：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 主要解决：对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。 何时使用：多个类相互耦合，形成了网状结构。 如何解决：将上述网状结构分离为星型结构。 关键代码：对象 Colleague 之间的通信封装到一个类中单独处理。 应用实例： 中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 机场调度系统。 MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。 优点： 降低了类的复杂度，将一对多转化成了一对一。 各个类之间的解耦。 符合迪米特原则。 缺点：中介者会庞大，变得复杂难以维护。 使用场景： 系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象。 想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。 注意事项：不应当在职责混乱的时候使用。 12345678910111213141516171819202122232425262728293031323334353637public class ChatRoom &#123; public static void showMessage(User user, String message) &#123; System.out.println(new Date().toString() + " [" + user.getName() + "] : " + message); &#125;&#125;public class MediatorPatternDemo &#123; public static void main(String[] args) &#123; User robert = new User("Robert"); User john = new User("John"); robert.sendMessage("Hi! John!"); john.sendMessage("Hello! Robert!"); &#125;&#125;public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public User(String name) &#123; this.name = name; &#125; public void sendMessage(String message) &#123; ChatRoom.showMessage(this, message); &#125;&#125; 3.6. 备忘录模式备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。 意图：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 主要解决：所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。 何时使用：很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有”后悔药”可吃。 如何解决：通过一个备忘录类专门存储对象状态。 关键代码：客户不与备忘录类耦合，与备忘录管理类耦合。 应用实例： 后悔药。 打游戏时的存档。 Windows 里的 ctri + z。 IE 中的后退。 数据库的事务管理。 优点： 给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态。 实现了信息的封装，使得用户不需要关心状态的保存细节。 缺点：消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。 使用场景： 需要保存/恢复数据的相关状态场景。 提供一个可回滚的操作。 注意事项： 为了符合迪米特原则，还要增加一个管理备忘录的类。 为了节约内存，可使用原型模式+备忘录模式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125;&#125;public class Originator &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public Memento saveStateToMemento() &#123; return new Memento(state); &#125; public void getStateFromMemento(Memento Memento) &#123; state = Memento.getState(); &#125;&#125;public class CareTaker &#123; private List&lt;Memento&gt; mementoList = new ArrayList&lt;Memento&gt;(); public void add(Memento state) &#123; mementoList.add(state); &#125; public Memento get(int index) &#123; return mementoList.get(index); &#125;&#125;public class MementoPatternDemo &#123; public static void main(String[] args) &#123; Originator originator = new Originator(); CareTaker careTaker = new CareTaker(); originator.setState("State #1"); originator.setState("State #2"); careTaker.add(originator.saveStateToMemento()); originator.setState("State #3"); careTaker.add(originator.saveStateToMemento()); originator.setState("State #4"); System.out.println("Current State: " + originator.getState()); originator.getStateFromMemento(careTaker.get(0)); System.out.println("First saved State: " + originator.getState()); originator.getStateFromMemento(careTaker.get(1)); System.out.println("Second saved State: " + originator.getState()); &#125;&#125; 3.7. 观察者模式当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。观察者模式属于行为型模式。 意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 关键代码：在抽象类里有一个 ArrayList 存放观察者们。 应用实例： 拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。 西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。 优点： 观察者和被观察者是抽象耦合的。 建立一套触发机制。 缺点： 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 使用场景： 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 注意事项： JAVA 中已经有了对观察者模式的支持类。 避免循环引用。 如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; notifyAllObservers(); &#125; public void attach(Observer observer) &#123; observers.add(observer); &#125; public void notifyAllObservers() &#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125;&#125;public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125;public class BinaryObserver extends Observer &#123; public BinaryObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println("Binary String: " + Integer.toBinaryString(subject.getState())); &#125;&#125;public class OctalObserver extends Observer &#123; public OctalObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println("Octal String: " + Integer.toOctalString(subject.getState())); &#125;&#125;public class HexaObserver extends Observer &#123; public HexaObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println("Hex String: " + Integer.toHexString(subject.getState()).toUpperCase()); &#125;&#125;public class ObserverPatternDemo &#123; public static void main(String[] args) &#123; Subject subject = new Subject(); new HexaObserver(subject); new OctalObserver(subject); new BinaryObserver(subject); System.out.println("First state change: 15"); subject.setState(15); System.out.println("Second state change: 10"); subject.setState(10); &#125;&#125; 3.8. 状态模式在状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。 在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。 意图：允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。 主要解决：对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。 何时使用：代码中包含大量与对象状态有关的条件语句。 如何解决：将各种具体的状态类抽象出来。 关键代码：通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法。而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值。也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法。状态模式和命令模式一样，也可以用于消除 if…else 等条件选择语句。 应用实例： 打篮球的时候运动员可以有正常状态、不正常状态和超常状态。 曾侯乙编钟中，’钟是抽象接口’,’钟A’等是具体状态，’曾侯乙编钟’是具体环境（Context）。 优点： 封装了转换规则。 枚举可能的状态，在枚举状态之前需要确定状态种类。 将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为。 允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块。 可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数。 缺点： 状态模式的使用必然会增加系统类和对象的个数。 态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱。 状态模式对”开闭原则”的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态，而且修改某个状态类的行为也需修改对应类的源代码。 使用场景： 行为随状态改变而改变的场景。 条件、分支语句的代替者。 注意事项：在行为受状态约束的时候使用状态模式，而且状态不超过 5 个。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public interface State &#123; public void doAction(Context context);&#125;public class Context &#123; private State state; public Context() &#123; state = null; &#125; public void setState(State state) &#123; this.state = state; &#125; public State getState() &#123; return state; &#125;&#125;public class StartState implements State &#123; @Override public void doAction(Context context) &#123; System.out.println("Player is in start state"); context.setState(this); &#125; @Override public String toString() &#123; return "Start State"; &#125;&#125;public class StopState implements State &#123; @Override public void doAction(Context context) &#123; System.out.println("Player is in stop state"); context.setState(this); &#125; @Override public String toString() &#123; return "Stop State"; &#125;&#125; 3.9. 空对象模式在空对象模式（Null Object Pattern）中，一个空对象取代 NULL 对象实例的检查。Null 对象不是检查空值，而是反应一个不做任何动作的关系。这样的 Null 对象也可以在数据不可用的时候提供默认的行为。 在空对象模式中，我们创建一个指定各种要执行的操作的抽象类和扩展该类的实体类，还创建一个未对该类做任何实现的空对象类，该空对象类将无缝地使用在需要检查空值的地方。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public abstract class AbstractCustomer &#123; protected String name; public abstract boolean isNil(); public abstract String getName();&#125;public class RealCustomer extends AbstractCustomer &#123; public RealCustomer(String name) &#123; this.name = name; &#125; @Override public String getName() &#123; return name; &#125; @Override public boolean isNil() &#123; return false; &#125;&#125;public class NullCustomer extends AbstractCustomer &#123; @Override public String getName() &#123; return "Not Available in Customer Database"; &#125; @Override public boolean isNil() &#123; return true; &#125;&#125;public class NullPatternDemo &#123; public static void main(String[] args) &#123; AbstractCustomer customer1 = CustomerFactory.getCustomer("Rob"); AbstractCustomer customer2 = CustomerFactory.getCustomer("Bob"); AbstractCustomer customer3 = CustomerFactory.getCustomer("Julie"); AbstractCustomer customer4 = CustomerFactory.getCustomer("Laura"); System.out.println("Customers"); System.out.println(customer1.getName()); System.out.println(customer2.getName()); System.out.println(customer3.getName()); System.out.println(customer4.getName()); &#125;&#125;public class CustomerFactory &#123; public static final String[] names = &#123;"Rob", "Joe", "Julie"&#125;; public static AbstractCustomer getCustomer(String name) &#123; for (int i = 0; i &lt; names.length; i++) &#123; if (names[i].equalsIgnoreCase(name)) &#123; return new RealCustomer(name); &#125; &#125; return new NullCustomer(); &#125;&#125; 3.10. 策略模式在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。 在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。 主要解决：在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。 何时使用：一个系统有许多许多类，而区分它们的只是他们直接的行为。 如何解决：将这些算法封装成一个一个的类，任意地替换。 关键代码：实现同一个接口。 应用实例： 诸葛亮的锦囊妙计，每一个锦囊就是一个策略。 旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。 JAVA AWT 中的 LayoutManager。 优点： 算法可以自由切换。 避免使用多重条件判断。 扩展性良好。 缺点： 策略类会增多。 所有策略类都需要对外暴露。 使用场景： 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 一个系统需要动态地在几种算法中选择一种。 3、如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 注意事项：如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public interface Strategy &#123; public int doOperation(int num1, int num2);&#125;public class OperationAdd implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125;&#125;public class OperationSubstract implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125;public class OperationMultiply implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 * num2; &#125;&#125;public class Context &#123; private State state; public Context() &#123; state = null; &#125; public void setState(State state) &#123; this.state = state; &#125; public State getState() &#123; return state; &#125; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int num1, int num2)&#123; return strategy.doOperation(num1, num2); &#125;&#125;public class StrategyPatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(new OperationAdd()); System.out.println("10 + 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationSubstract()); System.out.println("10 - 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationMultiply()); System.out.println("10 * 5 = " + context.executeStrategy(10, 5)); &#125;&#125; 3.11. 模板模式在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 意图：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 主要解决：一些方法通用，却在每一个子类都重新写了这一方法。 何时使用：有一些通用的方法。 如何解决：将这些通用算法抽象出来。 关键代码：在抽象类实现，其他步骤在子类实现。 应用实例： 在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异。 西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架。 spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存。 优点： 封装不变部分，扩展可变部分。 提取公共代码，便于维护。 行为由父类控制，子类实现。 缺点：每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 使用场景： 有多个子类共有的方法，且逻辑相同。 重要的、复杂的方法，可以考虑作为模板方法。 注意事项：为防止恶意操作，一般模板方法都加上 final 关键词。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); /** * 模板 */ public final void play() &#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125;public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println("Cricket Game Finished!"); &#125; @Override void initialize() &#123; System.out.println("Cricket Game Initialized! Start playing."); &#125; @Override void startPlay() &#123; System.out.println("Cricket Game Started. Enjoy the game!"); &#125;&#125;public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println("Football Game Finished!"); &#125; @Override void initialize() &#123; System.out.println("Football Game Initialized! Start playing."); &#125; @Override void startPlay() &#123; System.out.println("Football Game Started. Enjoy the game!"); &#125;&#125;public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125;&#125; 3.12. 访问者模式在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。 意图：主要将数据结构与数据操作分离。 主要解决：稳定的数据结构和易变的操作耦合问题。 何时使用：需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中。 如何解决：在被访问的类里面加一个对外提供接待访问者的接口。 关键代码：在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。 应用实例：您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式。 优点： 符合单一职责原则。 优秀的扩展性。 灵活性。 缺点： 具体元素对访问者公布细节，违反了迪米特原则。 具体元素变更比较困难。 违反了依赖倒置原则，依赖了具体类，没有依赖抽象。 使用场景： 对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。 需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。 注意事项：访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public interface ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor);&#125;public interface ComputerPartVisitor &#123; public void visit(Computer computer); public void visit(Mouse mouse); public void visit(Keyboard keyboard); public void visit(Monitor monitor);&#125;public class Keyboard implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125;public class Monitor implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125;public class Mouse implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125;public class Computer implements ComputerPart &#123; ComputerPart[] parts; public Computer() &#123; parts = new ComputerPart[]&#123;new Mouse(), new Keyboard(), new Monitor()&#125;; &#125; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; for (int i = 0; i &lt; parts.length; i++) &#123; parts[i].accept(computerPartVisitor); &#125; computerPartVisitor.visit(this); &#125;&#125;public class ComputerPartDisplayVisitor implements ComputerPartVisitor &#123; @Override public void visit(Computer computer) &#123; System.out.println("Displaying Computer."); &#125; @Override public void visit(Mouse mouse) &#123; System.out.println("Displaying Mouse."); &#125; @Override public void visit(Keyboard keyboard) &#123; System.out.println("Displaying Keyboard."); &#125; @Override public void visit(Monitor monitor) &#123; System.out.println("Displaying Monitor."); &#125;&#125;public class VisitorPatternDemo &#123; public static void main(String[] args) &#123; ComputerPart computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor()); &#125;&#125;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git学习]]></title>
    <url>%2F2017%2F10%2F09%2FGit%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Git中文文档 Git 起步1.Git历史同生活中的许多伟大事物一样，Git 诞生于一个极富纷争大举创新的年代。Linux 内核开源项目有着为数众广的参与者。 绝大多数的 Linux 内核维护工作都花在了提交补丁和保存归档的繁琐事务上（1991－2002年间）。 到 2002 年，整个项目组开始启用一个专有的分布式版本控制系统 BitKeeper 来管理和维护代码。 到了 2005 年，开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 这就迫使 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统。 他们对新的系统制订了若干目标： 速度 简单的设计 对非线性开发模式的强力支持（允许成千上万个并行开发的分支） 完全分布式 有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量） 自诞生于 2005 年以来，Git 日臻成熟完善，在高度易用的同时，仍然保留着初期设定的目标。 它的速度飞快，极其适合管理大项目，有着令人难以置信的非线性分支管理系统。 2.Git机制2.1. Git 保证完整性Git 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。 Git 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希看起来是这样： 24b9da6552252987aa493b52f8696cd6d3b00373 Git 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。 2.2. 三种状态 Git 有三种状态，你的文件可能处于其中之一：已提交（committed）、已修改（modified）和已暂存（staged）。 已提交表示数据已经安全的保存在本地数据库中。 已修改表示修改了文件，但还没保存到数据库中。 已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 由此引入 Git 项目的三个工作区域的概念：Git 仓库、工作目录 以及暂存区域。 2.3. Git 仓库、工作目录 、暂存区域 Git 仓库目录 是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。 工作目录 是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 暂存区域 是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’’，不过一般说法还是叫暂存区域。 基本的 Git 工作流程如下： 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 3.初次运行 Git 前的配置Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置： /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。 ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。 每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。 在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\Users\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。 3.1. 用户配置当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改： $ git config --global user.name &quot;John Doe&quot; $ git config –global user.email johndoe@example.com 再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。 很多 GUI 工具都会在第一次运行时帮助你配置这些信息。 3.2. 文本编辑器既然用户信息已经设置完毕，你可以配置默认文本编辑器了，当 Git 需要你输入信息时会调用它。 如果未配置，Git 会使用操作系统默认的文本编辑器，通常是 Vim。 如果你想使用不同的文本编辑器，例如 Emacs，可以这样做： $ git config --global core.editor emacs Warning Vim 和 Emacs 是像 Linux 与 Mac 等基于 Unix 的系统上开发者经常使用的流行的文本编辑器。 如果你对这些编辑器都不是很了解或者你使用的是 Windows 系统，那么可能需要搜索如何在 Git 中配置你最常用的编辑器。 如果你不设置编辑器并且不知道 Vim 或 Emacs 是什么，当它们运行起来后你可能会被弄糊涂、不知所措。 3.3. 检查配置信息如果想要检查你的配置，可以使用 git config --list 命令来列出所有 Git 当时能找到的配置。 $ git config --list user.name=John Doe user.email=johndoe@example.com color.status=auto color.branch=auto color.interactive=auto color.diff=auto ... 你可能会看到重复的变量名，因为 Git 会从不同的文件中读取同一个配置（例如：/etc/gitconfig 与 ~/.gitconfig）。 这种情况下，Git 会使用它找到的每一个变量的最后一个配置。 你可以通过输入 git config &lt;key&gt;： 来检查 Git 的某一项配置 $ git config user.name John Doe Git 基础1.获取 Git 仓库在现有目录中初始化仓库如果你打算使用 Git 来对现有的项目进行管理，你只需要进入该项目目录并输入： $ git init $ git add *.c $ git add LICENSE$ git commit -m ‘initial project version’ 2.克隆现有的仓库$ git clone https://github.com/libgit2/libgit2 $ git clone https://github.com/libgit2/libgit2 mylibgit 这将执行与上一个命令相同的操作，不过在本地创建的仓库名字变为 mylibgit。 3.记录每次更新到仓库 2.1. 检查当前文件状态$ git status On branch master nothing to commit, working directory clean 现在，让我们在项目下创建一个新的 README 文件。 如果之前并不存在这个文件，使用 git status 命令，你将看到一个新的未跟踪文件： $ echo &apos;My Project&apos; &gt; README $ git status On branch master Untracked files: (use “git add …” to include in what will be committed) README nothing added to commit but untracked files present (use &quot;git add&quot; to track) 在状态报告中可以看到新建的 README 文件出现在 Untracked files 下面。 未跟踪的文件意味着 Git 在之前的快照（提交）中没有这些文件；Git 不会自动将之纳入跟踪范围，除非你明明白白地告诉它“我需要跟踪该文件”， 这样的处理让你不必担心将生成的二进制文件或其它不想被跟踪的文件包含进来。 不过现在的例子中，我们确实想要跟踪管理 README 这个文件。 2.2. 跟踪新文件使用命令 git add 开始跟踪一个文件。 所以，要跟踪 README 文件，运行： $ git add README 此时再运行 git status 命令，会看到 README 文件已被跟踪，并处于暂存状态： $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README 只要在 Changes to be committed 这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。 你可能会想起之前我们使用 git init 后就运行了 git add (files) 命令，开始跟踪当前目录下的文件。 git add 命令使用文件或目录的路径作为参数；如果参数是目录的路径，该命令将递归地跟踪该目录下的所有文件。 2.3. 暂存已修改文件现在我们来修改一个已被跟踪的文件。 如果你修改了一个名为 CONTRIBUTING.md 的已被跟踪的文件，然后运行 git status 命令，会看到下面内容： $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 文件 CONTRIBUTING.md 出现在 Changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。 要暂存这次更新，需要运行 git add 命令。 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“添加内容到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。 现在让我们运行 git add 将”CONTRIBUTING.md“放到暂存区，然后再看看 git status 的输出： $ git add CONTRIBUTING.md $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) new file: README modified: CONTRIBUTING.md 现在两个文件都已暂存，下次提交时就会一并记录到仓库。 假设此时，你想要在 CONTRIBUTING.md 里再加条注释， 重新编辑存盘后，准备好提交。 不过且慢，再运行 git status 看看： $ vim CONTRIBUTING.md $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) new file: README modified: CONTRIBUTING.md Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 怎么回事？ 现在 CONTRIBUTING.md 文件同时出现在暂存区和非暂存区。 这怎么可能呢？ 好吧，实际上 Git 只不过暂存了你运行 git add 命令时的版本， 如果你现在提交，CONTRIBUTING.md 的版本是你最后一次运行 git add 命令时的那个版本，而不是你运行 git commit 时，在工作目录中的当前版本。 所以，运行了 git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来： $ git add CONTRIBUTING.md $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) new file: README modified: CONTRIBUTING.md 2.4. 状态简览git status 命令的输出十分详细，但其用语有些繁琐。 如果你使用 git status -s 命令或 git status --short 命令，你将得到一种更为紧凑的格式输出。 运行 git status -s ，状态报告输出如下： $ git status -s M README MM Rakefile A lib/git.rb M lib/simplegit.rb ?? LICENSE.txt 新添加的未跟踪文件前面有 ?? 标记，新添加到暂存区中的文件前面有 A 标记，修改过的文件前面有 M 标记。 你可能注意到了 M 有两个可以出现的位置，出现在右边的 M 表示该文件被修改了但是还没放入暂存区，出现在靠左边的 M 表示该文件被修改了并放入了暂存区。 例如，上面的状态报告显示： README 文件在工作区被修改了但是还没有将修改后的文件放入暂存区,lib/simplegit.rb 文件被修改了并将修改后的文件放入了暂存区。 而 Rakefile 在工作区被修改并提交到暂存区后又在工作区中被修改了，所以在暂存区和工作区都有该文件被修改了的记录。 2.5. 忽略文件一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。 来看一个实际的例子： $ cat .gitignore *.[oa] *~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的。 第二行告诉 Git 忽略所有以波浪符（~）结尾的文件，许多文本编辑软件（比如 Emacs）都用这样的文件名保存副本。 此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。 要养成一开始就设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 列表项 所有空行或者以 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。 星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（*) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。 2.6. 查看已暂存和未暂存的修改如果 git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 git diff 命令。git diff 将通过文件补丁的格式显示具体哪些行发生了改变。 假如再次修改 README 文件后暂存，然后编辑 CONTRIBUTING.md 文件后先不暂存， 运行 status 命令将会看到： $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: README Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff： $ git diff diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 8ebb991..643e24f 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -65,7 +65,8 @@ branch directly, things can get messy. Please include a nice description of your changes when you submit your PR; if we have to read the whole diff to figure out why you&apos;re contributing in the first place, you&apos;re less likely to get feedback and have your change -merged in. +merged in. Also, split your changes into comprehensive chunks if your patch is +longer than a dozen lines. If you are starting to work on a particular area, feel free to submit a PR that highlights your work in progress (and note in the PR title that it&apos;s 此命令比较的是工作目录中当前文件和暂存区域快照之间的差异， 也就是修改之后还没有暂存起来的变化内容。 若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff --cached 命令。（Git 1.6.1 及更高版本还允许使用 git diff --staged，效果是相同的，但更好记些。） $ git diff --staged diff --git a/README b/README new file mode 100644 index 0000000..03902a1 --- /dev/null +++ b/README @@ -0,0 +1 @@ +My Project 请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。 像之前说的，暂存 CONTRIBUTING.md 后再编辑，运行 git status 会看到暂存前后的两个版本。 如果我们的环境（终端输出）看起来如下： $ git add CONTRIBUTING.md $ echo ‘# test line’ &gt;&gt; CONTRIBUTING.md $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) modified: CONTRIBUTING.md Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 现在运行 git diff 看暂存前后的变化： $ git diff diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 643e24f..87f08c8 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -119,3 +119,4 @@ at the ## Starter Projects See our [projects list](https://github.com/libgit2/libgit2/blob/development/PROJECTS.md). +# test line 然后用 git diff --cached 查看已经暂存起来的变化：（--staged 和 --cached 是同义词） $ git diff --cached diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 8ebb991..643e24f 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -65,7 +65,8 @@ branch directly, things can get messy. Please include a nice description of your changes when you submit your PR; if we have to read the whole diff to figure out why you&apos;re contributing in the first place, you&apos;re less likely to get feedback and have your change -merged in. +merged in. Also, split your changes into comprehensive chunks if your patch is +longer than a dozen lines. If you are starting to work on a particular area, feel free to submit a PR that highlights your work in progress (and note in the PR title that it&apos;s Note Git Diff 的插件版本在本书中，我们使用 git diff 来分析文件差异。 但是，如果你喜欢通过图形化的方式或其它格式输出方式的话，可以使用 git difftool 命令来用 Araxis ，emerge 或 vimdiff 等软件输出 diff 分析结果。 使用 git difftool --tool-help 命令来看你的系统支持哪些 Git Diff 插件。 2.7. 提交更新现在的暂存区域已经准备妥当可以提交了。 在此之前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，是不是都已暂存起来了， 然后再运行提交命令 git commit： $ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。 (默认会启用 shell 的环境变量 $EDITOR 所指定的软件，一般都是 vim 或 emacs。当然也可以按照 起步 介绍的方式，使用 git config --global core.editor 命令设定你喜欢的编辑软件。） 编辑器会显示类似下面的文本信息（本例选用 Vim 的屏显方式展示）： # Please enter the commit message for your changes. Lines starting # with &apos;#&apos; will be ignored, and an empty message aborts the commit. # On branch master # Changes to be committed: # new file: README # modified: CONTRIBUTING.md # ~ ~ ~ &quot;.git/COMMIT_EDITMSG&quot; 9L, 283C 可以看到，默认的提交消息包含最后一次运行 git status 的输出，放在注释行里，另外开头还有一空行，供你输入提交说明。 你完全可以去掉这些注释行，不过留着也没关系，多少能帮你回想起这次更新的内容有哪些。 (如果想要更详细的对修改了哪些内容的提示，可以用 -v 选项，这会将你所做的改变的 diff 输出放到编辑器中从而使你知道本次提交具体做了哪些修改。） 退出编辑器时，Git 会丢掉注释行，用你输入提交附带信息生成一次提交。 另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示： $ git commit -m &quot;Story 182: Fix benchmarks for speed&quot; [master 463dc4f] Story 182: Fix benchmarks for speed 2 files changed, 2 insertions(+) create mode 100644 README 好，现在你已经创建了第一个提交！ 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。 请记住，提交时记录的是放在暂存区域的快照。 任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。 2.8. 跳过使用暂存区域尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤： $ git status On branch master Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) $ git commit -a -m &apos;added new benchmarks&apos; [master 83e38c7] added new benchmarks 1 file changed, 5 insertions(+), 0 deletions(-) 2.9. 移除文件要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 “Changes not staged for commit” 部分（也就是 未暂存清单）看到： $ rm PROJECTS.md $ git status On branch master Your branch is up-to-date with ‘origin/master’. Changes not staged for commit: (use “git add/rm …” to update what will be committed) (use “git checkout – …” to discard changes in working directory) deleted: PROJECTS.md no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 然后再运行 git rm 记录此次移除文件的操作： $ git rm PROJECTS.md rm ‘PROJECTS.md’$ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) deleted: PROJECTS.md 下一次提交时，该文件就不再纳入版本管理了。 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f（译注：即 force 的首字母）。 这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 --cached 选项： $ git rm --cached README git rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。 比方说： $ git rm log/\*.log 注意到星号 * 之前的反斜杠 \， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如： $ git rm \*~ 该命令为删除以 ~ 结尾的所有文件。 2.10. 移动文件不像其它的 VCS 系统，Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。 既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。 要在 Git 中对文件改名，可以这么做： $ git mv file_from file_to 它会恰如预期般正常工作。 实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明： $ git mv README.md README $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) renamed: README.md -&gt; README 其实，运行 git mv 就相当于运行了下面三条命令： $ mv README.md README $ git rm README.md $ git add README 如此分开操作，Git 也会意识到这是一次改名，所以不管何种方式结果都一样。 两者唯一的区别是，mv 是一条命令而另一种方式需要三条命令，直接用 git mv 轻便得多。 不过有时候用其他工具批处理改名的话，要记得在提交前删除老的文件名，再添加新的文件名。 3.查看提交历史3.1. 查看提交历史在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 完成这个任务最简单而又有效的工具是 git log 命令。 接下来的例子会用我专门用于演示的 simplegit 项目， 运行下面的命令获取该项目源代码： git clone https://github.com/schacon/simplegit-progit 然后在此项目中运行 git log，应该会看到下面的输出： $ git log commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。 正如你所看到的，这个命令会列出每个提交的 SHA-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。 git log 有许多选项可以帮助你搜寻你所要找的提交， 接下来我们介绍些最常用的。 一个常用的选项是 -p，用来显示每次提交的内容差异。 你也可以加上 -2 来仅显示最近两次提交： $ git log -p -2 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number diff --git a/Rakefile b/Rakefile index a874b73..8f94139 100644 --- a/Rakefile +++ b/Rakefile @@ -5,7 +5,7 @@ require &apos;rake/gempackagetask&apos; spec = Gem::Specification.new do |s| s.platform = Gem::Platform::RUBY s.name = &quot;simplegit&quot; - s.version = &quot;0.1.0&quot; + s.version = &quot;0.1.1&quot; s.author = &quot;Scott Chacon&quot; s.email = &quot;schacon@gee-mail.com&quot; s.summary = &quot;A simple gem for using Git in Ruby code.&quot; commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test diff --git a/lib/simplegit.rb b/lib/simplegit.rb index a0a60ae..47c6340 100644 --- a/lib/simplegit.rb +++ b/lib/simplegit.rb @@ -18,8 +18,3 @@ class SimpleGit end end - -if $0 == __FILE__ - git = SimpleGit.new - puts git.show -end \ No newline at end of file 该选项除了显示基本信息之外，还附带了每次 commit 的变化。 当进行代码审查，或者快速浏览某个搭档提交的 commit 所带来的变化的时候，这个参数就非常有用了。 你也可以为 git log 附带一系列的总结性选项。 比如说，如果你想看到每次提交的简略的统计信息，你可以使用 –stat 选项： $ git log --stat commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test lib/simplegit.rb | 5 ----- 1 file changed, 5 deletions(-) commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit README | 6 ++++++ Rakefile | 23 +++++++++++++++++++++++ lib/simplegit.rb | 25 +++++++++++++++++++++++++ 3 files changed, 54 insertions(+) 正如你所看到的，--stat 选项在每次提交的下面列出所有被修改过的文件、有多少文件被修改了以及被修改过的文件的哪些行被移除或是添加了。 在每次提交的最后还有一个总结。 另外一个常用的选项是 --pretty。 这个选项可以指定使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如用 oneline 将每个提交放在一行显示，查看的提交数很大时非常有用。 另外还有 short，full 和 fuller 可以用，展示的信息或多或少有些不同，请自己动手实践一下看看效果如何。 $ git log --pretty=oneline ca82a6dff817ec66f44342007202690a93763949 changed the version number 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test a11bef06a3f659402fe7563abf99ad00de2209e6 first commit 但最有意思的是 format，可以定制要显示的记录格式。 这样的输出对后期提取分析格外有用 — 因为你知道输出的格式不会随着 Git 的更新而发生改变： $ git log --pretty=format:&quot;%h - %an, %ar : %s&quot; ca82a6d - Scott Chacon, 6 years ago : changed the version number 085bb3b - Scott Chacon, 6 years ago : removed unnecessary test a11bef0 - Scott Chacon, 6 years ago : first commit git log --pretty=format 常用的选项 列出了常用的格式占位符写法及其代表的意义。 git log --pretty=format 常用的选项： |—————–+————|| 选项 | 说明 ||—————–|:———–|| %H | 提交对象（commit）的完整哈希字串 || %h | 提交对象的简短哈希字串 || %T | 树对象（tree）的完整哈希字串 || %t | 树对象的简短哈希字串 || %P | 父对象（parent）的完整哈希字串 || %p | 父对象的简短哈希字串 || %an | 作者（author）的名字|| %ae | 作者的电子邮件地址 || %ad | 作者修订日期（可以用 –date= 选项定制格式） || %ar | 作者修订日期，按多久以前的方式显示 || %cn | 提交者（committer）的名字 || %ce | 提交者的电子邮件地址 || %cd | 提交日期 || %cr | 提交日期，按多久以前的方式显示 || %s | 提交说明 ||—————–+————| 你一定奇怪 作者 和 提交者 之间究竟有何差别， 其实作者指的是实际作出修改的人，提交者指的是最后将此工作成果提交到仓库的人。 所以，当你为某个项目发布补丁，然后某个核心成员将你的补丁并入项目时，你就是作者，而那个核心成员就是提交者。 我们会在 分布式 Git 再详细介绍两者之间的细微差别。 当 oneline 或 format 与另一个 log 选项 --graph 结合使用时尤其有用。 这个选项添加了一些ASCII字符串来形象地展示你的分支、合并历史： $ git log --pretty=format:&quot;%h %s&quot; --graph * 2d3acf9 ignore errors from SIGCHLD on trap * 5e3ee11 Merge branch &apos;master&apos; of git://github.com/dustin/grit |\ | * 420eac9 Added a method for getting the current branch. * | 30e367c timeout code and tests * | 5a09431 add timeout protection to grit * | e1193f8 support for heads with slashes in them |/ * d6016bc require time for xmlschema * 11d191e Merge branch &apos;defunkt&apos; into local 以上只是简单介绍了一些 git log 命令支持的选项。 git log 的常用选项 列出了我们目前涉及到的和没涉及到的选项，以及它们是如何影响 log 命令的输出的：git log 的常用选项： |—————–+————|| 选项 | 说明 ||—————–|:———–|| -p | 按补丁格式显示每个更新之间的差异 || –stat | 显示每次更新的文件修改统计信息 || –shortstat | 只显示 –stat 中最后的行数修改添加移除统计 || –name-only | 仅在提交信息后显示已修改的文件清单 || –name-status | 显示新增、修改、删除的文件清单 || –abbrev-commit | 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符 || –relative-date | 使用较短的相对时间显示（比如，“2 weeks ago”）|| –graph | 显示 ASCII 图形表示的分支合并历史 || –pretty | 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）） ||—————–+————| 3.2. 限制输出长度除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出部分提交信息。 之前你已经看到过 -2 了，它只显示最近的两条提交， 实际上，这是 -&lt;n&gt; 选项的写法，其中的 n 可以是任何整数，表示仅显示最近的若干条提交。 不过实践中我们是不太用这个选项的，Git 在输出所有提交时会自动调用分页程序，所以你一次只会看到一页的内容。 另外还有按照时间作限制的选项，比如 --since 和 --until 也很有用。 例如，下面的命令列出所有最近两周内的提交： $ git log --since=2.weeks 这个命令可以在多种格式下工作，比如说具体的某一天 “2008-01-15”，或者是相对地多久以前 “2 years 1 day 3 minutes ago”。 还可以给出若干搜索条件，列出符合的提交。 用 --author 选项显示指定作者的提交，用 --grep 选项搜索提交说明中的关键字。 （请注意，如果要得到同时满足这两个选项搜索条件的提交，就必须用 --all-match 选项。否则，满足任意一个条件的提交都会被匹配出来） 另一个非常有用的筛选选项是 -S，可以列出那些添加或移除了某些字符串的提交。 比如说，你想找出添加或移除了某一个特定函数的引用的提交，你可以这样使用： $ git log -Sfunction_name 最后一个很实用的 git log 选项是路径（path）， 如果只关心某些文件或者目录的历史提交，可以在 git log 选项的最后指定它们的路径。 因为是放在最后位置上的选项，所以用两个短划线（--）隔开之前的选项和后面限定的路径名。 在 限制 git log 输出的选项 中列出了常用的选项： |—————–+————|| 选项 | 说明 ||—————–|:———–|| -(n) | 仅显示最近的 n 条提交 || –since, –after | 仅显示指定时间之后的提交 || –until, –before | 仅显示指定时间之前的提交 || –author | 仅显示指定作者相关的提交 || –committer | 仅显示指定提交者相关的提交 || –grep | 仅显示含指定关键字的提交 || -S | 仅显示添加或移除了某个关键字的提交 ||—————–+————| 来看一个实际的例子，如果要查看 Git 仓库中，2008 年 10 月期间，Junio Hamano 提交的但未合并的测试文件，可以用下面的查询命令： $ git log --pretty=&quot;%h - %s&quot; --author=gitster --since=&quot;2008-10-01&quot; \ --before=&quot;2008-11-01&quot; --no-merges -- t/ 5610e3b - Fix testcase failure when extended attributes are in use acd3b9e - Enhance hold_lock_file_for_{update,append}() API f563754 - demonstrate breakage of detached checkout with symbolic link HEAD d1a43f2 - reset --hard/read-tree --reset -u: remove unmerged new paths 51a94af - Fix &quot;checkout --track -b newbranch&quot; on detached HEAD b0ad11e - pull: allow &quot;git pull origin $something:$current_branch&quot; into an unborn branch 在近 40000 条提交中，上面的输出仅列出了符合条件的 6 条记录。 4.撤消操作4.1. 撤消操作在任何一个阶段，你都有可能想要撤消某些操作。 这里，我们将会学习几个撤消你所做修改的基本工具。 注意，有些撤消操作是不可逆的。 这是在使用 Git 的过程中，会因为操作失误而导致之前的工作丢失的少有的几个地方之一。 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令尝试重新提交： $ git commit --amend 这个命令会将暂存区中的文件提交。 如果自上次提交以来你还未做任何修改（例如，在上次提交后马上执行了此命令），那么快照会保持不变，而你所修改的只是提交信息。 文本编辑器启动后，可以看到之前的提交信息。 编辑后保存会覆盖原来的提交信息。 例如，你提交后发现忘记了暂存某些需要的修改，可以像下面这样操作： $ git commit -m &apos;initial commit&apos; $ git add forgotten_file $ git commit –amend 最终你只会有一个提交 - 第二次提交将代替第一次提交的结果。 取消暂存的文件接下来的两个小节演示如何操作暂存区域与工作目录中已修改的文件。 这些命令在修改文件状态的同时，也会提示如何撤消操作。 例如，你已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 git add * 暂存了它们两个。 如何只取消暂存两个中的一个呢？ git status 命令提示了你： $ git add * $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) renamed: README.md -&gt; README modified: CONTRIBUTING.md 在 “Changes to be committed” 文字正下方，提示使用 git reset HEAD &lt;file&gt;... 来取消暂存。 所以，我们可以这样来取消暂存 CONTRIBUTING.md 文件： $ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) renamed: README.md -&gt; README Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 这个命令有点儿奇怪，但是起作用了。 CONTRIBUTING.md 文件已经是修改未暂存的状态了。 Note虽然在调用时加上 --hard 选项可以令 git reset 成为一个危险的命令（译注：可能导致工作目录中所有当前进度丢失！），但本例中工作目录内的文件并不会被修改。 不加选项地调用 git reset 并不危险 — 它只会修改暂存区域。 到目前为止这个神奇的调用就是你需要对 git reset 命令了解的全部。我们将会在 重置揭密 中了解 reset 的更多细节以及如何掌握它做一些真正有趣的事。 4.2. 撤消对文件的修改如果你并不想保留对 CONTRIBUTING.md 文件的修改怎么办？ 你该如何方便地撤消修改 - 将它还原成上次提交时的样子（或者刚克隆完的样子，或者刚把它放入工作目录时的样子）？ 幸运的是，git status 也告诉了你应该如何做。 在最后一个例子中，未暂存区域是这样： Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 它非常清楚地告诉了你如何撤消之前所做的修改。 让我们来按照提示执行： $ git checkout -- CONTRIBUTING.md $ git status On branch master Changes to be committed: (use “git reset HEAD …” to unstage) renamed: README.md -&gt; README 可以看到那些修改已经被撤消了。 Important你需要知道 git checkout -- [file] 是一个危险的命令，这很重要。 你对那个文件做的任何修改都会消失 - 你只是拷贝了另一个文件来覆盖它。 除非你确实清楚不想要那个文件了，否则不要使用这个命令。 如果你仍然想保留对那个文件做出的修改，但是现在仍然需要撤消，我们将会在 Git 分支 介绍保存进度与分支；这些通常是更好的做法。 记住，在 Git 中任何 已提交的 东西几乎总是可以恢复的。 甚至那些被删除的分支中的提交或使用 --amend 选项覆盖的提交也可以恢复（阅读 数据恢复 了解数据恢复）。 然而，任何你未提交的东西丢失后很可能再也找不到了。 5.远程仓库的使用5.1. 远程仓库的使用为了能在任意 Git 项目上协作，你需要知道如何管理自己的远程仓库。 远程仓库是指托管在因特网或其他网络中的你的项目的版本库。 你可以有好几个远程仓库，通常有些仓库对你只读，有些则可以读写。 与他人协作涉及管理远程仓库以及根据需要推送或拉取数据。 管理远程仓库包括了解如何添加远程仓库、移除无效的远程仓库、管理不同的远程分支并定义它们是否被跟踪等等。 查看远程仓库如果想查看你已经配置的远程仓库服务器，可以运行 git remote 命令。 它会列出你指定的每一个远程服务器的简写。 如果你已经克隆了自己的仓库，那么至少应该能看到 origin - 这是 Git 给你克隆的仓库服务器的默认名字： $ git clone https://github.com/schacon/ticgit Cloning into &apos;ticgit&apos;... remote: Reusing existing pack: 1857, done. remote: Total 1857 (delta 0), reused 0 (delta 0) Receiving objects: 100% (1857/1857), 374.35 KiB | 268.00 KiB/s, done. Resolving deltas: 100% (772/772), done. Checking connectivity... done. $ cd ticgit $ git remote origin 你也可以指定选项 -v，会显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL。 $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) 如果你的远程仓库不止一个，该命令会将它们全部列出。 例如，与几个协作者合作的，拥有多个远程仓库的仓库看起来像下面这样： $ cd grit $ git remote -v bakkdoor https://github.com/bakkdoor/grit (fetch) bakkdoor https://github.com/bakkdoor/grit (push) cho45 https://github.com/cho45/grit (fetch) cho45 https://github.com/cho45/grit (push) defunkt https://github.com/defunkt/grit (fetch) defunkt https://github.com/defunkt/grit (push) koke git://github.com/koke/grit.git (fetch) koke git://github.com/koke/grit.git (push) origin git@github.com:mojombo/grit.git (fetch) origin git@github.com:mojombo/grit.git (push) 这样我们可以轻松拉取其中任何一个用户的贡献。 此外，我们大概还会有某些远程仓库的推送权限，虽然我们目前还不会在此介绍。 注意这些远程仓库使用了不同的协议；我们将会在 在服务器上搭建 Git 中了解关于它们的更多信息。 5.2. 添加远程仓库我在之前的章节中已经提到并展示了如何添加远程仓库的示例，不过这里将告诉你如何明确地做到这一点。 运行 git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库，同时指定一个你可以轻松引用的简写： $ git remote origin $ git remote add pb https://github.com/paulboone/ticgit $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) pb https://github.com/paulboone/ticgit (fetch) pb https://github.com/paulboone/ticgit (push) 现在你可以在命令行中使用字符串 pb 来代替整个 URL。 例如，如果你想拉取 Paul 的仓库中有但你没有的信息，可以运行 git fetch pb： $ git fetch pb remote: Counting objects: 43, done. remote: Compressing objects: 100% (36/36), done. remote: Total 43 (delta 10), reused 31 (delta 5) Unpacking objects: 100% (43/43), done. From https://github.com/paulboone/ticgit * [new branch] master -&gt; pb/master * [new branch] ticgit -&gt; pb/ticgit 现在 Paul 的 master 分支可以在本地通过 pb/master 访问到 - 你可以将它合并到自己的某个分支中，或者如果你想要查看它的话，可以检出一个指向该点的本地分支。 5.3. 从远程仓库中抓取与拉取就如刚才所见，从远程仓库中获得数据，可以执行： $ git fetch [remote-name] 这个命令会访问远程仓库，从中拉取所有你还没有的数据。 执行完成后，你将会拥有那个远程仓库中所有分支的引用，可以随时合并或查看。 如果你使用 clone 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，git fetch origin 会抓取克隆（或上一次抓取）后新推送的所有工作。 必须注意 git fetch 命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 当准备好时你必须手动将其合并入你的工作。 如果你有一个分支设置为跟踪一个远程分支，可以使用 git pull 命令来自动的抓取然后合并远程分支到当前分支。 这对你来说可能是一个更简单或更舒服的工作流程；默认情况下，git clone 命令会自动设置本地 master 分支跟踪克隆的远程仓库的 master 分支（或不管是什么名字的默认分支）。 运行 git pull 通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。 推送到远程仓库当你想分享你的项目时，必须将其推送到上游。 这个命令很简单：git push [remote-name] [branch-name]。 当你想要将 master 分支推送到 origin 服务器时（再次说明，克隆时通常会自动帮你设置好那两个名字），那么运行这个命令就可以将你所做的备份到服务器： $ git push origin master 只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送。 5.4. 查看远程仓库如果想要查看某一个远程仓库的更多信息，可以使用 git remote show [remote-name] 命令。 如果想以一个特定的缩写名运行这个命令，例如 origin，会得到像下面类似的信息： $ git remote show origin * remote origin Fetch URL: https://github.com/schacon/ticgit Push URL: https://github.com/schacon/ticgit HEAD branch: master Remote branches: master tracked dev-branch tracked Local branch configured for &apos;git pull&apos;: master merges with remote master Local ref configured for &apos;git push&apos;: master pushes to master (up to date) 它同样会列出远程仓库的 URL 与跟踪分支的信息。 这些信息非常有用，它告诉你正处于 master 分支，并且如果运行 git pull，就会抓取所有的远程引用，然后将远程 master 分支合并到本地 master 分支。 它也会列出拉取到的所有远程引用。 这是一个经常遇到的简单例子。 如果你是 Git 的重度使用者，那么还可以通过 git remote show 看到更多的信息。 $ git remote show origin * remote origin URL: https://github.com/my-org/complex-project Fetch URL: https://github.com/my-org/complex-project Push URL: https://github.com/my-org/complex-project HEAD branch: master Remote branches: master tracked dev-branch tracked markdown-strip tracked issue-43 new (next fetch will store in remotes/origin) issue-45 new (next fetch will store in remotes/origin) refs/remotes/origin/issue-11 stale (use &apos;git remote prune&apos; to remove) Local branches configured for &apos;git pull&apos;: dev-branch merges with remote dev-branch master merges with remote master Local refs configured for &apos;git push&apos;: dev-branch pushes to dev-branch (up to date) markdown-strip pushes to markdown-strip (up to date) master pushes to master (up to date) 这个命令列出了当你在特定的分支上执行 git push 会自动地推送到哪一个远程分支。 它也同样地列出了哪些远程分支不在你的本地，哪些远程分支已经从服务器上移除了，还有当你执行 git pull 时哪些分支会自动合并。 远程仓库的移除与重命名如果想要重命名引用的名字可以运行 git remote rename 去修改一个远程仓库的简写名。 例如，想要将 pb 重命名为 paul，可以用 git remote rename 这样做： $ git remote rename pb paul $ git remote origin paul 值得注意的是这同样也会修改你的远程分支名字。 那些过去引用 pb/master 的现在会引用 paul/master。 如果因为一些原因想要移除一个远程仓库 - 你已经从服务器上搬走了或不再想使用某一个特定的镜像了，又或者某一个贡献者不再贡献了 - 可以使用 git remote rm ： $ git remote rm paul $ git remote origin 6.打标签6.1. 列出标签在 Git 中列出已有的标签是非常简单直观的。 只需要输入 git tag： $ git tag v0.1 v1.3 这个命令以字母顺序列出标签；但是它们出现的顺序并不重要。 你也可以使用特定的模式查找标签。 例如，Git 自身的源代码仓库包含标签的数量超过 500 个。 如果只对 1.8.5 系列感兴趣，可以运行： $ git tag -l &apos;v1.8.5*&apos; v1.8.5 v1.8.5-rc0 v1.8.5-rc1 v1.8.5-rc2 v1.8.5-rc3 v1.8.5.1 v1.8.5.2 v1.8.5.3 v1.8.5.4 v1.8.5.5 6.2. 创建标签Git 使用两种主要类型的标签：轻量标签（lightweight）与附注标签（annotated）。 一个轻量标签很像一个不会改变的分支 - 它只是一个特定提交的引用。 然而，附注标签是存储在 Git 数据库中的一个完整对象。 它们是可以被校验的；其中包含打标签者的名字、电子邮件地址、日期时间；还有一个标签信息；并且可以使用 GNU Privacy Guard （GPG）签名与验证。 通常建议创建附注标签，这样你可以拥有以上所有信息；但是如果你只是想用一个临时的标签，或者因为某些原因不想要保存那些信息，轻量标签也是可用的。 6.3. 附注标签在 Git 中创建一个附注标签是很简单的。 最简单的方式是当你在运行 tag 命令时指定 -a 选项： $ git tag -a v1.4 -m &apos;my version 1.4&apos; $ git tag v0.1 v1.3 v1.4 -m 选项指定了一条将会存储在标签中的信息。 如果没有为附注标签指定一条信息，Git 会运行编辑器要求你输入信息。 通过使用 git show 命令可以看到标签信息与对应的提交信息： $ git show v1.4 tag v1.4 Tagger: Ben Straub &lt;ben@straub.cc&gt; Date: Sat May 3 20:19:12 2014 -0700 my version 1.4 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number 输出显示了打标签者的信息、打标签的日期时间、附注信息，然后显示具体的提交信息。 6.4. 轻量标签另一种给提交打标签的方式是使用轻量标签。 轻量标签本质上是将提交校验和存储到一个文件中 - 没有保存任何其他信息。 创建轻量标签，不需要使用 -a、-s 或 -m 选项，只需要提供标签名字： $ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 v1.4-lw v1.5 这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息： $ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number 6.5. 后期打标签你也可以对过去的提交打标签。 假设提交历史是这样的： $ git log --pretty=oneline 15027957951b64cf874c3557a0f3547bd83b3ff6 Merge branch &apos;experiment&apos; a6b4c97498bd301d84096da251c98a07c7723e65 beginning write support 0d52aaab4479697da7686c15f77a3d64d9165190 one more thing 6d52a271eda8725415634dd79daabbc4d9b6008e Merge branch &apos;experiment&apos; 0b7434d86859cc7b8c3d5e1dddfed66ff742fcbc added a commit function 4682c3261057305bdd616e23b64b0857d832627b added a todo file 166ae0c4d3f420721acbb115cc33848dfcc2121a started write support 9fceb02d0ae598e95dc970b74767f19372d61af8 updated rakefile 964f16d36dfccde844893cac5b347e7b3d44abbc commit the todo 8a5cbc430f1a9c3d00faaeffd07798508422908a updated readme 现在，假设在 v1.2 时你忘记给项目打标签，也就是在 “updated rakefile” 提交。 你可以在之后补上标签。 要在那个提交上打标签，你需要在命令的末尾指定提交的校验和（或部分校验和）: $ git tag -a v1.2 9fceb02 可以看到你已经在那次提交上打上标签了： $ git tag v0.1 v1.2 v1.3 v1.4 v1.4-lw v1.5 $ git show v1.2 tag v1.2 Tagger: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Feb 9 15:32:16 2009 -0800 version 1.2 commit 9fceb02d0ae598e95dc970b74767f19372d61af8 Author: Magnus Chacon &lt;mchacon@gee-mail.com&gt; Date: Sun Apr 27 20:43:35 2008 -0700 updated rakefile ... 6.6. 共享标签默认情况下，git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样 - 你可以运行 git push origin [tagname]。 $ git push origin v1.5 Counting objects: 14, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (14/14), 2.05 KiB | 0 bytes/s, done. Total 14 (delta 3), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.5 -&gt; v1.5 如果想要一次性推送很多标签，也可以使用带有 --tags 选项的 git push 命令。 这将会把所有不在远程仓库服务器上的标签全部传送到那里。 $ git push origin --tags Counting objects: 1, done. Writing objects: 100% (1/1), 160 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.4 -&gt; v1.4 * [new tag] v1.4-lw -&gt; v1.4-lw 现在，当其他人从仓库中克隆或拉取，他们也能得到你的那些标签。 检出标签在 Git 中你并不能真的检出一个标签，因为它们并不能像分支一样来回移动。 如果你想要工作目录与仓库中特定的标签版本完全一样，可以使用 git checkout -b [branchname] [tagname] 在特定的标签上创建一个新分支： $ git checkout -b version2 v2.0.0 Switched to a new branch &apos;version2&apos; 当然，如果在这之后又进行了一次提交，version2 分支会因为改动向前移动了，那么 version2 分支就会和 v2.0.0 标签稍微有些不同，这时就应该当心了。 7.Git 别名在我们结束本章 Git 基础之前，正好有一个小技巧可以使你的 Git 体验更简单、容易、熟悉：别名。 我们不会在之后的章节中引用到或假定你使用过它们，但是你大概应该知道如何使用它们。 Git 并不会在你输入部分命令时自动推断出你想要的命令。 如果不想每次都输入完整的 Git 命令，可以通过 git config 文件来轻松地为每一个命令设置一个别名。 这里有一些例子你可以试试： $ git config --global alias.co checkout $ git config –global alias.br branch $ git config –global alias.ci commit$ git config –global alias.st status 这意味着，当要输入 git commit 时，只需要输入 git ci。 随着你继续不断地使用 Git，可能也会经常使用其他命令，所以创建别名时不要犹豫。 在创建你认为应该存在的命令时这个技术会很有用。 例如，为了解决取消暂存文件的易用性问题，可以向 Git 中添加你自己的取消暂存别名： $ git config --global alias.unstage &apos;reset HEAD --&apos; 这会使下面的两个命令等价： $ git unstage fileA $ git reset HEAD – fileA 这样看起来更清楚一些。 通常也会添加一个 last 命令，像这样： $ git config --global alias.last &apos;log -1 HEAD&apos; 这样，可以轻松地看到最后一次提交： $ git last commit 66938dae3329c7aebe598c2246a8e6af90d04646 Author: Josh Goebel &lt;dreamer3@example.com&gt; Date: Tue Aug 26 19:48:51 2008 +0800 test for current head Signed-off-by: Scott Chacon &lt;schacon@example.com&gt; 可以看出，Git 只是简单地将别名替换为对应的命令。 然而，你可能想要执行外部命令，而不是一个 Git 子命令。 如果是那样的话，可以在命令前面加入 ! 符号。 如果你自己要写一些与 Git 仓库协作的工具的话，那会很有用。 我们现在演示将 git visual 定义为 gitk 的别名： $ git config --global alias.visual &apos;!gitk&apos;]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
